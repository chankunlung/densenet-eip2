{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "60f4908d-ebb8-4038-efda-55af156f3f36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import math\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from matplotlib import pyplot as plt\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "l = 32\n",
    "num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2\n",
    "\n",
    "# kernel regularization for controlling variance\n",
    "reg = regularizers.l2(1e-4)\n",
    "\n",
    "# kernel initializer following the densenet paper\n",
    "init = 'he_uniform'\n",
    "\n",
    "# momentum for SGD optimizer\n",
    "momentum_sgd = 0.90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "a24e040c-0511-4953-92c2-f6a78a4d13f4"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "\n",
    "# convert y to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hvAeq-Kwznh"
   },
   "outputs": [],
   "source": [
    "# convert the type of x_train and x_test to float\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# data manipulation and standardization to less than 1\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "colab_type": "code",
    "id": "cBjrR5bgXf7v",
    "outputId": "16d0d834-22ef-434c-ab73-e9be2c956d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzsvWmsJUl23/eLiFzu+vattq6u3qeb5HCGs3A0skyDkkBRginLkiBSkimbAD8YAmzDBkTpkwEDhgAChg0bFjCGBUiWTVGWSGrhSDQ3DcnhDKdnRsPpvbu6lq797XfPNcIf4mTeWz3V3VVd9V6/Fu8BCpU3X968mScjI87yP/+jnHPMZS5zmctcjk70R30Bc5nLXOby77vMJ9q5zGUuczlimU+0c5nLXOZyxDKfaOcyl7nM5YhlPtHOZS5zmcsRy3yinctc5jKXI5aHmmiVUj+mlHpDKXVRKfVzj+qi5uJlrt+jk7luj07muv1eUR8WR6uUMsCbwJ8CrgMvAj/pnHv10V3eH12Z6/foZK7bo5O5bu8tD2PRfg646Jy75JzLgH8M/MSjuay5MNfvUcpct0cnc93eQ4KH+O4Z4NrM5+vA59/vC42FFdddP+c/zBrSarpDOYXzO3BqepB6l+F9TztcvdcfHl6GO9dIBvvqaM5+T3kg/a6urrpz5x7zHxQo0aHfrkS9S5HqHlsfLA53l57d92zUR93joOkH6/z29WvX2d/fO7G6BWg2G25tdQkArRVF6e9hPE7I8xwAax1KVbcxezvvGpTqHrfqZr6hZgfy9FjnXK1VBVTOqH8e7q7j/GkUzjnyPKcsy+PS7wPrdmlx0Z3a2prZ4y/13WqaHdO1OGZ0omYPvut703PdWw3uPiYO5b53erlx6yYHh4cfqNuHmWjvS5RSPwv8LEBn7Qz/6f/4Zb8fi3PeoC5ViBbb2lGibQlA5KaTbaE1JcZvO412hZzn3RPHvQbo3XpwWPn/3Wq7h4HvLGjNv/g7f+Z+b/nYZFa3Z86e5df+v18HQGuNFoUaY+ptpRROT1/UavQpwNxjALr6QPksL7BzDmdVvW2tvevv77dtraUs/fPNCktRKn7iz/3pD3H3Ry+z+u122vw3/+VfA6C9EPDKa9cB+MpXv4tTIQBBEBGGMQDOTg2Gst6CPM+JQv/aGa3rCcBZW+up2WzWOi2Lwo9BoLQltrRycdQTfDIZUpZ5dc31nBsEhqIouHZtdt47GTKr282NDf6P//V/A/x4nTkGLZozxtR/UwpK0YO1th7f7x731fGBUmg1fQeqxdA5Ryl6tgpUPQm5u8Z6NSsoRz12HQ5nHX/pv/jp+7rfhwkd3ADOzXw+K/vuEufcl5xzn3HOfaaxsPoQP/dHTj5Qv7O6XV2Z6/YB5IHHbrPROLaL+5jLA+t2aXHx2C7uo5KHsWhfBJ5WSl3AK/KvAD/1fl9QSmECXX3AKr/ihE4RF2O/rQtWu95aXQl73Lm9A8Bbtwsaa+cBiLsboL0V4WRFej9xTt3lVtjKolX2bnejPh6mlrFBaf1ArvUjkg+lX/heq8BosQS0Arl3v7LXR9X3N2t9KqByBpx7l1tceXHvshCYOc9dFrBsG2Nqa63+keOXB9atc672npy1hGKVtttdxpnfH0UNjI78MQrS1FuZpdHEsZ+otSmJ5bt5nqO1V0AQGdIs9ftLUPJuKKNRldVlC7Se6k6JtxeYkKIoqr1TSy4IZCwfq5I/hG7v9pbUjKel7jHOjDEEwXTMzVq0s/de73dTn9/OeA5KqVr/WmtMENTnrD2KssRVXsTsO+B4ILV+6InWOVcopf4m8GuAAf6+c+6V9/uOUmCM/8nApehiCIDJ91lW+wA00h7Pbp3x20HO+NIVAKKdA5LBHQD08hkaG0/5/e0lrPKD2zofkpArnLlYNRPvVWhXGfL27kBQ9bCZnTQUWuuZSeZ45EH1qxR3XWM9yIyWCdbHFpU4MXpm4M5OnLMDsfqTP7+aDlDA6elAn51oZ1+YmXu561qrl8FYC8bVE8ZxyYcZu+Ao8gyAIjNoGV95UVAU/v4zVRAbCRfkBVmSAGCDkEhe4kYUExhvJAwHE5otP3bjRpM0k1BAkhGG/hgNBLJQOldSFP53tdYoCaUFYYTKkureav1+FMR8H3ZeqMZrGIZTQ0GDCmQRMxHG+mPGozEHBwcA9PsHHB7sATCZjOux1m63WVhYAKDTXqDb9VbzxsYmzWYLgDzLsbaadB11nkhBZZA4Z3FOwgX23eNY39NQu5c8VIzWOfdl4MsPc465vLfM9Xt0Mtft0clct98rR54MmxWNY10dAlAMLtPI/arUsH3ObK0AkI4Klpr+spTWRM0mAKdORzhxy3qjqwwu3wIg6ZymufUMAFF3nSp0be3UIVauxGpJnjmNEovWKU1t+bqpm3y3KJQyx27RPrgobGWtopDYP1o5UFW4QGPkJqvkAEBpLcr4z1EU1UmWsixr9dwVIoDaXFLq7qyvm9FT5X7NWsMwtV6i0FA6+zHQrdyL3EOeZ7UdY7RBVx9sgTL+mLXlFqORt4QO+wPS3sgfErUoxTJzGMbDTL6ak6Zp/VtOki5lUSCPhqIo65BFdaw/JofKS3O23vaJR8uRQXEeobzzzjsA3LhxgyT11nkcxTRCCcXkKZNxH4Bef5d+OgAgm+Tkk2q8WqJIjreWRHQ0mqS0O966PbV1hhdeeAGAT33qh1hc8kgSi8VJ0rEoijoUo5QiCMTCtu6usFcQmPsOHxzrRBvrnGfM2wAMox7aJ2hxeUgsrpVqtOl0vVLyYkIksS2lU2JJSMSNgEV5GIfj64wubwNQLp6ltfYEAGF3jUL5HwjKElfFvNzU2C+1nXGv3L0nWqd8NvKETwYORznjBlVxPZRD1TfpandTWVvHpLQx9Id+4N68eZO1tTUAut0uwWzcqsq4uqmbBTNjTVOvVtVkWkk58906vGC9O/5xIJ+31pJLDDVuRjRiP7ZCYwhkIdMu57HTGwD8tZ/6i+zv+FDX//N//SNGMhlMsj7O+e+WBFhB2Lgird3YoijqxScIA6xoOM8TZA1Ea12/9Fq5+jmVZVlPEkVR4LAfSQjhQaUaA2macvWKn3ST8T6R2wUgMiVZ7u9rmBQUxutwNMjZvumPKYqCs2dOA7C+vl6ji9I8oRz58w8vjXjp1ZcB+PqL3+Av/sW/BMBTTz1VGxjADMJhNsfh6nFcGR73GzqYcx3MZS5zmcsRy7FatBEF7YZfNYxqoax3myYqnMG5lRixhlxgCMRV0iqrz+NQNBo+pLAeQ0eSCIPRVQ6H3rqNVs/RXvcohbC5SKGD+rtKXIQQNbPaq7ss2tlkmJrBO55cUeQzQXsrSWjjYcCAD6fo0K/OURQxGHhX7LXXX+d3f/d3Abh48SKnTp0C/Cr/zDM+LHPhwgWWl5cBb01lmX8eZVlOdeUc1n1wYqyyxLIs48Vvvsh4NHq0qjgCsdYyHHirX5kGeTUcrcNVVqnLOXtmHYDHzq7SMh5J86f/xKe4edsne9+6ssPNXX+/pY4wxru6xqjaEs2V9zLAW7QmlHfDQCbucBRNkQYKKAt/DbOOhDEB1hYfEbDjQUTx1FM+uf3MM8+Qi+WaTA4YD68CsLd9lauXLgFw6dIt0kLc4ThiYcHr2ZiAxaWOnLIkSf3+3OaMht4DDoOIIPA6v3j5LX7xn/xjAP6TP/8XeO7Z5wCwzr7LI5uiFKokJci4PomhA601Stz/yFpyGRwWgxXlOmtrpzQMw/qGfRxwOvnZKg7lXB2XWVSKrrzEvf3LHO57+F5783G6p5/032wsVPhvuKuS5+5IlpuJ3SqtTvxEm6QJkzq2FaG9ajHaUKO9XMmtm14nb7z+Gm+++SYAh4c9FiVD+8lPfrJ2oS5dusSrr/oS9VarxWOP+cqzJ554gjNnPDJkaWmpHnxKqRpQPzsBz06us6gG5xzNZvN7wgwnUUpb8jtf/QMAAq1A+4XeqTZxqwtAkmnK0o9jO9zjnVdfBCAcXmNDYrfhpmF1wccFb/WaHAo0TBlQhRQdBCFGQmZ5Oc0vEERoCf04ZVCB6N05sBLfdUwhS8ZCyYkPe6mZSkajNVHLowK6nQXc2uMAbG31WVu7CEAQvsj2tod9JmnK4mIbgDzL6gUKZwkluL3QajCcTOT4hAo8YMKYKzd84cm//PK/pNn2z/Tc2XP1vBAGIYGc866pV8b0/eYXTv4In8tc5jKXj7kcq0VrgoC2WJ/9QZ+ymAKBwypbqKeuTmCmq4lzU8yr9kDXen9lLe1fvEwgmMb28godyTT2ty+xf+hDCu2N87RP+ZCCarZBgts4h63R0TOUAA6UPvmog9u37/CNb3wDgC9+8Yt10L7UjlCu/a033+Rf/6t/DvjS5fPnvR4+8fzztCUUU5ZlbdlbaxmJW7+zs8Mlcd1ef/11Oh3voq2urtZu34ULT7Cy6hNpxhhyCS8U77JuazyuVrzwwgs0mie/6spaWyfAGlFMEHl9HQ4tE7HiC6u4ctFbXVde32LnncsA6EkfxCi9cGaDH//ifwTAL/3mq/zhm94yC6KYJPFWV2yhs+it3sPDQ5SEY4K4QSk4Wlc6crGAtdIMxZJ2ZXHX8zvp1ixQAdfr7aoIyZHX6Jlmu82TT/8AAJ3OEt/5jvcubt+6QVGFGpKkHq8A7ZZ/RlprYvG6DvojrIQR89KSS+nyK2+8yi/+Ux9G+Ot/9ac5d8YXt2ll6mSY0VP0zF1FN/chxzrReiIM/+DToqTMq3gtxAIiLifju2qLK9EzHzRQBRjczHFxmhJnEjpIxzSk8GFxa5Mi8fHI0Y3XGA78pLty+nFaK6fky22oKkBw099WDj6CgoUHlTzP+Ge/9EsAhO0un3jueQDiiLpYo7PU4YXnnwXgsSefZGHJQ+qKwiHLDbFyBBI37O/eRgs3QrvzGFEkAzRNGfV9vHI46vGbv+4hk8trazx+4WkAtrZOsyrohU67Q/XGFM5SBba0laztvXF1J0oWuh3+xBc9N0qn0yKTsNdXvv4aB4f+RQ8UpP0eAC9+5Xfoxv6em+ECqbj2p86dorHg73fr8S4vXfQwRaOaBJWObA6JnzDCMqvzF66w6Bq9YdHWvz9OBfU8pbUmivykkudgjKsLVk6sKB8ChHfF/NGYaqZ11GNoY32LzU3/3iaTEb1Dr/OiKOow1l1wQhPiJgKjsw4rPCllUU7HntG8/LJHI/zKr/wyf/2n/jMAVpZWyDKv8zC42+B6kDlhHjqYy1zmMpcjlmO1aB2OrKaUs0QVGJlp6EBLQseLQtd1z9Nac2a2pxxJoJ1FC5dCZ6FDKlnZsixr1yFQimTkLdrDN3YYrHoXYeWxZ1hYXJETacqZctyPAYyWZhRS9n1m+xf+wT/ki5//DwH4j//cnyGSsuflKObsqr/HdrPBYOR1PZ5Y8shb84uhoilFInu7uzSaVTmkodP1+wdZghOkh24aGoIjtfmYGzc8U9Qbb75JGHlXe2N9kwtP+mTk+tmzdRlwUFrMTCjhJItSikboB4EtJxRiWZqAGiUT4VgVd3W8t0d7ySfJJiG1xzAcTdg/9N5VkuWMJEmjJppUQi15mtDveSstMAYtvB5ZmtbeiVO2znhr5ctBwXuMs2xqZVl8LPTLe7rkeubPwu2gA5bkXd1uturSWK017Xa73u71vJ6v39llOPFjXQcBoWCOO52wnj0KVI3c+Pa3vk0z8h72T/7lv8Liog9BFkVxF772QUrzj3Wi9VJVa00LBLTW9WBV07J7iqIgr3A0zqIEvuRxyK7eX1cvWUsioPKouUza9+5X/84dNtc936Uy1BO8UQF5/zYA+6/tMlg/C8DGufO0qooRp1Du+OvxH1QaAbyw5u/r7ZvX+I0v/78AvPDcY3zhC97lnYw1maA1+r0hjY6Ha4XG0tZ+4mwCV6/42GLv4JAN4wdZEFJX0YwOB2iByOzc2WdZ+cEd2JjlFR8uUOqQRuyPuX7lbfLUTyid5UXiWCA4fDyKQbw4VFWYoAPihnB2hBGIC69cQUvITqLcko48l8dBflhTfA5eyvjhxz4BwJuv3saWghwINFZCNjk5RgZ1HMYEAs5P8pJCYrFBHFPK+2C0oSGTx8RZqjr9siyxNv9YTLR3U2lWcCpbu/lYVb/nmilhz3ic1PmIWZrE0WhEX+CLURxzbs3D7hRQVIUJ1jJO/HzRG40JBcWRK/jt3/5twIcX/upP/SQAKyvLNT2jMcZf832qdh46mMtc5jKXI5ZjT4ZVweowDGrMZWWGV1Jh4Q77B9y6eRPAr/xuasVOK2dnaM+YwWs6i5PV//Bgj1SSZM1Ol2bLWwhRHBNWhQzWUtzxmLpb/X2Wtnwp38qZs8TdpTqEcVJFuZLlpr/fT5xe4o1dv5rfev27HJz1iYO3btzgG2957GxR2hqHmaYZi9ZbX+uLizTXvZvfarfJxKNwTJ8L1tISazWahDRD72ZZHaGFSQ3rWGz7/T0N1y+/BcC17dt0Fr11sb66SbvVZCzu80mXikfDKUMgrmW3uww3pUjGKLrCxnWqsUoYeX3d3N1lZ0fCBTi+/pVvAbB/Y0xLLFFrCpyMxaIIaEi4J9RglH+uzViR5FVprqlZ6LRTniAcwaqrKROWBx6c7LEL05Ltu8palWCBAU1ZY4hv3bnJd1/+DgD9w926NHwW1+qco9vxoZtFE00LaawlqSAgSqOqEFBZElfIpzio+Q2+9uLXGCT+3fjPf/pvcFqKecosxyl9X50Z4JgnWutcXbkSxgF5WpfX1HXJMKU61EFAu+2hP+O8oMqNO2VnIge2LkDIo5hcsotqlGKEss4Ulv7Ax7yGwz6RVEdtnj5N3PRub2mhGfuXp8hTelc9J4PBcu6Tyyfeu82d41BV+il5YsHHCrOLb/PVXY9G+P3Ll3lZ4rjOuhpGYwNDJNCijcUOn/0Rr5ONhaiGFvkqI398oBW7t/0CSKAwbYlFUtYtXhSKkcQZ33n7LcaZP/+1wyHO+PPHjS46NOztHxyFSh6xqJrUSIcdLLKgEGEkq9+MAxYW/BhaXmjV+QLVaBIYT+VXGEdv1xeNdMIFFox0E2lGHOZedwfW0hKER+xyAiXFCA1FUkihjoJhNdZNi6Qi8LGqHvdlqdEqvO96/JMiNUmRM1BOK+Ru3rgCwDdf/D16B55HoijyGvI2y//gjTf/3clkQq/nUTJBENQFTr1er/6tPE8JRedZllAhTxvNJi++WEHJbvHXfsp32fjhz31OejHNCxbmMpe5zOVEyPGiDqyrk1tRFNZ127OZRlWUaAlWB9rUNGmKAnsPAl5nLVb6V4VrK7iWt4BTpTACMD/XWCMRb2E8HjEZ+wxkkeUY7bfToqgZkJSCUK6hUSa0TYk54UbBYJzwtZffAKATxoSScHpz5w5p4XXYPv8UW5IU3H3nBlbusTAliehwmJb8vb/3vwPwI1/4NH/yRz16oShytDggoXIshf4ZjPOUUNzlcjT2lH2AzacsUpsLC1y74xOTyjkqSP1gMsZNpsxeJ16Ebu6wl/LWVV+8ceNmv8Z6xpEhECvWxJrByNfaTxLL2XMe020alr6M47WsQ6OiXiwK3jnwCl5utVnseMt4pWWIdVVeq8mthBcIub3tPYFbA8WeJH6dKwnFY7O2RCumvbBOsNyzAMBNGwXcuXWNb3z9dwC4fu0SRe514hx1KX8cx3X5+HA4ZFGKPtKsrInClVK0pMS31+tNPVUDo5EP72R5WSfJ0NAQ2oBbt27zpS99CYCrly/zZ//Mj9fsax8kxw7vqmAxcRDUUInZbKG2FiRDrZWps3xupneEUndnKStl9ZMxmVR6LC6v1hOyyjKaEo/UrRatlp+EgiCoa9O1gjL3v2vTFCMPLHIlrWCGc/SkilOkfa/bzccW2XzyhwDYu/0GIyExOXXuLKbh7z0KTQ3ijoKAsoqFaXjtLT9h7/X6pBM/4JYDTUMUneU5pvC6WlxcxsliSNZDORmgdhrTNeOMlsRxtc4oJQQURjGxUrXrfbJFc2vXx+ouvXOHg76/TxM0iSV0HcYFWlAHJjaoTLYDi1J+PJ09c5aBkCmFvYR8KOfR8PzTPi9w7vEnsIUYA5M+NvW/WzqFCaSKzkSc3fAhmJcu79Hr+ThxbiKiZrc+Xtv8YxU4uLtLCAwHngLx29/6Kpcv+3F5uLcP0tR36/Qp7ty5Un2ZRek/lqYpk7Ff6Ao7DUcExhCJAdbtLtDr+wl4MhkTVPmjuEEgi1Xv8AAl8LooaNZETL/wC7/A7s4Oe3t793VfJ3+pm8tc5jKXj7kcO+pAz2QFq9VrFnFQ5imqEAo+FTISoLEtS4JZpq26oMDVZb1RGLFzx6+A/d6IpjAgLWhVN2TMwiaJZC9NEFCZqkEc+SZuQDEYEYkLODzYxh7ewZVTUuCTKIHRnFn3IO6tlTUWpKTZLSxTpj4xtn1jl0HuEzFFmlEMpbY+CFjZ8G7W0tIyn//85wA4ffoUTpJkC40OTlzn/VSx0/f7w6VNGhV6wcJoIJ0EXEkuVsH1wwNWTnvX+fFulxs7vsvG2soG3UjxYvgRwLkfUPKi4KU3rgCQ5IZm2+vaoQmkTDluZCB4ZGUUy2tep3oZIsEda2OItR+XSx04EG6O9fUznD7ni2e63TbJ2OvoYHdMFsizhLrfVVYUNR70wqmY3X2//+LtlCQX7oXSEbh7uOQnUGYbL1ahjgDHxcseJfPO9bc4EOtTqwCst1a7DcVS13tpV6+/w/KKt2iVKxlLAry9tER30b8DCsNASO7Howkrq4Kv1bB/UCWKhU8FMM6RSRFVURRE0k5eKc2v/tq/oScl1x8kxzvClarjoEWa1fXNwUzoIIwjnKlCBIoVqWQ6GG5PXSA1k0d11C0ooigmknjKOE1pSLWMzbMaApIkBQdpRTs35bsNoohgxSs9z/OaNOTaW69AcodJ//DR6uIRi9bQbkmsOlQ08ItVpxGz+qyHa0VLpxiJSxpqg5PYVpYmtASlEEYhm5ubACwuL3D7lme77xYBL77xhwAM2k2+/6nvA+Dy3gFD51+AjY11nIR9zj+2RbzsX/7B4XM8IZVhe4cHpN/0NeV5WvD7L73GcHTy4V1JmjNOvb6anQWsFLDEcUxToG6taMJ4LC2WJiWNjnftG50mNvffTZMJE6kA63baLF/wcKH1008QytjdP9glqiu9NK22n0i01nXcezwakSZ+smkFmucu+LDDdu8aYzEKlPLtXU56vcIsjSZQG1RFWbAvrrktMwopRlrubqCERyJNJsRhRfpC3R339KlNrlz0yCGroNn14RSFptX0RTiD3iEH+/78jz3+OIEYDFevXq1bBZ06dYoDQc+M0xRb8UtYVXcqvh+Zhw7mMpe5zOWI5QMtWqXUOeAfApt47+VLzrn/RSm1Avwi8DhwBfjLzrn3BUQqpSgqgJrS1Kl8o2uy4rDVIgmFVLnIaMT+Eo2p4MrC3HWPCH+jGXP2nF/Z87ysa+ptntUrZiPL2KiZpFTtpmhtKKQtQeYsSImfy1Jef/llkiMA1T9K3Rqj0C1vukzKCWrbl9FaU3Jr26/Ou/03UIIhbLfbNc4wigK6qbeaWq1m3T3h5s2bfOeb3wTgd4IG+4l4Gu0l4tKzgL38xkW04HeXu4ZPXPDW8Pc9s0nc8br94S98mjj21kKnY3n9Tf+7l2/3SbH3Dfp+UHmU+gVFo+NDAZ3FJYaSaIkbMS1x54e9PZw8g2ScoMR7ixrTZOpknJBIglErWN7wVJXjZEwgpmdWlLSEbwJl6r55vkzdeySB0bUlnY7GbC56i+3sWpcr2/7aVBxijT0S9q5Hq9u7kSd1Xy7niGTcLHWaFOu+ZHxvd0ijVXmuOaW0Wl/otGhIocFip83WhvdQD0YJXUmAD4fDmhD8ySfOsrvnL+32rZs1xefW1ha3bnnPxFpb9yHr9fsMJTRWFJYguH/61PsJHRTAf+uc+7ZSqgt8Syn168DfAH7TOfd3lVI/B/wc8Lfe70TOOTIpUmg2Y3Q+JWioLjizllHVbQFbD2hfV1yRGsxkJ2dutMjzmtPTWVXz3RZlWR8XRBGxPIyihEkm7UMKRynuYKkMqXzXTgo2l9ZqmMkjlkemW+tKcsFfDfMRuvSZ6rDdZG/fZ0p/72vfBambX1xcpjf0+5VS/MiP/gkAPv/5z/H2Je9yJcOEIPX3fX1/j4F0dT270eRrf+DDCGmWkYz8YL1hhjxxxr/8e3cucabtG2XGOsJJwYJ2Q+Ku1+3N777JmdVFrgRH5lg9urGLwsnrkmYFLak6CqKobp5YlmUdQ21EJWniJ4DlaIFCIIX9g32qLrUT56irbRT0hXpyYXGJQDoytNpdms0qLujq4d5ptwhlvEY2IxGEzcZik5uCjsiPFjX3SOeFKudSliW5hEcio2kIMZEtUk5JDmI83GevL9A5ndMV0EugoJT8TpaMSSd+UkxGKZksbqN+HyOcFadPb9YGwJVrOxwe+vDg2bNnWV1dBeDatWvs7u7I/jN0hLRm+86Oj93eZwz8A0e4c+6Wc+7bsj0AXgPOAD8B/AM57B8Af/6+fnEutcx1e7Qy1+/RyVy3DyYPZKYppR4HPgX8AbDpnLslf7qNdyHeV5x1dzHtzOJoq6V6nKY0xHXVGnrSEM/OdFhgFlPLNIpgnauN3tLaOtnm+yhVdep6WrNuC2xFpWinoGlblCQCWB7cucPulQHJeJa+8dHLw+q2tLZuNx4FGifhkbzUrIolcP7CE4ySaXM/qShFa83murBu4fh+6Xv/9lsX6a35xMHeuM9w4Ff8/XgbI1n0osjo9bxF+6kfuMDjp717d3t/m/Vzz8i9ZYx70hLapjRXRP+tQ4gUdYOzI5SH1a8JAjpixQ5Ho5qzI4rimtU/VqZmLGs0SkKxnLDUeOR0kmKUWMZJRioZ7e7KFkqKQBrNJkZQMmvrGxRipeVZghFvbGlxgbzhfysJLAeCoW4EjkxI7seZ/p5E01HIw+oWqLtFoNS0NNwZYullF6iQJSmRffLUMpMr/r3d2TvALXqrt72wQO/QIweWz5zmwnmfaGzu9Dk48Fbp9o07dBve02oGMXsTnwyLDYzGgkYY9jh92ocLRqNMLC/fAAAgAElEQVRFrt/w5eZvvvU2qxJeWFheIpkkU/6PD5D7nmiVUh3gnwH/tXOur+6GWjn1HjyCSqmfBX4WYOvUFqGwv89yOc7WKFM6jGTzojBgc30DgKFwyMo5Z1rZuLrZWhxH9Y2naT5tlZOVVA1a0ixD5laKvKzjO1kyZjz02cXewSF7O/7BDPs9FhdbpFKJchTyKHQbhorDHSkEWIsYycLS6yWsbHj6xy/88adJc+9WZllSTxZJklCRRxweHDAa+mN++Zd/idXlVTk+q1/yzOboRAo6IlNTSMZRiJUCkLy06HomL+vzT4Ypy00/GS80mwSmnOEZPhp5FPptNtu1YRAFIdUcarShkKKaptY1B0dgAqqISDHJsVm1iDuKUkrstKmrmrI8Qwl8zlpqyr44jhmOenI9ZlqoY6eczMaEaAk1GOWwuVQ7Jg7QNSrnKORR6HZjfZ3yXouBdayseVjgk0/+AINbvhpvfbnJRs8vbnuHiqHottEJCUJBbhwOWF/z4+zM48ssjvz+tY2F2hgLopK1NR+7bbZaZBVPhzakEoK8fft2bcC0Ol0SgdSFQUCjdf+NRe/rKKVUiFfm/+2c+yXZfUcpdUr+fgrYvtd3nXNfcs59xjn3meWV5fu6qD9K8qh0GxxdnPNjLY9Kv1U10Vym8qh0uyTVXP8+y/2gDhTwfwKvOef+p5k//Qvgp4G/K///8w86l3OOVLBweZ7XK20cRQz6/eqguiQzCg1RxWjONGDurMNWrcptUVOgJWnOeCzoAOc/g7cWqlLbwkGrKVa1yUlL7y5cu/wGPWGRKicJQym102GA1R3ul6XnQeRR6rawljd2fDHCATlLXe9ylU4x3L4CwIXHFtiUPl67uzs884xHDty8eYPbwsa1vrrKjWueLrIZNziomLXUtJ99lqUosUC0iWu2qOF4RCzudat0hDL3J2VWlzQ2ggZLcq5nzv4A2VgRmksfqKsPI49Uv2XBRIi8o6CBsYJcyafNLPO8IJn4cXlQJijJbqNtXUASmZjBWIo6tKs7Kaycf5KoURGim9pjG0+SOoxVpCmJhCmy8ZB07K8nSScMZNhrownF8zCq4Khs2UepW+CuzgVTNm1Th/kuPPNprsh7fvntV2kLjvbs1jq7wvMwSW1NpZiVlmTbv8ONlkbJ/rCxQCmW653dIZ2ufy4bm01y2d8bjLlzx3u0YdAgiKaJ9Oo68zwnTdP7DsvcT+jgi8BfB15SSn1H9v0dvCL/iVLqZ4CrwF/+oBNZ6+osYpbldSwmmUyw0hqlKHOKoiKGSBj0fFwwGQ9RUkVT5rbmSS1diXNGzpMxlkGc5SV9cYFHgwP6Ert56hPfxw9/+vsBuH7lTd7Y9hn2bLhPW8hRDscjhLGO9uI6zc2n0FKh8ojlkenWNAztCx4SNHKT2oWPCBjt+/joay+9gsu8C6XQ/Oav/wbgyUcqj+/bL36T5WXveSwtLHJr5DtQoE39wgdhg0BV8e8pfWVWFkRCO7nZ7lAK6Dt3aQ2BMtZw7ZYsCOMdijSjdBVd5iOXR6Zf51xNGVkUOVpWkXKGxzQfOkqpiy/KAU6y3iaMaEvniXLBcTiW7sBKE7Y8ZKzZXqndXltaAolN9MaD2u90WmEFkmd1QCZ/KC01B+04mVDkVV1/QOHcUXEdPDLdzopSqkb4BCaoCzS06vLYc58GfLfhW2+/CsDV69vsCqomDMKaAtFXnkr8u9OgkGq5w4PtetKNGxELXf9bS4vTirS9vSG9nl+5Jpmd9m+MTH09cRzTXVio9f5B8oETrXPu93hvc+5H7+tX5nJPmev2aGWu36OTuW4fTI6XvctZEBxtaDR9KQJwhaUr2bxkkrC27LPkl65c4cYNn8Dc294l7vjVRKFIhZ4sLwpysRD6e/vs7HpC4O3dffYPfVgg6e+TSoKg0e2g3A8CcHpthUOpjV787Kc4kFLQ79qrqHUPJN966pN0Vk9z/TtfORKdPCpRTmEE82rLiERc26woMIX0pcom3Lnl9XPqzBnaQhfnrGUkbuhoNKqTYZtbWzXtXKfbYkEywE4bckkimkKxtOhd3ixPeVMwuKvPvVC3kx+lYw5Ft9o4XrriDaA3b75CO4zJyyOzaB+ZaKWpYBoOS1Z6a70bGAJ5jfYtjKXDxOL6Cu7AW7Q5BiWl3mWjQSL18p/8zA/z5Cd/2J+/0a1nrVbLMBZscuYSkom32AJjaHSkHDeKaSx4zyPIRly74Y/f3r1DklUl7AGGgqMIex2PTMOIhQMtRQfPft+niMUbHkwKgqb3Vu/s7dfjDB0wEgz+fq9HV/CvUWzqxgJGp7Sb0j8Qx2g4qn+3KwUgapzXePPeQc9nKgFXWibDIUV+f2P3WCfadJLw1uuvA2ADTV+y/BpFT2qO+70+LQkHqiiuYyKHu9s0xSVKkpQ7Oz7GvtcbMJIJtb+zzUCUQthkZd0jSyZlTijJosODQ3a2/eT9zPlNPvk5Tyd46cYeN1+9CsDK488TL/lsZ9RcRGtz4odqqGLORs8BEAQNAgnRREGAcf4xHywc0Gz4ljJbp7bqJpXjyZg49neYphlDId1AwZl1P+A+98IFLiYegXB1VDDe9c8rMjlPrgtkLxrz3UtfB2A0OKSjPL9BbgcMhkLJuJxzcfcVAOK2Ip9M61BOtqg6c5yXFqQdymg8qqsdCwu39vz4+8TWBtGC5/7dORjTUlLd1enw2f/A80Q8/dzzjOqutiULMokm4wFWqu263TZB6Re1srR1Pf5yZ4FYEnSjwYiLN/wEc2d/QCmoHaU1yp70ketlFq1QLe5FVmBkiiqMxQmPbysO2Tz/FAD9wz26whx5ZmWBS9JWaKc/4tw5n4MItGZfig4W2xFb69646jQCmlJ5mkzGdYNLNRhzMKgmXVt3eTGBqTlTAm1otVoYs3Nf9zdPVc9lLnOZyxHLMXdYsIwkcxt0WjRkRU7HY3Z3vEt7eLDPvxMQ8cqps4xG3roq84x3pA323u4eVy/77aC7SAWkHQ56NR6vvdiiKb2sRq0miQDDk7Sgd+C3L7k9Xr/mV8BrBymZ9hZba2MRZSqiaiNYuZNtGbSabX7wBe+GRlFIGEjZJqqmcuu0Fljd8GGZLEtr1MeKW6rxgEVR1AiNJC1pKm8p5TplEvnQgSqh0H7Fb6w2US3vCUSdlL7xFt3l/ZvEI2lP3r9N0JCS1WJEWnqXTqvQV6Wc8Fbu4HkJckHMWKhNlCLPcVJSWzrDjmTAr+7nPHX2AgDPPnuGVfGuDno9zl/w+wdpRiBZ76jR4qqEyYb9QxD2tW7DkCeCQBhNCAJB23RCDmUc39zr8+9e90iRvUEGUhChUb4B4SPXxqOX2eaMpYQFy7L0lFz40E3FllVaS0eSi09/4nleedEne7dv3uTpLR9OefapCzW+djSeECz58deITc0O1ogbdDreWl1ZWqibEmwmKQd9P0/d2d5lZ9+P17SEVPDjicoZ5hn5fXYHOdaJNogirEwAS4urnDntXavD/Z2a7/WqzXn7de9arnUXaVbta3DkQsHXbbcJI6+gx86erwsWLg6HlBM/MWvjmEituVIhyvptV8J3LvpJ3YQHFMpfj2lu0JSsL9qAIBm0MmgdnvhOosYErAqlpNYao6u2PLqG1IVhSEv5WFWz2awztMaYmhZuMpnUVTplPiSQCrCbNDjA66fo75EJ/M1thWQdqTsPhpTGT9INowjwKIj+9pC2ZOkXmi2URHcoS/S9+YFOnJTltLDCznSP8NlsIYPJp0Uaf/j2NmPr3fzzzdN8+7LPkl975yp/6k96vTz99NPkzh/zr//Vv+XffevbAISBodkQcpRuk1HPxyDzLMeYqpChSSY8Hde3D9iVLHmuQgltgNHTJqYnWZyjJjK6az/UBlI5KetQiVaKXN7H1sYFnv2UPz4rfpdb13yOYCU2NKRT8eGdPWKZyDuNRp072NvfZzj2z6vb7dIRWsvujJHW7XRYWfPXsN+bcChwvL2DffqDwaPjOpjLXOYyl7k8nBwz8bem0fHuJ1rTFCq4vN3ln/+KLyzJkwmjnreQrrz9Drm4CweHPTLB2pZW0xJAfp5llGITxXGLTDoyYA0g2XYTUcit2rBFT7LwC60FYgGJKx1iK4A52tM44ukZ0SefpV4pxURQHEEQ0GnH9f6q1LbZbBHkU/drFnPonJTUhg20YEFtGwLjLY0dImyFb1QjjLi2TuUUxus8VwW2Yj0zlrTwzzFjTNPIsy4KjKzvCiWJxpNv0xZFVnM9RK1FahtFKWxZ1eZrSvGQDiaWF1/zeOHff+1G7RoHRvFJ4SVYHTm+/G/+NQAvffd1cnF1jXJYCa8ofUgpiTecQqmKwL5Xp+eKsqTE/67TJU7ak1NjaE+2fos858qVK4BPhFXMWUmS1roNw4hIxvFoPKEpKILTp8+x8NgnAPgBo1mREMHbb71G3PZ6e/zMJocDHwpoNqJpqTMlE5lTbu/1MTLvgKOsSqOztC67zfMSo/w5VzsN1loRN4Qp7YPkmCdaWBPykkZs6vYypYOXXvZohDAwdAR29Ftf/xZbZ3ydvgpiuqLEJC0IJIbSHw1rdyqMwpp7M7OWUMDd4eIa5856IonV88+ytOLJJkJl0JLFRQfYChiOwHkAjPET+ckeq5RlUbtfnmvWX3CeF/WEury8TC4UlL4oxB9jbYmzFRi/IJNQQxrknnsOiPMWhYRl4uYQo6tOxQHaVo01G/VEoKwjCvxvNZslYUOKTaytQ7IahznhIZlKwiDkQNj+1+MuSqqIsqyoq4OMCerxV2rFtAzeoYMp+chvfuVFAL769e+yuyc8BkEXXTUTRYE0uXS6xErxgrWOauosdGMa1yRFSehNG4XSFQzSCTj/ZOvYOlvfSxzH7Gz7vEmn2+WpZzy6wGhNURU1ZXndEqsRlHVYb+HU45wWIyFYXOedq76ZY683IBKOlTSdsCDQrWazRUe4JHvDpKa7VMaQCdFRkhZMRhUCAdZW/CKwurxMuxnzrSu793WP89DBXOYyl7kcsRyrRWudY2HJY9iacURR1csHhh//s38WgP7BAe9c9X2qNk+d5fwTfkV77a23GUl7bJs5SleRd9vaKj33+AWGE2/purhBa9Uzfy2tnmJ1zWd9g7iFMZIEUgZVWRpaU0qtncMiuWWcKwj1x8G5VXUf+yhq1JZrmqZ3sdcHVR28MbUlVhSKWOj9YMpwH0URSty1fKgpRj4r3l3MCCvm+ygkzP22UZaispJ1STL2Wa9cJyixyowzdagn0JosTY6UXerRiaMrTQBtWXo3DLDYuiyzEUZTij/lpuEnXE2N6ICDvtCAqqKmm1Ta1A0BldM1qF7roEq8k6VZbdFGZsoUZgJFUtXcu6IuJVVOPLMT7zWouzgE2oInNsbw8su+v1yn3ebUhn+Hm3Gjfh+zLKsN9siErGx6/PtoPGShIraPOzVnh8Wws+tDQOPxkHbbh7SiMGBR5iZ0QCJsaJ32CpvSZFM5RVtClv3RmLfeuUV6jyTeveSYu+Cqulpj0BtQSvxlf+cmSer3B1qxdcq79o9deJLf/4Z3s25t79FqC1FK6cildjmImpTWP6T9QcH6uecBWD//NK1lH3aIGu26KWSoFaFsW1TdvsY5W9MzBoFmoetjQOc3l7hwapWX/mnzSHTyqERrPYXUvyvTXLlW1tq7Jt26IWYY1O+iMWbKtRoadEMa1g0LlrR0FW1reg2vj44OiKxUjJHimLpZQxnoZeBqsLkuwYmes7xgPBpi7dHz0T6sOOdoCF9D4ag7JnskQNUOSdeA9iiMsLaiLqSeaAvnCIOqwgys8Dw4O6X7NDrA6Woid3VIwWhV8y2Am1IL6mlH6cAE02dsq3FxssU5K1SdfuKscje+9VVR769yEJ3WlLIyyzOPEgJyqwiMR8acufAsjQUfIrjy1lsgsXNtFAg3x/bOnTq8024169BBEDQIKzRSEJJLyGJnZ4drt3yBglOaUZLVFIofJPPQwVzmMpe5HLEod4z1j0qpHWAE3F8E+Xhkjfu7nvPOufWjvpgPKydUt3B/+j3RugVQSg2ANz7q63iXzMfu0cojG7vHOtECKKW+6Zz7zLH+6PvISbueh5GTeC8n8Zo+jJzE+ziJ1/Rh5STey6O8pnnoYC5zmctcjljmE+1c5jKXuRyxfBQT7Zc+gt98Pzlp1/MwchLv5SRe04eRk3gfJ/GaPqycxHt5ZNd07DHaucxlLnP5oyYPZdEqpX5MKfWGUuqiUurnHtVFzcXLXL9HJ3PdHp3MdXsP8YQiD/4PMMDbwBNABPwh8Pz7HP9jeHjMReDnPuzvPsw/4Bzw28CrwCvAfyX7/3vgBvAd+ffjH8X1fVj9znU7H7snRb9z3b7HbzzExX0B+LWZz38b+NuPQvlHqNBTwKdluwu8CTwvCv3vPoqH/LD6nev26HQ71+9ct49Ktw9TgnsGuDbz+Trw+fc49nPARa3V2w2pqVe4V5YWfEljsxHSafmyuzTPGQx9OW4YBJiKRcs5cmH+D+KQUBipSjvlOihLW5c9hkFALKWkRmviqMn3Pf8cSZaztbXF5uYm1jniOH4FoCwKlpeXfx48zWBLmra1O12Ujrl54zoHB3vHWc14v/r9HHCx0+m8vb7hidRLa18597hn8Tfa1CWizLAk+ZLN6e1UZZvOeTYlAFsWddtyY6Zlura0NfG1UhoUPH7hAq4sOXt6izOnNsGVlKV9BTyN38b66s9Xx1fPLgxDhuMxg/6AZDI5iboF0e8q5u3HhSUOxyuf0UISP8PT4NuuVwxcBqTUmEBPVT2bEpndVtzdPK06rYznHyIGHJ/RDX5IxRAa0LxSneczuvHzfruc+bICDFco2HXlcen3gXXbbDTebjf8mMiK/JWWlH1rPWU8q3g5wL/bdalzENARysSsyBiMpcW7MQRCfp/n+ZT/Qam6dNlZhy0dzTDEGM3yQpulbguFq8euCQydZvTz8mWCcFpurYDROCVJiw/U7ZFzHSilfhb4W8CCUopPPOe7y4YUbC578ojve/YMf+yzvmHd5eu3+I2vfguAU+vrrATTXvc3D32d8cbjp9k678kjDpOU7oqfYPYPJ0zGnl7u9MYqTwhnwmLc5cITnrPyzcu3+M3f9Q0E0yzjqSc9feL+3h4vv/QSAGtra/zg9/vr/Pwf+xHC9pP85F/400egnYeTWd3GcYP/4e/+zwD0RyPS3OthsbtAV5rLuSKtFzQdRDgqzl3DwYEn3SgKSyKdikfDbYbC7r+yuE4o434w7NNdXKnPo6oBPeixf9M3f7TFkENp8rh7MKx5f+Nmu6a+3Dx9lq9989v8s1/8J49eOY9AZvXbRvMHHU9wpKxFCZmIylNwfjHKGQJCV0gX0/BtVdxSA5ryLmbTzj2utPXcqgJwQgTk32C/qUc59YzsSoiEnOb0Akq6MJCBuy50i+khKPmyi3HBIp8tbjwqlTwymdVtFAb8xI/+cQCub1/n1h1Pk9hqdmoOh+FwWFNqbq2vkUh7ptNra3zxc5/z3925yW998/cBWFpcYqPtx+j1m3dq/towiuiNPAfHZFQwkaahC4sdNk95zg6jLP1DT061uLLI1es3AdBRyNopz5/QasSEaH71t165r/t9mIn2Bj62UclZ2XeXOOe+pJTaB34sDMzPNISMROmAncS/6N+8NOHytp9cXZnQG/gVZyEuMGFFNpGy2JHulSZi97JfNJ0OCLW89DsJZuyP77QtXbFA2u0WiRBSLHTatJt+4qnaZMiF1g9VKcVIzpNkJa6tatakY5QP1O+sbpvN5s8c7PsBNEoT9vb9opQsT7Cr8sIXKUre7LgBRrrgDodDeoee0Wg4TuoVX5OTyaQ7mUwoxDDu9foIjSedhSWMeBTNdoOWtAM53OvVOgujBplMIrd3rzMRQqBhWjBOs9oLOUZ54LG7rszPVLywtBWqI2xnWYAa+XvTuaJw0mLcJQSp16nOllEVEXvosLmcX4OquuAahRUiKJU4dCr7gRnzFhuLZdYw9V9dUoKQrzBjVYPGhgEcmzELfAjdxlH0M0Phlx4cjmjKHJGm49rT6nQ6rK8Kl3UYsigGw0KrzUVpcX/zcA8Vey95lBWEi15X58+cJhWdDJIxVrZ1oAlbfi4Ypwmj1I/jTrdFJuxdCRPOPuENuXGS017wv+uKgiRNqtDDB8rDTLQvAk8rpS7gFflXgJ96j2NvAOecczRaXlnLm08ipDjouM3Lb/8hAPu33yEf+9Xqzs0+a8KitbTc4DGxgLUFLWz0ReBIB34gJUlOFnnl7mQTWnu+N1h3cZ2JsIYpHFrYe7RT6Ioa0aqpJ6chmXiLMJ8krJ6KayLtY5T71e8N4JwJAhYWPJ1bR0Gz5V/sVquJEuYslKoHRmktTl7O0WhUN6ZzztXhBaMCMmGXH4/HLMmz0FozHPoXw2IoRZ9KTYiEENyGEZTe4mqHAUNZuEwGI2kb30gKio8GXfjAYxfnxLoEEosSInO33KLqd63GMSb1OlJZArlf3BkMfXdHgIWw/q4qXc08hXGoTNzSSYEqpuTdrp5oHbop4QsDtfLGJUoY0BRlPY4dGhWHkB3r2H1g3RZ5Rjrx72ccxighjN9Y7dST7tLyEqHxY3r79m7dB2+7SOtebkXpWGpUVKGGg5GfR85vnuWOGBKHwx4NMbSWFhsM+v53i9xgpauCCUNaK/45Ru2ClRUhCh+UZMm09XtuXT1pf5B86InWOVcopf4m8Gv4x/73nXPvZUe/CDz9YX/rj6I8gH7nun1AmY/do5O5bu8tDxWjdc59GfjyfRxXKKX+plL6Vzt1zzBDmkispH+AlZ5VJg4pcn9ZQ+toSBxqYalDEXi3YGiWKZZ8nK/ZbkPHk+dM7Lhe5fM8IhMLoTfKiCW2NckmTBJvaWilp52uHVBzfSqihvBXasfh7i1K6Qx7nHI/+q1022q1f/XZZ5/0OxV1y2ZryymJtKJuAeIctcu+vLQybfFsQUkowNmU9NnnZdsR6mlisgoFKKU9yTXgXAal93+NMijpCKtMQC6xBss0yRGEIUVZ8I1/+5UPqaEPLw86dlH8Kg3pLGwsiKXPJEWvek/LtQM4lO7JQRtVuWy7fdgfyPna6CVJpEUGm4rLnzjURAajhTosQImrGb6hvgalqtAwJGWdlHPMcvtqXGiOnfj7QXVb2vJX211vucadiCjyOmy2GrUnsLe7y/Zt30qoKODMudMAlLZgLAmw82cfIxlKG6Ziwrjw273xiLghXgeOroQdAg15y//WJIVQjkmyjER6trm0QA18nmIyKNGFPz7NM0rcfYe9jo342zn35UYcs7fj3fnJnR20TK6xgq4QcG+dPs1w6GOKk0nK1paf8E5d6LK86CfUnbBJWoiLkEIj8vFI280IJzKhtjMG0stqt5fSaFSxmJyRDO5AhzNulqNODauA/sRPNrsDxan2ya6ec859+fkXvh9VhUSUrkMdTtqlg7ycVeigLDFVUjwIp0lxrXGCUrC2QXdR4rs4kMaLBlUTqSut62x5WVrKsqh/a+b66qwv94hpRVXfthMqzrkvf6bRRp3x7qTTDi2tvkkz/w9QnTY0q0nRwbIw9kcR3PbJRg5H2MrlDxSMq4BtiKrWcjttYQ5qimyIDaox7dSAhGDILdQTrKsNBqU0LgpOdMsw59yXVxY7rG36cRaFhkRCNFdu3GZPEldxEDCUDitLK8vETf8sdu/coZBFvD/u0Wj6+SI9TFCyoN/pHWJk/LWDAJ1LMDw0rGz6/M7tg0Ny0VOejCkkYB6FDaomClY7ciFqH6cZjWbjrnH+fjInlZnLXOYylyOWY21lY4ymLH0weTgY41KfUFnptlFyKZMepEnlEwVEC36FiouETclMjp9t8dXtqwDovODzEo44e2uI8d4FbitloLxF0co0mUCQxgkUTlq4aE293Ds3E9Y2DK13B9++M6G1mE7bhpxYqcHXHiQ985eizkhP29dore95vC0ydnc91/Ha6jqJPAutDaG0G8/L4q5zVvKeq7tzuLL8nt2Vhe3uM6HwkYqmtiaVVijBfZKHOEmQKA1qxY85d9jHiQeg1hdwgvBwez3URI5PsynWVk17gIHDqZnxVu0PAmbHa2XR+mTnbPLMP2OnNCo4+T3DojikkFDM/s4+ays+YY6zZBLmK1AEode/1opBzye3FrodCrFQD/YPaEkPsEajwa50LbbOYsTDW1tbYjLy88jG2U32Ux92CJuKyq8aHmQYwUnHYZuJdH92qpxiwPOQRtT2OPL7kGOdaONmk6UFPylu377N2dNeoZ1Oi2vbPkM4Go4Y9f3Nd7oxSeYVd2c4YRJ6fN31keGG8Q/ArMbsaMHCXbnBwr7fP9lcwklrYNMNaQqOM0kSbGXIa0UNoHF2BqqhGIi78M52n9XFPll+widaqfIDD+5+L9hJBfyenRT98X77+o2rvPGmxxN/9jOfZ3vbD+iN9VOsra3Kb83Gpqa/42Ygcnf9hrp3c8v7hcacDFF1s0WldN33jDioIXPKgmr4PEIaJIxSf3w3MhiJ47LQQh/Ii3swAinOUeXYg2nB936rwgVO4aT1dZmUqEMfdzTrTVw1Jm1Ghd+VKLjf1B42dtLFlgXX3rkCQKAbnN70cKqnLzxGIDCr29vbLK4syTc0YSDhrSJnNPD6LFXJUPoQtjc6FBLeUQZa0lhzkia4wOtkUE7Y7vuwY2ANkaAawiDi8EDyOEYju4kahoYUQVEo0kmOm/cMm8tc5jKXkyHHatGWztEfeGt1Y3WJM2d8dZcJQ3YF9G1JObv+mN+OLbcGfjUfbKxwcdEvLYdJxMqCzzoSt7gkLcaHz51lI/Qr+6AwbIwEuzl4lVPLgu+0mlwwuCrWtdvqZjqxWudYW/JB8jOPPcXSwiKBOVZVPbA4qBNN77XGvpdrr7WqXaArVy7x9luCxilLWk2vh7ObZ+tuoJ6F1ccAACAASURBVNqoGW/07qRXZaVqPXWF3UxYYzYh937XdCKlwrxqQ51JnAk/FW6aUM2bLf7tGR9G+KGDIU8IGiMLHeWKmEgLEdzw5xnvb6OlHKyBQdXtyUMU/vgiSzHeeMO0Wh5tAOByUNX2TLWvcryr0vpESlFaVjd9FefgcMCly74A4fyZ0zzzmK99OHd6k52e93p3tve4c+iTi80opvKXVlZW6HY85jUIAs6d9t8djIc1qmYwGqDFoj28fgctuPsiKXFtQcNEEdp5z6HMbK2/MAzqTrnjwQRb6LtKg99PjnX2cM4RS+jApjGXbvhYYJLnhOIibLQDVmRC7cWG3dxDK25dvsiimP+L7UPMlld66/FniZb9xDxcOsVL+AewlVqWQu/GXXn5bXojr7jNhdMYQSMEKqAOHdiZyQCYHPgwxbUkY2vxUzh3wkMHMAVNqGly/93Z/3tt+2NED1nOhvS3d8WEVsu7Stdv3+T0OT9wu932dFK/y/2fmYBnY1fOl1DX11ZV5miFZiZOfqJFTXWqFZgqDmrqEuSgLMnH3uV8bZLyNSkUGUxGtMTNbzc0XQHGU1hcx8cCm9kqvbF3Y/fsiKZEDBeUpi9whNt6yONSMWZ2E0iruOzd1WB1zLssoSjvifQ4SZJmJRevXgdgZWmBRdGJUZa4Ku/Wjn7Pv9tlkfP4eT8Wz2ydpiVt4Ld394kkhnr9xvUaRnh66xw7Bz5eezgckWWi/xLapZ9rus0O2wce4RCFMQtSnIOZ1oRqFxEo4UBphqRpWsMlP0jmoYO5zGUuczliOVaLNs8zDgUXt9huE1feV2AIJLgdKxgnPhSwP+xz4bRffc492WH9sU0AVhfXGe15a/jm3u9xWPrgebe5xWbDr96LRcKbN7wrtvXkeVYjj9Mre1nt9akZ0H6F//R/gMNdX569s/cqzzxzjqL83iz7yZMpfrJaaN9tub47CVbtN6KUs2fOcOOt7wCQphOu3/aW/YVnPs0Tzz0LCGJTzuOx9VOvQFX43bKc+a1pebNW4KqiCW/q8t7BjhMkWkHgdeQAVxW3OEUmuM+3k4RX5F7+VeC41fev1yv7t/iOYEA/3ejwrK4y1wW1J9EM2DHek7hmDRVv1aINuCMEQXmR82PWbz+dZTNWkqPiQ7greOQsLis+Bup1aLFED4ZDBv2qcMMQSjFMd6HFF7/wWQDW1zf4xHM/CMC3XvwWly56IqPD/5+9N421LLvu+377zHd+81BzdfXAZnezOYpsUqJoC6IYGbKtxBESD5ARJbIBC0gAJ7AcIInzJfCnAM5HAQ4QxwbswA5kOWJESxQlkiJDcWhOPVbXXPXmd9+d75l3Pqx1z3stk+zq7qrio30X0OTt2/fdYZ199l7Df/3/B0c0GpL17m/ts7wszdtxb0z/QPadZtjk4Ej2jloYYTTTOH/hLI4iQ/YPDnE0gU2KKd4MpRQbwpqUJorQ4vkGxz2FqIM8y9ndkQ0sX2yzubYGQD30mWi9aRBnGB15CVoF4XlxXP9sjf6CLO7tcMoTz0q54CN+m1FPMV2TuzR9qSl+9ut3eGVXFuWlj3yMxy8Le9fh915n97bWazmuseR5OWOkE3I5k+t3nuA9+uGat20nN9GT3f8fVgM1xlRQL3sCRbC5eRYvFKTHi999kc3zQrf43qeewJ3VDYvj9z3eeqRs6Wq6Znxzoi5bkGuNsixK6aoDPxiLcErNOFDRJJbH6fg0BkUCfHHS45/r1FcRNimVD2Jv0Of1RNAF3zIZZ+uS6kahodAyQpJnUBf/5kEDM0M1WEgTeb45dZhoaeIv5gOeNvI+pWMr5IN7Mkm1BuKsolo8reZ5HqWWWXqDAbEyau3v9Tm/KcikX/gL/xE/9dHnAdjb3+Ol770OwDe/+SLdQym5LDU6JArdWl3ssNCWTXH/cJ90Is8vN1ZoBnKNlheaTHuyAafDIYuBlAtuHd7EKlyuvV6jpXSuTuHS171mmiZEjfp9I2fmpYO5zW1uc3vI9kgjWs/z6LRkjDaqtcisnCyNqM5SS76Kb0omI4l0povbNC7IY28pZKgUdMMy5boiB/adjNUNKQusNZYYDSUtWI4jnlyTyKxXjLmrEXNnrUZzU2fNJ8ed8RIoqinRkjCQ6OWxSxfY37pNrmxBp9lmEWpRFNVJ67ruD22IzcoFWZZVJKlpnjPVkcYwqlFTzofQBV/fp8Di6d/K4INci/F4yN6RNC+HwyGJAvkdr+DsWSn7LC6uUSptn+N4ivb4CYlslRsZSkg0K+pPCBX3HeUxQ2Usc8djpl1t3iQJgZYdct9lV8tkruMQazd8Mp3S0FHpRtDAP+Ffo0D9YeDzRb1Ok8GIv65/u0lWlRpaxqswuAZgPNGR3tNrpS3pK6IgzzKaDYkgQ9djoBjZq6+/waAv0eTtu3d46ftSLnDdgEuXhDvaLXP29iS6rTcCjCNRaZoM8d1SH4+58tglABYWm0Sa+k+6YwrlAX3q4iVu7t0EoNFoM9FGeiMImE2SG5ORpdkjoUl827a8tMqv/o2/DciU2GyTM447y0EJPIsOzvDq8I9pnxHHFY2CwJdUwA99mqrUEDCmUChG6jU5LORinHmqRd+VdO3eS98g21IC66VzRMuSIrQaBVY5FmyZVuQrw9EIT1PgMIq4dvUlkpPctafUZhuq53nV45PDC7b6H9mMu12pvzabTVotQYN0j3ps74kPo3qDiaZif/rVP+HTn5GyzGSacO+e1rD399neEWLk23eusa8LfTgcHte9TVFB+T71s5/mYx/9JIAQ/Tx6+sl3ZifTbz+UfwBjTVVSuHJQstGXTXerXlAoHM44plpbRWFJdYGHUVgdMYW1TDV4cP2SQgcQPMetyjGFgVzX/VfrBZFST36yTLmkb9SyHsekCY4Sk5/ujdaWtjr0fd/HU8RK4LgEWkL5whf+mEsXpVyYFjGXLsvjSxevsLoi5YVk1Ks2wtFoVFV3Ll8+z4EeeiUORzpheutWn8cvCjnVe5/eJB7JcM57GufxX5HPvbm9w3S2IUXmmPCm1qTE3vdk2Lx0MLe5zW1uD9ke7cBCkTPoSRTluM6Jho1DPmuoeAU9HTSYhF0WPDmd8wKWlqR5Vqu1CLUTuFhrU49m89B3cR2JKEb9BcpC+RMm+9iO/K3f9OiP5YQ/mBxwPpyBzXOsplhZnhOEOg5ZlhqNnO6GAvyZ8doTqICZ7pfvGjwdybx6/Sr3tnYA+KmPfpxUO9vf/s636R7JyX7lyiZ1LR1877svsrW9DcBB95CbN28CMB5PyJVC0pii0ieLoqh6bMuCW9cl1fudowGbaxLdPvvsh5imk4fgiYdgxpCPdAAmH1d0haXNMCtSovpgeJb/cVcyp28Y+ONA/P5iPiSZEXmPh/jKfJZmWbXmwlqdTBtC4yQmtBIle8Yl0NIB9lhroQgCvqgNxjtxyV/Q/7BhLJHeG6XjYWxy6pdu+We07OJE7udGu8NHPywyNf39wwqz2g47XLgga+jgcIe7d0RtpUwnrCxp1jWZEGj0n6c5vpZlgqjFwZ5EtG9cvcUTj0nZ4fzlM3iO7BEELb7yXWm29XsTFpck21tdXuCoK/dGlhaE9dp9D9w82nEnaynyVB8e0+sZY6uJC1OYSlZl0hzP1jOOU1CMlbHetAg8JfWIC0pdWJ7b5MKy1Hf67jIT7TTubsBEF+JaM2PclfB/uwgpRpJSOEVyLHGBqYTdjIUiO/2g7z97NxUz6kJjiPTQKCZ9Xn5VeAxu3b7FBz4iOk1hEDGMpRYWNkI+8dM/A8D6Wp09LQsc7nZ56fsvAtAfDSkKPRgdj6guJR3XGBwdPPF9l0A5gF3jUmqJJqy5jJT53vFcskn+k8F54BjQgRm7P4C7skbLeEiSyeEeNJv81KLclO9zI/6SIyWqfzW1/ONSDrWjdIqvPMmBl1LTEkRnY5VRLIdO3Ovi6Ux9kiZkepC5xiVXohrfdcjrcg+8VOb4imp4jpgraC3Z82Vq7NFTKb8ts+WxqkejXqefKJwty+gdyVqpRXUmY/mN3f5hVR5pt1s0VBOvcA3ttvRr9va77F0X4qmVpSUWF6U3VKsv8P7nZQrt4lNP8DOfFCTDpbNr7OzKZ33xy9/kxnUZoGi3FlnoyHWvNwL6fdk7xpMpvcFA+hv3YfPSwdzmNre5PWR75KWDnnYOT4LqcSzBrDPqhux0hRx8ksTUSzmJzizFjDTyORrvkc0aP611PE1RQ6fDQkOGF+pBg1sjSSlGaY+tLUEjnFs7U+kQZUnMrqZ0nbpLoKTBtqBKvaNIZJ5nJ+5pNYN5s5T4CeasmVDjd7/xlUrV9pn3f5DNC6LqmpcuNV+YkT7zi3+RUCn60rTP7/+/QpRvHI/FRXmNH3rEsWYmpUi5A9i8wNWINgg9GkpZVxS20h67dOVxLqgUemlLkiSp0ufTbt6MGvH8BpyTdWaGY8y2rFf6XZK+rDnPM5xpyQDCry+t0e7L2vrf0i2OCm3e5jmN+kybqsGsCxxPk4qOryxhqMTiWRLTmmFwazVcO1POqPOqYs+/kqZcNCqA6nkKpTndDUfjOBWlZDFNMDoiPxklDIcSxXrtoGo6um5IPJXXX7zQ4rHLci0W66u02oJuefo9z7B19yYAge8xUOWFqLVCQ7X1Wgs1jHJEfO1bV/mDP/oyAC+//Dq12mwM+Fg/cGs8IlEW8CzPhNrxNKIOHNehqSqpshnoxuA4RMoQnxqf4ZYqpu6NuHtLQvWFtoeOQNNYXcTRv3UwWOXoKAKXqS6+vHRpugoTyRwOupLevbE34MoZSQUypySvy/TIyvoq7ZpsSL3rN0D5KDHBv8PvempN7yfXdY/TcVvSV4hMe3mN939Ial6NxVWGSiNXizxKnf/2/RBHIUR13+cDH/oEAINBzJ07Umc1poan3eA0zWlr6ibKC3Jd6vUQX0sWR4MR9UhS6uff/1OsK9nHaDqh0WjgzEb1TrNZi9Vat+Ma5YYFljv4ykHLNKU4kEDC7u4QH8gG7LQT/vNzcrh0Dxx+ayRpaZFluLqOx/0+feVYjfOUmk4stVtNRiNV1k1dIq07+jiVyrAbGqZKz/jFLOVT+pXPOu6x3M0pNuNAVmgvJknBzgZaHIZaLnCMy/q6BF3GLSsxxxvXb7DQlmvRqXe4fv01QPiun3zyMUDIYN64JiWw+sIiKHLg5s27bOsh+Y0Xv87hQIKQsO7hKvGM65lKCXoymRBEWusNAur1Bq57cF+/8XSHaXOb29zm9u+BPdKI1mDwvPD432cRLW4FLp6WJX1NIxKnybU7cnJtbjZYWDwWAXQDHT/0IiaOhPaOGdMfS/RWY4GLSpkWJTmJnv73BmNcT04h32nRcyTVsE9/mPrZmwAMtu9i9Dv8RDRqEGrHWFPPKIpINFXPbcHGplBKbp45W71+mhQYLRFMizFOORtGcIlnVIfWZ3lFos/LV56gfyRRQWwsVocaPOPgKxa202xVDbAgdKuoYJImBHVpUpw59wSlLjvrpKc8qX2zOSpISVFUNInGDcFVEcpahHNOfGzX1/E1Wsp3tqgF4tNfqLX53Fhef90tKz3QcDTiCR2q2cYlLWZNL5cZd3e9HuHrIE0JmFkmUEKhWNtXjMMbqsV3LjRY61OJYZ1WM5ZCBwo8POKJ3s847KtKwkJnAV/XVqMR0FMMeD1qU+QqvBiGDAaSLayvb3L5CRErPej1cWrS9D5z8Tzf+u63APjs7/0+3UN5Pk6HNFTNxWKIp5JFCDuq7FNpmpHrkEiz1aKzsFjhf9/K3nKjNcacB/4JsI60tn/LWvuPjDFLwL8ALgE3gV+x1h691fuVxUmSE72hjaVQFodRPoGG/OBasM7tbQHG377tkGmtpLZcp2zpFJSfM451qqTsstaUNC7IDM5Yte7ThLryy44Kw50thZgNwVG+1f6rr7FSk+cXFuswPFYbNT9EIeDd2oP0rTEGXzvVeZ5XNC5RGFYkLnle4iivrm9LKAWVsXXrdQaH4sMrjz+L31FlCiIcK5vCE0++h9vXBbGwn0xoaD17Ok1JU9ngszxkbV3+dml5oUIaJMYwinVTn0zJdb7fmIfLd/Bg1+4xNSLGPeZ8LTMqKpcTfAhmoY3TkbXoLSyQa0llMSlY1QBjL4hY1im5Nc/lrywK1OiN/gH/LJPrMRxNq9TV9/1jRn/Pw+pNnmYFV/Q6PR2u0pkpDjtW7qX4wfv4wa5dp6I3zCdFJZPkOC4jLREkecb2jhxcUQBnzwlywHd8pqoe/LWvfZO/+JnPANCot7m7I6XAe4eHHCoC6cV/89sV8ube7j55qj2FwKHRkLJmFB1PpGHdilYxiuqMU0E+FRh6gyH5ffYX7qd0kAN/11r7XuBjwN8xxrwX+E3g89baJ4DP67/P7e3Z3LcP1+b+fXg29+3bsLeMaK2128C2Ph4aY14BzgJ/Caq6+/8B/BHw937ke8GbCbTNscbVjBhuNJ0yLSVCCpptRttSInjjtQyjGNxG0mVB5YPCho/vyeu9AkrtLk5zh1tXJY3Y2x5i6hJd1PKMJWVVv7l7m2Ykr/fdLnsTwTp644Q68gFJ5kgk8VaOegf2IH1blgUnGbt8jawstprAFNUDHWrwSmIVvkvzKY0FLbM0GxWPATanVFHFxaU1nn3fBwD48sE24Sy6s4bBVFLVJ557Hx/5yIerz0qVH6J+8w2++bWvAfAHv/NP+YVf+isAPPbUs4yGw4dGqv4g/Ys5HrUFF8uJ76xpu/V8jEqnl46pnjebq3gqpLh/b4tDxcV+cHGZzzji97vTMWubskY/XO9wq3sTgC/YtNK+8l3vmNbTQqjUiz9VBPzyqkR4740aRNpAsuMBxs3eTML+gOyBrt2ihERRB3F8rNLhuZUyQn/QZ/niJQCSyZDJREuKq2vsHyi/xrTPjmar62su/+Jf/g4Atw53OOpJhDodx9QaStRecxmpOospfXpdFW1c73D+gvizezggOZDni6IkVGa7LMtJ0/zhKCwYYy4BHwC+BqyrswF2kBTiB/3NrwO/DtBudyq+AgwnNoYcV6df0sLgKbTCej6FBt3Xr/bwlbDjiac3yLW+6A8nhJ7Wd4xPqRNOvfGIg5tyAUzZpqUlhc3lGmu6WO9MrzEqpF772s6Emiq+Xg7aNENJjQs8KN1j/tGHZO/Wt+vrG8RK4uJ5XgX1StMUTzvknudVaqPGdajX5DB53/Mfo1RGnbJwjxEdjkMyY/E3Hk+/VzhAv/P1r1GfqbqaIVFHrtenf/GXK1hMlmWE6kPjerz2PUnX0mnMkXbj7ZPPcnt7lzR7+K3xd+vfC2HthGqFpVKv9TwI9Hd6xweyLQqcGZg9yyvGoshaPu4LAuOn22f5eEfm9O/c3WIyS/kbLc5MJI310pRCr2VeFExjWd9nYviMImZ+YeMs51QVw/UMNleFjKMa9A4eOsfnu/Wt5zpMZlN3JyIaa2313XcP9mkoF+xyp02zKWt6cWWJVlvKf69efZ3vfO8VAH72k+vV9er3BoyVF2LQH9AfyX4RBCGNpmycnWaTUktaW9t7eEqW3Wq3GSmpjBtCrsFhlpaUb6N/c99HnTGmCfwr4L+x1g5O/jcrR9AP/FRr7W9Zaz9srf3wrAYytzfbg/BtZ2HxEXzTn0x7EP5dDcIf9JL/4O1B+Nb9CVDqfbd2XxGtMcZHnPnPrLX/tz69a4zZtNZuG2M2gb23ep/SWhKdzzZQsfG7BlIFDo/zgpZyGvidFlbHcTtOg9svy0F549Xv8uRT8pqLa21W27KBN+shpUo8ZxNLUErkEAQtoqY8rtUiutcEVJ50R5QKQo/HCfWWRBcb566wpPLkcqgaPG+WNj5Ye1C+dV2XWm02IFCQ6Bij4zgnmgsOpiL7dnCQ18fjtDr9w9CrGJDKssTXyNUYSHJ57HpNlpW0/aB3i/e/X5jvm62ValzUCyImGn0tLKwTaumm3jD4GvUOpxMy6z7U6eYH5V9wMLPSgeMyc5INA8xsHLwosVrecrITygaOg9WO+YWz5/ivWhKZdRp1wpZkFUGR89s9KV29vL9LT99nuVFjoGDYtMj4oC/r8q8uXeb5NQkWm67BzmSwy6KKAs3Cktxce6d77QL4OkRky7LKUIu8IFUGtDzPuauNcd91qTe1uZ0UfPwDMkZ7+95dXrkmwo7v+9AH+IWfkxFzL/L5zkuvAkJB2dBR6tu371QsffVGnUKxvJPpiJs3JOtqdhp0Fpv6HT1296XBVmbgeD73OwxyP6gDA/xj4BVr7f964j/9DvCrwD/U///Xb/Ve1loS7VCfVARwHIdUN4NhmuPXBZicFYamL5HaR599jOGKpPmf++PP8SdfvgHAy52IhZbUcVv1CG+W3hUlQ60v5ufXWanJ+wTxkLu35YIN93u4dRVnW1/nycefBODc5gXcqabM1uK63n3DON6OPUjf6vsBsum6J/hMZ/PYqU61yIvB15vWc2uVwKtxiord3/O8quyQ53l1jYznVvCxztISH/iw1GUnaVLV13zfx+pB2mgv0VmQjTnwRfUYwAtcNjdWK7TEg7YH7V+rxCTGcWBG9IKLnU3J5SmojzihCIzjCiIBCNt1Vn0VB0xTyKR22KxFeBNdx4MhVzzZeL6SxUTKh/DL6xf5TzcEhH+51aacfe6kjxNIGcG6HkYPOzsZQhg9lNLBg/St47pE0XHJqVB1gyROaKuYaxRFZBo8vPr6S+wdyAH1qdVPcaCImVq9yVTLULfv3uNplV5637PPceGyTEF+5at/yrZSeY6Gk4qC0vN8smw2mZdV6/7w8IjWogRyg8GIkfaAXCckzaf33V+4n4j2E8DfAL5njPm2PvffI478v4wxvwbcAn7lvj5xbidt7tuHa3P/Pjyb+/Zt2P2gDr7MD4+Pf+5tfZoxeI6czr7jUmpH0TgefY10+9OEeE8i18yWrGkDrD+YsN+V572whp8rGbJf486RgIvZH2BmXUBbkNUkArn0ZIu66gSVyYBhJpGAu9phhgYP2zVaK5LSlU5GW9PbWljDdd3jTvwDtAfqW6Aoj4cs3FkDJc+rSNcPAqxS8aXphH5fIp9Wc4mRkh5P4gHLi5KSniyXJGlSiWZunF1jWTGifn1MUFPKQNKKAa3M0oqBqiwNaDTYXmhV0bDnOUQPUY/tQft3htiwxjsuC6QpzJpeZYHVhqQ1BpRi0pgcWzUVnQo7bNIpxUgA+Yt+k9+oSfRWbCxwXTkpcvo8dUbIqX959QxBTdZhmYGjqA5b5sf43SwVIn3AZkNMigpgPlh7oL61VOWtNE0JNYKv1d5MQ+joAIwB4orW83vc25I0f219BVd5N16/fotMMfu1Zuc40wp8hkMpJYdhCDqoc3Q0OC63GWi3dNTZC+gqNWKSJqD0lXEcg8nfjD75EfZIJ8PKoqSrFHlTCkZah8pKwz0VSdtPp1jddAPXsJvLj7/z2svYgaRZxuZYVzu0aUlNN8HYehS+ks3UAhY3BKKR+yHbB7JJr7VCFs5eAqCIDvF0Q1pZXuG1N64DsPrYM6xq7czxA1m4p1yd0QKpbrTxdFqhDrI8rw6JKIqqWyMpS3SegKNuj1evCQXi2pkFVpalVm2tT6/X1/cZYxV2t75xlmcVgfDyy6/wve/IpM1TzzxXpWKltZW8yt7ePsvLUlNrtZv0dKH7lHi1CPcnRGVhxi1gHFMpQ9i0wI4EamSyAke72IT+MfTHmkqOxrguRqe+bJjh6IZhx3u4niIN2gs8sSjX4De9i3hNKfE4ZYLVwQ/Hi7CO7vaNheO6rLXYhqxdgwOj7kOBdz1IK8uSQst8nU6nqpuOhsflF8dxaCu6oMyTitxl73CPe7vSuwler9E9kLLA2soSN28LvDNNs2poZ3F5jTXtL+zv7RNqk7PTWaDfl/0ljROVWIKCjLES22RlQUsFH1vtGmk6rQKat7LTfQXmNre5ze3fA3ukEW0U1Tj/pDScXtm7y15PTp80txxptOR6hpZ2IIs4IepIE2vjzAVW7UzuOmdoZgTiOQdHEiH1cIgVu7m0uc57n3wCgO2DETfvKpGvaXN2SebRk4MpDVdKBE3T5KAv38eGTdbPy4x/YBw8z69o606vWcoZbZ53LMg4Y5YHwWHOXuO7dbxQQtqXv/cNWsrAdW7zIhPlTHBxhKAdqNcbxFOZpGw0OhSlvO+Fi1f45otfB+CrX/4KL3zsBXn/wBfCdODO7VtsnNnU96lzd0s4E5LJFMeNfmL4JGZWxgnosADjGDuDJy02Mf7xOqlc77rV89Z1jxsotRAU322mQ6yWIErHx9VIywsCSuUBKIyHM5NqL3LKUKIrU2uBAu+tI6U4ADorENXAO91r1xhTNWo9zyPXZqy1tlrHeZ4zUK0vrMUqm7m1WdVc3TvsEulAwXAS4yiTmmcMB10pxdzb3uO4kFJw5qyUZYbDMblmz2VZkinaIWoGtHQ6ajge4HkzGlCXZnMZ17t3X7/xkW60zWaDT39c2PtfSGIGOjc8zTJSLSP0hz3ifMbG36CpC7FpfMx41hWMsUpXNsgmXN8RWEwfhx2dUe4sdFhRSNHNw5uc15D/uY0zPHdJNnv/I5+kphcyqNco9YZZabTZVLHCKPCJajXqtZkC6um0oigwWgswZV6lYkVZVkMKcEyfWfMaXH1DNshB7zrvu/QpAHxauN5MEue4G1yUKYdH4tvVlXWspne1ZpuPvvBxAG7dul1N8jSCRjW9s7O3z4VLl+RvV1dZ3pJUb/+wy5kzF+5bDuTHa0aEGAG6Q9DuM6ttnI6k/PYE9Seug5lNz52ghDVwPEnmWmyoMDE/rCYfndJWWpBlXuDozuB67vFAhHWO6SVPfm5WgqOTYa4jz5929xo5UABwfTKliKQ0BDrFWZqySv89x63qqRZLqDwSFktNFXSjMKjoQVvNkFIHnPI0wei2t7q5wnTGpZAkQn8JpPmkCqyKUSESsAAAIABJREFUElwlwmottLC+7lPjI5gG5MX9DdvMSwdzm9vc5vaQ7RHTJFoWdEBgfbFdnfjWGnx3Jo+dkekoXGYNzokGxCzkN8apUqiiLJjMcKI4ZMp0RJpWKdenLj2O0XTt0kKHtYaUI2phgK8NhSzLIFR8Z0lVDN8/OuRLf/BVBr3ug3fIA7Q8y6rvuLe3VwnZLSwucqhUc7YsqTeksdJcrzPWdDMMG9S0421Lcxx9mZS8mJEexwy06XPmfL0ajba2xNHU9MqVx6tIejqdViPB5y9cIqzL544mCecvCX0d1rK/t0/2CEZw37UZINfGjB/Apvwemsc4VXOC30CUFGfk67ZKJawpZxQfkOeYmW6ea0DTXlwPo9mAO+5VdIi2rGFmWF4MVqM6XA9qOnWZFVhF1ZAb+eLl6S7NGKC90NZ/8egrLtYpMpJEm96lxyzQNaWlmGW9YchIx3fTOGEwkDJiGkVVM/KoP6BRk0g3jzM8vV5HB0dV2cfzvIr7o9GMqkGd/iBmW1nAam1orqr/Q49knN132euRbrRxHHPjpqhL+r5fTSn5XlBBgVzHqWBFnndiUMA4FRen5/nMtl3HWpq6cgPfxVWhQMdQ3fR5kdM/kk0oyBI8o6BjLK+8LLPRf/RHf8Tlx4QF/4nHnyDRm393f5+jo271XqfVHGOYjmSRteqREHUAWTyhqZSGtajGTCvCq5dsXhQQ9+hwRNiQIZHc5FCKf8aTLlv3pJ567uzjPPvccwD4YR07q6OVkGvJwimLCu3geR4tnYB6zzPPVB37sixp6sbsuQ5OaStw+Kk2K1I9AES+/IOivGbqwziqmKzkSbNarLXHqb1DRXVoLceDD65T8doKDaMeZHFMqcGDWQ6w2oPAFlX5BgMmVH6QRl7Va411tJxxumsHnudQqsDlJMkq8YpGPaDQtTWKCwqllHRsUe0LWZ5Xh1ijFjEDYkxHIxz1T5amGOWaaDUiSp0AK21JrBzAhmMV6YWFTqV2IWekfG4yLWhkqiZiA/JkfN9TjfPSwdzmNre5PWR7xKGEZTQaVf92PIJ73CU3xlRFfs913wwBnKVZjlO9Pk3z6vRvNJsVea8xpkr/8zSleyjhf6MWMVUVhqIs2dkXfO3Cymo1s757eFSRPIeNBs8+/35qmnqcZnO9maBfSaZY5DLLK59keVlFn+NxH0ebCK2lZaYqV11SEGraNBxMQdGwvu8TqpCgtU6VumHL6rr4vl+lUp7nVRFCYU2VveB61aCKYxyCwK3KHKfZbF6ANk6cwKOaWAiDivcAWx7jPm1ZRbpgsRqmybCCPu8H1VADZYktZk0gC76sN7N6URQdQNK0GVOYS/V9bJpATUoZQtOoyARbYCfj478/pRZFIe95UrLJyTRhRwcQbJkxniiVZwZRIOvPcbyqGeZ5Hr761oUTKIWkYqFrRLUKm5sVeSXImCQFvj/jBzm+TxzHZTL73DwDT/52Y2GD4aH4HN/FpvwQypx/1x6tOKPjVF1sOG6GGmOOIS/GcIxfP7H4TtAqyhy5PPRdp0oRiixh2Jc0qyzL42arLYjCWW2rZDSQGlBpoaO1oeXlpeo7lNZWKXZpLa5TclxYO51mgWkiKZHjOKAQH993KTT1mcYxvi6aW9du09VJu/PnLvLGVYFulaWpgOHnzl1kTXDzsnlPT5DT6Oe6joOd1cuL4hjtUBQVTWLoB1UpI8/zSrUYaynL8n7X6o/VirKg0NpnOZ5ilF/DOMz0TkTxYLYwy7LqC9gTPMC2sMfDC76HnRHV2KziSbClxWqqazoLoBNRpFlFxESRH2/w0xhm9VrPw6pQI3mOmYw47dKivuuxoUMyeweHvO+ZZ+Xx4Q72UBBFxp2SaN3aWreaJDPGVENHGFuVZaLQx9PrstDqVHwfk2Ra1WVdz8fzZoGEx+Ki9G5GozFXrkhZLS2mTPS+CoI6h/vaq3EdQaHMSwdzm9vc5nY6zDxKsLgxZh8YA/en0ftobIX7+z4XrbWrD/vLvFM7pb6F+/PvqfYtgDFmCLz24/4ef8bma/fh2gNbu490owUwxnzDWvvhR/qhP8JO2/d5N3Yaf8tp/E7vxE7j7ziN3+md2mn8LQ/yO81LB3Ob29zm9pBtvtHObW5zm9tDth/HRvtbP4bP/FF22r7Pu7HT+FtO43d6J3Yaf8dp/E7v1E7jb3lg3+mR12jnNre5ze0/NJuXDuY2t7nN7SHbu9pojTGfMca8Zox5wxjzmw/qS81NbO7fh2dz3z48m/v2B5hVtc63+w8y8XYNeAwIgO8A7/0Rr/8MgkN8A/jNd/q57+Yf4DzwBeBl4CXgv9bn/wFwD/i2/vOLP47v9079O/ftfO2eFv/OfftDPuNdfLkXgM+d+Pe/D/z9B+H8h+jQTeCD+rgFvA68Vx363/44LvK79e/ctw/Pt3P/zn37oHz7jpthxpi/AnzGWvtf6r//DeCj1trf+AGvfQH4B/XI/3RTlWkdx7xJ2KwiHTnxfYxjKmKIsiyr/+T5bsX85phj/lT5e/m/0kIxm68v7fHjPCOYkVC4DqnSIeZFge/Onncp3sScbumPE6Zx/sjYT+7XvzPf+r776fqMR8JafGWmz7OMWk2IMxzXrRRSyyyvfqO15TEZR3F8CYqiwFX/B2FQsf5hnMr/ru8SKo9EkiTEsczcR1ENq6z2fujNqBfwAher7H7CR2HZu9dj0J2cOt/qf3sB+AeNRu3TKyui2OE4pvr9xhwTHBljcJSLwDmhdluWJaWdUSPaE3y/piLUMSfYkyyWGe+GLavNgJP3qrUWe0L1+MT3ragqHVdUGLa3D+n1ho/Ev+/EtzXffHqhrkrKZVl9f9dzcU/ck+aEr5yKEOX4/s+tQ6IcEbYsiHSdhb455gPmmJ6gLI8fy3VUfglsRWYl3ECzvz2+FsYYjDHsHvbpj6Zv6duHTipjjPl14O8B7cB3+Ws//14Aosij1ZYNwOARKp9mUeQVgUsY+NSUS3U6SUlTISxZXVtC6WuJQg/HPSH5qxpX07jgaCgMVkfjjN5A+C4P9/Y5vy6kKe1Wgzu7e/J8d8DakkzStRtNBn0hWbEUGFPyT3/vpQfqlwdhJ33rui4//VEh43DzjM0zQpazu32H55VHtra4hB8KQ9Fo/4hBT6YL83SMp4xd+8OSUpVvBt0RjUhe/9jFc6isE8ar4wZKLL7W4uJjogd2/dpV3nj9NgBPPPk0ZSib7ubjS/hLck1XLy1RNGWDn04nOGXJf/cfn0Zkz5v9G4Y+/9P/8DcBCEIPX4lhwiDE18UYhAFRXfwY+RG+atzFccIkkbWYF3nFDxv4AYFyLIdRWG3MeZGRqTpukiSVnlaZ5RWJd5ZlFYNVmqbV4RgEPrW63FeNVpNmu8Ov/hf/8wP3zbu1N+0LnsOv/bTce3GaVMRTC4sLLC3pvdru4KukjB+EhHUN2KyPVWKYvTzk9kAIdZJRjyeWxJ9PrYeUuZKD45HqdhEnBbly3AZRA0/f33EKfF+Z5xKXyUT8n9uEXEmTXM8jCAL+zv/yf97X7303G+09pLYxs3P63JvMWvtbxpgu8Jla6P1ao6Gic55hY10Ye4bjmHjGPHWCjas0Fl+Zi2LKavF5gU+kkbGxOWV5MvpUGWhbEviy6daigLGK6bm+TxDKzdBo1agN5aLG23tMVZRwbXkVX//28HAPy4+FZu4t/XvSt2EQ/NpyewMA36a0QvHD2aefYrkpBNzjqctMgGL57CabF2RxZ+mAfCL0lR+pdQiM3KgBdcpC/NyNDYcD8cOtuzvgyp3dG+4xzCf6WR1e+MgzAFx56gqOCtnVFnxi3SDubh1Qz2XZLS+uk+YTHDNTJXhk9rbXbqtZ/zV3FjoVJaXSR1ovoB5JpNvuLFKri5CfzaeM+nKIZ3mMVWpEz3UJVI/K8/3q5vZdn6IiBD9ez57nVVFUYaFU1qpKyly+5wlier8K04xjMeZEEPJo7O3vC775tWJGqVmWQuYNjMeTKgDz3BBPtezqGIzuXKa0FIX4c1IAoVyLLCu5tXcTgAuLKzRCjYy9kLYypk2mKTsHQvCdlpD7Gq16BvSe96DaRygdSvVz6HmEgXOCafBH27vZaL8OPGGMuYw48j8D/uoPee094LxxHIwuLNczzJjL/dAjyWWjrdfrlYyEwRIrr2peliyvyOkW+C62mKlglpUgoOOY6mR3jCUKlL7ODxhrNOwFQcV2nyZplYLUooBMVTBH0xF+cEx9NxgMqtLDI7T79e894Lzr+viBcJJGHsSJcO6WWU6oC6sWtOiNxEHX9wcsrMhm0Vls0tON9lxngcmR7Ma7w0M0KGOURUR1ORgbrZD9feH3Xbt0jlZToud0bLF6M9z4/jbTQ8kiugeH9Kai/rB1GPO3/vZfk8+NIg4GB8w4bx+hve21C5ZSb5d61GZjXfhTz5w5y+Ki3Nz1ehPXkY1hNDxke1aCsTmlStAUeVapBpRFcUJBBMpCOYTz9E3ctLOb2eJgte7iex7eTIbF95htVJ7n4Wsg4Xl+VYJ4hPb2fWuPpX4c4xzzGBdFJXOUJCkzReY4TimZbXh1PJXH8pwQk2uQZh1ubElW6udjPvw+UcRebbdxdbNs1ANaLfncg6MRvUM5GDvLHZYXJTix05zRSLhp8aDdlIi5VgtxPU6UMH60veON1lqbG2N+A/gccqf879baH5Zffx144p1+1n+I9jb8O/ft27T52n14NvftD7Z3VaO11n4W+Ox9vC43xvyGxfyuq1r0tszY2ZOw3YvKit0cSko7O9FKXNUPW91YrJjis+kQV09z43pVWgZORfzrmEokgTLLqddnRM0Oe6qqkEwixomcVguLLWqBRCO5zSpy/AxDc2EFx7vzdt3zru1+/Fv51jq/mxUzv6VsbEj0eeP1q+SZ+Ha9XQMrfnDzJt098cN4UhIoe/2kbNMdiZjjve0u4ZL4f5gO6N65AUh0MehJBHxUDOm/KNFqSU69LhnLvXu3cMuZVplh4wn53L/2t/4Wa2ckvR5MD/nCv/4yw96x6sajsre7dh3X+90nn/wgABfOXWF1RerSYeAxSzOtTbGp/JZGGHL5stTMjeNTzNL/ImU0FuL5Xu+QOFExwXxKnMrzeZJCcZLMWt+/yLF6D/iuwdEo2TNOVdw6qblXlBDHWXVPPCp7+/sCvztrFmKOm3uO4+JpNmaMQ1HMfFiQa1868h1KJWQ/OOhzmEpWOhmPuLMnWd1rr+8xysSfLzz/HqZjuUZJDr2xZMY7h8NKZLS+ZIhU+WI4GFU6cFGtRjAjDTc5Ni+5X+bvR6awYK397Jn1JVzdzMgdRvqD19odmq01APYOh4zGsvkZY/G0PpLblGIijou8oqrdBrU6nj+ry1rSTMN8PJJMnu8NYghU770WYjJtKJRlJYNRUlLoco2zKbk2LwDOn72A75++ZtjMrLWf7bQXOOpLOr+8UOfi42cAuHH7VQZ6MzeyNlqhoTeJKR35jQfdmOFQ0vwP/crHGfvy+mTYJ9EF7ax1OJiIxMj21gHxRJUU7kGuC71ZCzm3KdexmBQkM7b7xYBP/LywzT313BoHY2HN/9K//TJf+pd/wujo0W+0b8estZ99/rn38pHnXgDAc3zItUESjymtiidSYLSk5foRnq51W2T4qUqjpGPcoaS0S5HLUCVr7u0cMFIFgSKd4qrvPNfHVchGQUbpqsqFCSol4rwoq3KB67rVRpVlmSAeykdePrhvs9Z+dqPtkc+UkA3YN2XjuulS4FUSVxD4M5UEj5v3ZN2/dnOP5ob4yrMFrpYpe4nLv/nDbwHwta+/RLOpAotBRHtZ1uv6+SuVIkMBTLXRmOV51bD0XFuVa8oipyiK+z7E5iO4c5vb3Ob2kO3RijPakno4A7dF4Eh32w/bjGI5ffrTgoFGS6VNMFZOlmvXtzCZRGBPXT5bnWhRkRNpMTyIfEo9DUeTjP2uREppXuAGKjGcJ9RrcqLVfI9SJaTHkzGpdnsdL+CMnnR5mhN6p19A0NqUOJGUv9ebsNvdBiD3M7b3JBJNJgYH+e3d3iGlKz6J05xLl54GYHn5PK9+/esAmCJnoOlXrWW5cEHKEZPhmL42DrLSpTkry5QFTV/eP3IDelrKWDq3xqWnLgDw8kvf50tfEsn5b33+m+QHBnsSNHJKzfcCvESj+CzGKNLCkGNUnj3PU0rFJvthHVxZr8aAW2iWlk2JNK047O6Tq0Bm0/XpJ4r1zspjqezCcNiXdTwaj2loNNbpRMd6V4FX6bMBlT6WtVaabad76WIwFSbYuCdwyY7BdcTngZcTKHLA83MCrQuO4oSXbkgJbLeX4C5oEzgp6GjjKl5ZYVfLZNcOE6IjySia7Yjnzl0EYGltjTLVbIQRk4lcO8fzK7x/WWak+bE+njHmvtXYHulGa6wFTe39wGFjVW7c3X7ONBMHjeKCVH9w4LukerPuH8WVOFvUnFZaiXk2JNE0v9Gos74hkKXRZMhAa2FLS4tksXxuFHmkinFqRU2MlgsKP2exvSyfGzostKWDn2WWND0Jcz6dFtZ8vEh+y2A4YGdfNsLCtez1ZAPuFgma5VKWWYVXTBN4/ukPAZCMHeKB1lzTMVPFH64269SWFCY2zCpw99bdbQq9ppk1kMv1WolCPvB+2bzXn7nAyy9uAfCNL3+L21fl9V7iExq/UjE+1VYUFJOBPswwWgqgzChKcep0OjlWds5LVGCVLC+ZTPXQT6dY9IYuDb074pfCd2EqvjvY7+G6qkTcT3jjDekPTCYFkeJHN860eeET75fPcm0F8geqxwZRlDanPEgwhuOBgrKsDgbHcSpUhuO6x7BPXEaJvOh7V2/y+m1d61GDbl/7PmWE4wT6tw6dZUHGuJ6Hrz2gTrteDfNMx0Maioduhy6elWvkeS4ai5HnOa6iPsqilO82F2ec29zmNrfTYY80orXGYPWkHsUjBipf3Y09Ui0R5FlJoalVYSHL5cjoLK5RSrOa7aMY1z3GwqazYYfhkN2hvGeWp6Ddwr3DHRQWy5mN5apzm2ZTfOT1mxsLXHhMsJG+gZ1tSb39IMJ33TdFDKfRptOY0Viiz8CrceHyYwBsXr7AnRu/B0D/cMTwSLIC3w2JdOr10tkrLHUkmv/Tb34Jd0lwoc89/7PsDiQaHhUpUVOQCcubq6RWPmuhadm9K+9ZFj7tumQCn3j6aeoL8j7fu7PN7nclu0gPAlqeXGvrFaTx+Mc1EPK2zJYFaSINwyxPKJJJ9fwMF5vECf4seMwmHOnk3RvbPW5tyePDoz0w8vozZzY5OJQ0djAZM4nFp3d399AlzWQSY7UeVq832b4jjcQ0n/Lxj+uwg0clZ24Mx1EgPsZxfyIyhhketbCWQkPIPM/J8tm9Ws6GPskyuHsg2cWLr99DlzR5NqTQIZlm1MZzxT/WWjJt2DZaNVY6IitubFFlxntbd2lpGefZZzeozeDN1lRYXgxE4Qzjb970vd/KHu1Gi4MNpW7iRXD7toT5pdvAmcnb25xSO7dZbpn9RmtNNTRgHRdXf7DvWkwgXplOp4y0jGAImdEVTMfDaqON4z4LHXHo5csbLDZV+73dwHHkD5aX16oO5LXrdznqTSod+dNqk3HG9Tckhbp0/ky1cV547CKf+50vABDXSuJDWXBJaVhZkwGe5TNn+co3vgKAV0uoXZGU9OlP/gw/95gsyt/+V/+SwwMRgT2zvlbVAaeuh9G0uIgd6jps4gYRt7dlU7h+/SqzmWnft2w+VtPXwDR1eGXrkQ8svH2zJUmssKA0JlYInLEWV2ulZV4w1bJUL0/5k+++CsCXv38do8Mko3GfXMsxzndfoRaKLxYXFzl37iwAKzbixm0pKQwnabX2JmlKQ8drNzbPs73VBeCFFz5QbeqT6bBKZ/0owDGnv3SAAUe7+WmSY/X7xknMRKc1rTXUdGIxczxuH8jzvdiQ6kFS5CULHSkR2HJEvaYogsJjanXU2YRk2uuxRU5PXMiw36ele8TkUpOaMxuTdquyRhQGFergJAfF/djpP+rmNre5ze0n3B4x6sCSaxPh8uNr3L0px4njWALFxQ57Q/KpvKYeRgoIh3Q0YjZFsLm8jNEwf5q5jEaSO8SxqQrmgReSnzhGSm1tj9KyGg29s3PE49pQ8ExBomwT3X7MtetCjnLtjVvE04xsxqhyas0wGuro7G6P737rZQAeu3yFTkdqLklW8vyHhNTn3No54pH4pN+7Rz0Q3O3S2pNc3ZOT+kLf5XIhY8/h4nMEY4mayqxHWYpz22ubjA6lWVN3A3qKjf6dP/wDSs31gkaEo6ntTm+fxUKymuZSi7DVrhjFTrMVZUE8kfLHNJ6ArmNbFiRTHQE3DqOJlEW+efU239+SjM1fXKWvTZrC9eiPdAAhz1hbkfQ2qNWYaDQ8TRJ6PSkplGVZIQqiKODsWeGzuHPnHtOR+Prn/9zPQ2vGylYymsjfpmaKcdwfxxju2zJDxbNDaW01Rp9mGdmMxKUAV4c4usMp24ooGiQFg4ncz4sLbdaWpRm+trYJytPxxuvbNJVIanGpxf6RZFrxNKNM5B44OhqQKVHSKM5pKpuY45QVg6BjbcU1Ye2sAXnKBhZA+Af8XBzU2x7h5bJYSwIyrdcm4z55LM6thzUWWpouJMOqdtOKhBwGYDIe4+hNH3k1dIiGLJkSKvNXEEX0hnKTOJ7HeCwO/fq3rtOqSx3x8Utn2d+XBbqz8xI723fljUrDQqPFacfI+J7L+TOSepoiZ++OQLomwwlra4LuOOh1WV6WOutTj53hlnazL62cZXdXNoJ/+7nfw1mQcsHyX/4Yt3Vq6+U7h9h9ORhr6R6+lfeZFilOW67F9hs7ROpz02nQ25bXb7Yj2srU1hu4pD1BO9ze69KNDxkPZ0Mmp9fKImc6Fh8laULoy+/McksSazkmjfnudeFP+fy3XmHxrEDa/vwnP8b16wJpu3r1GkksgcHO0RHLy1Liscbjxi1Zc57nV5OSZVlUZEe+53L92jV5bBwWGnKdrl/d4txZ2WCatQ6Z1pIHowGO757qgQUQ+sGKdhJT7bqu61UUhVlusQqv2z0YMdYidtio0dKhIweHoW7ANSekeyB9lsj1WFiS15w9VyNU4pkbN/YY9ATtlKRFNRl6OIhZWRLfppmtNto8T6sZVNf1eDsVmXnpYG5zm9vcHrI90ojW91382QzxJMXTufhJZgkUn9byPRI9QY66Aw52pCnQWlkl147ZjRs7nD8rAwUN35LrSG3qHNOYJUlOZmcEwiVGGaI8x61S2mkW8Nnf/wYAq0sv01Iu0U4zqJi/PMdnsd2pxv9Oq0W+x0ZdoqCFxSYtjbjSacLahqRNr1+zFIpR/tNvfp2lxjoA/aMhmTIUtbKY6zek7PDlr36HQNzM67ev4W1JVPbc8jItzTQmUYnVaCE9H3Lh7DkARkPh+AWotwJQuj4vqGF0ft31LB/7+Hs4/O3vPgyXPFAri5zRkZROiihgqrRm/WHC4ZH8zt2DLt967ToA270RWSDNyT/8/d/j4nnhRsgno4qS0neOO9p7+4cVWqCzsFgR0u9sb1fZqbWWqSIT3FqLV68K98Tvf/6P+NW//p8A0IjqTJW2cRhPSZOkIh0/tWapeKSNEewvQBjVMYpSssZhrKW93cGUQreuxU6zwt0ba/GV5+Fw64Brr0sz8sKFswz6is2PPFZWJPMbDAx7+3K9jONhFHd77fY+Lc3MFmpeVdZ0fcgqVxZgZPz5fuyRbrRB4LGiwOHRJGYylXrWtJ/i+AKGXzt3geFAUrRaWHJwID8ksQF+Qzq3B90xbMl884Vzy8RKjYbrMNYaYWgCstmYGKZSBxgPJsRThSOVJU0lwr5974B2Xd5n5dmLrKxJ6uBYhysXLhCG33zg/niQZm1JqF1Wa2yFvuhPRrQXJD01ZY3pWOuy/QOO9mSDWG6c4amLQoBy9kzBJfXVzmtd9r7zbQAWwoCkJymyfzYgVpRIUhiamsIOwiF7+1L/Wl1a5eknpWTRiurs7CthSlnQWpVF/8k//+donK/xh5+/9hA88mDN5gUT3VCnSx26Q9lEv/GdV9gbiK/PXLyC15JNbr2wtFpSi+4edrl3Q8o0SZywtCwHX55TKVLU6jmhEvt4flARsU8mU8aDoX6JJZZ0yOfmjbsMB7KOB1/8Auvr8lk//8mPstiWMkJeQre/V0GRTqtZK/yxgGyaSuSf9kbUazN605I9LaFsdyekpaT5WTamsyB7x/LyEtZR0YCoxvqa+GF/d5ee8lFbb5H2orz/4eERffXtQmexIpK6t3tEpEiSM0sNVEAE4/pkhdxjxkiJI0nnXAdzm9vc5nYq7JFGtJ7rcGFDTvz+0MErpWgfT44YF3KyNxfOcXFNuuT7t7YYTiRFHScxKDO947mk2hibTgt2diWl86IabR2dHY/H2HRGX1dWgG5J1eSx61hKzcs8P2I0kfR5MEr4yIefAiDyXC5sXiJU3O5pNdfzyIyc2p4N2VGJntt7O4QNucxRBNNYTvCgHjA8lCjzyvKzfOwTPwfAV//0aySHci2GvazyG806k4E8nsRTpjN/Ogk1xRYuLa6wc08iWs93+cwvfQqAl759nZduSQnIXarxc3/5lwBoryxyc3+LojjdERdI9jNQSr17w11eUlTK3d0DaopZ3t7aonso+FrPc9nelmuwsrxEqiPgrSji4mMyTGJv3aHbl+uRJin1msqwJHFFFWqtrSg+a7Va1dgKw4iioex0/TF/8pUXATi3uMiVC4JMWGo1iKf1qplzWs1aS6xsWUlW4mgZMU5i9GmcwHCopPVpanAUO+94PgtL4v/FpUVSpUk8s/44jz0pah+vv/Z9LsyabX5ArAiiwXBIsyn7RWnLqgSRhS4TrREk1q0yY6c0s2Abgw4r3GdV5pFutK5jWGorXaEHrVAWQJLlvLatRBjGVKnASnR3itr2AAAgAElEQVSR4UBhHNs7M6ZDnGwwG6knTlsEKndxNBxVIoBR5NPQ1O2oO6DUabPAc0GlU9I8ragabV7iaT3o9t0eOzuyCT375GXS+E2akafSPM8FpdC7de8uQ4Vf7Pe6bGgH+/yVJjt3VCfM+vzM858A4Nzis/z2Z/8fAL767W/g12UjWNr4CMtrUs+Kp/tkWqKZ9nuM1VfuoqFQfxrqzMb3xuMlvvxVQXH0ui2Wz/20fNbT5xnnUj569f/b5mBvRDw+3V1xkKP5tq7F79zZZn84491YoNQ63VF3t4K9jUcxOzty6PR7fRoNyT+vPH6FXA/68xcvUN4WlMJoNKoWWa1ep6llsnq9jqO8gSurK/QG4tOiyDl3Vq7NsD/g3q5s8K/d3GJzVa7BQqvNQmOxolk8rWaOgQbgeMRKb1rgYk2ojyOmyh1dFIZ6Tda0H/gVpHNpeYWxBktl0KLQ6dEPfvzPM+rLur918zq1hgRvw+GY2prsEaPRhFTRI8YPGaeKgsLB1/XtOgZHiZjKsqAwTiVA+lZ2uo+6uc1tbnP798Ae8QiuodmWRkCztcB4LM2FzVHM1qFgLhcjh8GRNLpCC49fFiB9mvR5/AnpaN+teezvK0uP74kOGOC4Mb2+lCPqkc/CgpxEC502iXZrJ+Mps9JBnhXEClh2jVuVEbr9mDt35DtsLi3QKzPS9HSP4Fqn5In3ScpY3N7lMcXOlk6fbk98YuolF55f1r9o8LM/+2kAvv2177NnhRh55bJlMpTyTqPxJBvrzwOwff0rdFQQs1kGWCTr6PYm9HWWoyhcjCfR8N6ggdWUdXFplUVtOuZ9ePGelBHKxKGM29jidCM6AHLglV1ZE2/sdvEV1bG42qF3JGs3CAKMRmDj8bTSxFtdXafREt/1B0POnZOIftAfVaWApaWl6nGtXqPfl3tjaXGRKJi954R2S/72IOxxqGWKxy+d4UibOtcOupzZkec/sLJOo9asaP5Os/lKgWgKSJWZq8RSU4RKXBj0VsV1feqapYVRhNVmX5LlBJEKi9bahMpON03HDBWnv7i8Vg2ATKYxvZ4ysuV5hc5IspxJMis1HmOmHeOBkfcsbaGjzaeQ6yBOMu4qML4RhfjKI5flJb7Of4fJgFRp5G7vdOm0ZGM4d+kS6IJpLi4R69hXlqcVTWIUNaqSSZ7GHKnCZbPdZGFBazFFQm+gtH5JWcmBFDbHKsNE5Pusrcvn1uou1167XtV+TqtZLMuXxZ8/8/yzdFTI8nCny/hQyWaMz/lN4d/062vsqn+chqWxKv681405c+k9ADz19MewurBcM6xE8F7rGkrN9YqgTqstMLGFxRWmsR5iwOxAS/OkSn+n8ZRcKejy1OA73mmfBQFgmhXcUyWIZJpVgn1lXlTijEtLy0xVmnp7O2NxUVL4x648zn5XNumtrbs02/L8aDzGaHf76Wef4ebNG/ppllokt+bAsXR07d7b6tP2ZaONwpDekQyl4KzS6WgKPJ7w7dcExdFuN3nmPU9VlJan2VxVUrGOwfFnZDAZVLBKX9lzwMWrBFYbrRazQuntO/dotSQAaHU2WV0TSN1oeMRkJKXA5fYaXeVSjuO4kmyfTKdV6TArcoqZCst0gDMTlHU8KGW/sHkhn3qfwyCn/wrMbW5zm9tPuL1lRGuMOQ/8E2AdOTp+y1r7j4wxS8C/AC4BN4FfsdYe/aj3iuOEL35J2Pt93+PsWYmEDro9HG3nZcmAGdVWVIuYnVbtdpO+znbf3j4g1sgp9JxqTM/1HRxnpgEGM+r+JMtnhyHr68vkmhbYMqfQqCtOsypFO7vS5PymRLSjYZ+9o11yZRR7kPYgfZukJYNUTtu912/zcSVAn8YDRgM5tc3UEGRy4h9uTei5NwFYXKmz35MTf7ubsKa6S7VOhAZoTCdDjm5qc8d3cetyRi+1mkyV+DpngjfTYCtLAk3dLAUDZbva3rpL0JyVeuqM8py8eDhlmQfp3zTPOdQRbRePTWXa2t7e5vx5KWm5rqv0nOD5hmfeK7wSo/GQGzcEpbCxucqSjt32Bj2WlmZS5SFHWoLwjKXVEN/1e4cYzQ9Gw26FQ3/2mSu88DHh6YhqLldfk2h4Oo7ZVcTJ1WvXOX92g6J88DSUD9K3QFU2mUxzinKGB89JFSEQ45Hra0pTVK8PgpBSaSqn06Ri1Hrj6mv0hlJOabfaNFuC9Q5Cw2FXvs5wNKqYzYIgxFHGvtIWFYNgMu4zndFUBmBKHY4oS/nb8v4y3fspHeTA37XWfssY0wK+aYz5feBvAp+31v5DY8xvAr8J/L0f9UbWWjKFUAyGI/pD2TjrzZBAO4GDZIyPbHiNWkCqUzSTPKPdlEW5sbHG1euSNqWjjFi7haQZzbZsJO1Oi0RJOgaTAUc607y5vEhbIR1JPmCqJBHtZoNAu4v/P3tvFiNZet13/r67xpoZGblvtVdXVe9qdpOUuEgyaUn0eEaSZciyBoZmTI0wD/aMAA9gwy/jh8FY8ADGeDyABRoyoNUWZWm0UjZtukWRlJpsdjfZW3XXvmVV7kvsN+7yzcM5cTOr3WJnsTOLSTsO0J1RkTdv3Dj3u+c7y//8zzMXTlLWUObi9TVur6zlnToHLAemW9dxWJiV3vrttW3Wr8pD21qO2FmTMHdrY5NKTVq9tpsdOrHkbu+s+sQazj/x2CLlUHNV7S6OJwv05Mxz/He1mwD84Zt/wMvbusC8OQIdN+L3XCpKBxgnGY22VOaTqEPS0/77nQ1sU1NAI5N0kj5pemh8tAemXwBXcxwTMzOMjonBS5IkZ+m31tLWAaLj4zVOnxF+4xe//nV6yj8AdWpjiqpp1FjWfPWr32iT9EVf3babj22amRhndFTW/WPnT1FWA1wul/NNrdVt5xSiG5sbqL1gdbrO9SuX8/rEAcuB2gUU4ufbjGIg38VxfXqKFtppN7COpEescUlVP73mDqGmtGYnJygU5JiVzSYb2jyTxV20uYtrW+vE2mE2Nb1ApIa8027TUnuUJRlWz7lw8ixnZ+V+VUJLMpi7ZAxBUKT0/N19Kes9UwfW2nvWSqXEWtsELgLzwI8Cv6yH/TLwY/v6xKHkMtTt4cpQv4cnQ90+mDxQMcwYcwL4HuCrwLS19p7+ahkJIb6luI5hvKYD0/oehbICtOM47xnudjr0lVS6NjZBz9kNEVZ1qNqd5SZtnSZQdApUS7LjWCfDcwZYxJCCViY7/R4gYfXaWpOwIK8LpZDutu5QScqp0/IVHj23yN0VwTdeWVqn08vY51Thb1ver25tmrJ6RXZXE3X52p+/AECvacm6OtWi2aVzTPT2yCOLXLojRRPjl3jmKRkHvr7ZHIx1Y7vdhqJ4U7PzT/B4U3Ty+Yt/wsioeFbnjp3FaoQQt7s0BvR+aZ+7Kzf1dUqgPeg2S/MCkOtA6HsPhZj6/erXOA4jZVlnYbGAr+xx9bGxHC9bLBbwdcRCpVKm05WKdm1shB/4gY8BsHhsnqpiyUsFn1Oadmg0moxr8czFUlYkTZqmOU7UNy5dpQRdubtMuyVect/GdBQ/WiqVOXZckDqFcpVuu0l2CKmDvfK+164Fq1wkxWKRoCDrCTdgWxEz7V5COvB0PUsWD5pqNoh12Go59NlRitUsM6wvSwEyidpUK4NmkC6hRquu4+MMyudZgW5bPitJUzQY5s69VYpW2/pthyjejQ4cx6HX3R/z3L4NrTGmAvw28PPW2sbeh8Naa40x72qKjDE/B/wcQH2kADqyxnNS0ljHqnhhXv2L+1HOWL+9vc3Kmn7JYoVGS75kcyfCZAPWc4+gOJiC63LmEYEXXb52HRyFZSAUaiC943iDnK7B1+9R9AznzyiUrN/i3oZU5K/d3WRhso7jrO1XVQ8sB6HbMAz4xstiOAu1DhNKJDN+eoErr2iffTtj9Z4Aty88eY7nnvswAM1mn2uX5G+73YjGthjsOL1F6st92TZNFiZFP72xj2F6YnSXN7dhSxZot71DtynGJel3SeJB/sqCdta5rkOokJ2435O82yHT+B2EfiuVEgVtendch1jXX7vbY3l5Vc+VcebM8fz1+LikXR5//FGM1g76ccSGIhBslgyANCT9Hq5eRhxFNBVJExYKBMFgOoWHrwZpLdog1q6dxJDztrY6nRy0XyoUWNvM9k188u3IQei2HJDDr5Y3IzIdbRThsd0Tp6uTebhqO6q+j03kdbvRI+qIfpJeJ4d3dXFzeslNG+EaeR4Cz8FqHr2fpLQG6zVJCDW/EDvkA1yvXbtBtCb6K5k2qY7EcV0Hz3foR/tLy+wLdWCM8RFl/rq19nf07RVjzKz+fhZYfbe/tdZ+xlr7rLX22YpO8BzKrhyUbn3vaHf/fKfkoPRbKITvdsh/1XJQui16hx/RfKdlP6gDA/wScNFa+0/3/Or3gZ8BfkF//t57n8vJMX1hwaOvu3Dcj2Q2D3BsYZ5Yd+Dl1S3aTdnRNrcauMpuNFKu45SUHNx38AYohXIhJz12TUaq/AnV0MdousA3GcbTWfG+S1CTHfD44jQNZQ178c5VlpTZylqP2dkZfP/Ge329B5aD1G1YKlGbFNzg7LzD4gmJ2EKnxtpt+S7tLKLvqIfQjbirnlVzq8POihxz99YSWqwlPD6H44oXe3HpZaa+/zkAnn36r7L9578FwOr2VWxL9JzZhL7mHdI4wzOKe/QcMq3W+n5IwZdQL2p3iLLo0ELbg9SvzTJ6Ohvt3vVN+kqTGPcTQk2L+IFPsyHf88zZY8Tqdb3wwhdx1BOtlCv46qEGhRBt68cPPbJUvCXHBniamqhUKnnRCzfB01RadaxCoCmIza0mqYa3rW6HNeWwcDLDnRtN2p2Dx4AfqG6BruJWN3Ziulp47jke2YBg3VqKnnz3tB/laKE0SUgc9VB7HQpKFepWRwlDbRnvtNjRlKK/Z9x4kvRpaGNIr9vNW/l93yNVT9p4LoHyKhS8kFRf+6FHGLo47s6+9LUfN+gjwN8CXjPGfEPf+4eIIj9rjPk0cBP4yfc8kzF0lejFpJaikmWMFAsUlVDDOB4dpY6L+gmakmKrkeFr3spmEVksCysIQ2ZnpQvK8XxW1yQ0Hhut0lUaxuOTs3SU06Db7xIM2OvjiHAwkLFe523l99xYabK+LsfXxmtUSqXD6q45MN0mSUIaySKINxyaZTF4UYE8jdDz+4RaIb969QbFqiys1178BrVQdDhVnmL1lnB0JuOvU6/qdNWNy7z9gkC0uvXzBEZujNvazqu1+Ia+Qr2C0OT8EmniEYRj+jrFxkp9Z1x6aQ84tND2wPTruS6xjq/ZWl5jXBEeYbGA1Tzf3MIsng71a7abRDdlx/J9l7G63IOajhUCyfENprOmhR7OIBXgxPnU5TjqksYK5vctqSufVa+PsZ53NVlQwx/6ZdZWBHEyUigIt+vhOIwHpluDwej3dX1DoBSRmQnoKKoyTlKMhumeyXAHDTNpRqkk69jzPFzd9CrlMqmmpOJOh0SNd7/XA12X3W6HruZY0yTJiaqqI6M5TNQA9XG5Z9M1D5BrS9KUzCa47v5Siu9paK21X+YvvlWf2NenDOVdZajbw5Whfg9Phrp9MHnI7F0uqYZQrUabUSWkHqvVqCr+dXl5Lfc+y8WAYwuym/hrnTz53+u0sJ6kCCpln15XvNhCcZRCIDvjTnMr97SCuINjZLcKfUgVr+i7LrMzcv6tnSY7SoPX6rgUPPH8pkbLtFvtIz93KU1i3K5c/0azSzuSkObk+TOsqIfTaDWZKQ7aOe/y+JNCBTkzN0Wic9QarR3irhZrtq7T1uprp32HjXtSTF5v3KKjgwqTTisvXiRxTKh5+B/6Kx+mOioeyMtff531e3IvPGaJ0kH6CAp75kUdZXGMoV4T7OzOxjZt5RnoY6nUBJkxMTVGRavbnudw7Pii/q3NW0DTPbx6rVaTSEO2qNPFasrMyTJSLdjEcZyjMpLQYUwLbKOjo2w15RmwaYKCHSj6Llurcv9uXI+YnKjn7GJHWZRoC993kNQvZJlLW4vkZg99eZqmdJV7JCwUKSgaxA8CggHvifFJNHWYpRBqusorumxvaWTWi+l0B8Utl1TRTk67RUHbcbOUPNqemxnJC2bGOJI2CvZnQh+qoS2VyzzxtJCUXH7jTWo5LKPIjsI4Ot0EtBMjcDz6Wt0tuwlhWZEDno/vyKKvljysGlHP6eAV9KGPOiT+wHB28qYGPzT59IGRap1IKdnu3l3junY+jZdcHr0guUk3NCyvrRInR5tUxjWGpg6jG58czakgG40egwG+s/UFxsoSwm6ZJvduC7pgcnqcb+rU3GarR0kX5ZznY41OFeiuEilNYrG/S4bSw5Jp/ivLsjxE8wKX7//UhwB46iMLfONFSUf86Rdu0R4MDMiKuFkxH2NylMXzXJ55+kkAzi2e4qU33gZgo93KmxfWNlYJypInL5freJrzq1bKOBryb29v5VCsTqNJpHy0aT/Bqu7iuEeS7lazywPKxOJInq/t9XokuiZLRZeyDhxsNjqEnuTnNze3cb4LdjGDxbU67dZYXHWWktTPUUqu4+C6g+kGbk5baq2lo+G/t5cYpp/kEDzPdUnVjnjGyZ8Nx/PzdKTv7U4L7na7ZJpSLJYD7up0kPHRkJpOYXGBLE6wQ66DoQxlKEM5GvJwx417Ph/6gb8EwMTEODfeluFpO60uGvXS7MS5VxQ4Ka6GpfVRn7ExKWL1+z7jY9ovvrlFS4Hb2AQFLzA7OUYhlPcdp0C3K+dpd3oY3Rl7Ucz1a5flc5sdClpRrFRdwqLsgJ1el6Tf2/fO9Z0Sm1l8nUXvFRJOnpKw9c7qBoWyVG5HJsYZqYpHWy92uHNNvMxTHz1LxZfmAutWKVVF/zOlal79ptempfwSWRLl7zukuwWdNMGoR/GlP3mN048+AsD5p8/woU+KxzUyN8qX/uNrACy9vYMbjR794YFII8DHPiZNBxv3VnB1qsRLFy/R15RW1Ohw7U3R6bGTGeMT0u7sBw6RomF63S59rWgnsc0bbzrtDjvKNxGEDlUdzz4xOUlVqRFt2qOhkJAoauJqu6/b3KKiIP9K6PHM930AgNrkHMa4vPz6pUPRyUGKp895MYRErVIaOwyyHpkLaONGmjkMgKI27tNNB4gWj1QLlq7jUFIEQuj5JMq+1+9HeSQQeB4oZt93DJ4iHLoGMi3aJ5nh9qqkd7xCi7m63JfQpPgmI0n3t3YfqqHd3mlyR4cqTs3N89KLQjDT63dYPCX5wnLqcemtNwAYKfgU1XCWym5OqBHHEUXtRd5ct7vAbZvievL+9Ph4Hoo12lt5Z1IrjimX5KHfvrfCzrbkL11HunkAwkqYd5g4GdRHanju0mGo5MDE8Q3FRcklOYGlPKKz7tf7+LrgdqIOdeWprU9VuXhJDOROI2Z+4QQAd5Y2iBRRUC44TJXkAR4JfbabygFsMjJ9GhzHyYH21kKmMJ3Nu01+5V/8PgA/9bd/hA9+v4TdH/7wGU4cPw3A7//W87zypatkHG0KSgDP8wl0bZXLBY5PS27/6lXDjS0dR9PosbMjnXE3b95iTen4Tp8+nk9VtXGG0RDVc0zem3/r1p28Ar4wOrPb7Rhb7t2RlFDW7xBpCizrJZyoyX09eeoM4+OSLhip1hg/JptsbWqWLDNUFWVzlGUQ2qfW0Na8aSdyc6hnklmMThDxrKE06O7CYhUeaLIsb2QyuHRakvYKCsW8aaPf7xPoJhkGfk6NGve6hJ7ci8nRCi3NnVsyun2tX3Ri6iNyH4tFH9ekmH2mZoapg6EMZShDOWR5qB5tp93hrRcFcpf1myxp8enk488yMSO78Pp2m9U18TJrx4/hK79hmvQJfB03vrbD7YYgDXyvQFvxssb1SHqyEzmsM4g7ysWQju5KaZbQ2ZZjVte22N6ScC0seDnIf3SiRqqeQ6lcZnOjdehcB+9XHB9SDfkr9XESBXdb16E6ImkWt1ThzprQ9R2fn2DxrFD9Xbp5nccfkzD/xvZNSuVBhdanqGmW0wtz3Lso1do0jsgGrYiemxcpCkGBwZLyXENLaQV/4zN/SCUUL/b8E08wMSKV8x/78RG27v0G2zot40iLMbszvfyQCWXUOjld5/IticCaboXxSUnNrKwsceOyFMxuX73CaEVboserOK42aKQZWU9beXcatLTXftvz6W+KNxYncY4asGR0m7Jej9VGeOT8WQBmjx1jZErXbn2CorLcOY6H8Rxc52gXxCzQS1QPPZu33UY2yAnme/04j3xKfpAXrgLf14GrgtYYtHc7rkOkyIR2Yyf3jNM0paRpGR8zgB/Ta0X0OnLMaKVASSOQre0GrpKPx3GW4+n9IMBn/x7tQzW0Bd9n594dANbWVkm04r/T7LC+KQto6e4y3oAXMk1pa27VcVPeviQ9+61WJ8+zjNddrDrmNoNQQ7HtRpuCVhSrY7Ns6ticPg6OjrK48NjTPPGkdDtVR4rMzIoBCMvFnLYtizKKS6v4X7txGCo5MLHW4iRyzYWgwJYmvVtpkZlx4X+Ynp3i8//uIgD1Ypmnnhbj+qUvfgmvoB1NFxZYuSjpnUq5TDkS3T45O8fdTaGmvLmxgRmsUGsYpKniJEIBC8S2jzuY5BpF/PN//gsATM0eY3ZB7tGP/bWP8H0ff5Irr90+eIUcgmQKaHdxKY0I3+/pY4ucuiHX//pKi1T1cuHCWaYVinX18hVuXr0CwM2rNqf1K4UBniJsbJpSDsUA9Dq93YnGrptzsm63Ozh9McbzZ45TU1KmSlCkqAiHoBDm+UsTxxjXyfPmR1cMPaUu7MaGZk/hbG62u7Yyi9VnPvQDrOZr+3FCorAsz3H3pGUG/5POU6v3zthdQppGu5k3TQWBn/Nab2xuY3T6y04nGpyGbjfKjXrU6+H6Ts5/+14yTB0MZShDGcohy8NFHTiWYnEw96tGy0ry/87S3bzX2XMcJnVOe5L2KFR0GBqwqVwE1vr0dVJbtxflPcquF9DX9s6gUGK0LuFUeXSeBcXgLpwLGdHmiJPHTpLpLKutzXUiJcLOACVtZ25qnrMXLL/1779y8Ao5QMkyQ6yTI3a22nmrbdEPuHFV0B2vv/pVMsVwbty8y8R5KUCeWljE6I5/bv442y9L8SXebjEyISmdsdEqM+NSSNvpJaw3pFruOAZfoR7WQKzjl4+dOMGP/tgPA7DVe5uNtqA7dho30BmH/MZvXuL0sUUybds9ymKMyT0nG8dYXwpM9foEH3ryAgA7X3uV0oxSbT7xJI0N0ePc9CRFja5arS53l6RI1kpbVBURMjo6SknvmbHk7aOtToemomp2uhHHlN9garyGp2k1z3FyBrSkH9Pr7bY4u55z9BEzgBb5afctUSo+ufFcEuXIsMbkLbJRnBCpqxtFUc7/UDAena4Wcq3F01Zem8R52idLEiLVT5okJAOWREteVG9FfTra7NCNIiqqZ4vB0TSMtfaBODoeqqGNk5ird/UhTjy2dga5OUtzU/Kyk9OzeXeNbzJSVXSz1c6B3sZxKWsOJU0SEr1L3W6bbSU4WTx+jlPnhGO1OjqHo8z/G9tbOU1dpxvTVXjNjdt3KVfl4VnbWMVkYjzGxuZptbs5g/1RFd8PKJVlYfX6bchkY2lvdthWUHy1WsmNWtJz2dKRHidOn+K1y9KwMHJsmkc/Jnq7e+0mxWnR80p3i0BuC6fnZ+i2JVzupTFxT3Yl43l5/47vWoKi3LtqaDEVnYg7UyLRIZJ3Lm/xwpfeotU8lAkAByrWWjIlROr3m1il4DSVESZnhVP2icUV7ml+8cadbZxUDGRxpEpTuZQXZ+vMTUtK4e3LN9luKp9poYuv+UUTp3S0qabZ6eVGBQzT2tlX8YroniaGROFLWbuDDcTxSB2LzRyOeuIAC339jr3YYnVgqucHoB1y1pg8tO8nKds6HNNkMTV1xvpxRqZDXn1Mnk81ZGSadkjimL6ePwwLxOpoWePQ7GrTVGzZVorFzCaEI4PBrulgshaO4/AgMy+HqYOhDGUoQzlkMftN5h7IhxmzBrSB9Yf2oe8tE+zveo5baycP+2K+XTmiuoX96fdI6xbAGNME3v5OX8c7ZLh2D1cObO0+VEMLYIz5urX22Yf6od9Cjtr1vB85it/lKF7TtyNH8XscxWv6duUofpeDvKZh6mAoQxnKUA5ZhoZ2KEMZylAOWb4ThvYz34HP/FZy1K7n/chR/C5H8Zq+HTmK3+MoXtO3K0fxuxzYNT30HO1QhjKUofzXJsPUwVCGMpShHLK8L0NrjPkRY8zbxpgrxph/cFDHHpYYYxaNMc8bY940xrxhjPlf9f1/ZIxZMsZ8Q//7K9+J63un7FdnQ90+uAzX7qFe61C37xRr7bf1HzLN4SpwChkN+U3g0fd77GH+B8wCz+jrKnAJeBT4R8D/9rCv5yD0O9Tt4el2qN+hbg9Kt+/Ho/0gcMVae81a2wf+DfCjB3DsoYm19p619mV93QQuAvMP+zr2KfvV2VC3Dy7DtXt4MtTtu8i3XQwzxvx14EestT+r//5bwIestX/nHcf9HPD3gREDE6GOjtBf5j8Hc+ytlUF4AL7v53SINstyEo0gCPKhc3Eck6ZyjOu6eDpJwRiHQWNylmb5uBQLJEpO0e/3c/IOg3BYgnBc+nqeXq9Hkqb045gkTR8ased+9LtXt0HgT4xPChmP4zp79GZzPs0sS/N+cdfzcrKRNInzY1zPI+nrXCHPxVM6OptlJEqi4fl+3jvuOi6O/m2SJBgl3XAcJ+fqzDKb32tjdqnl4jjG8zy2N7fotNpHSrf6fq7fYrE4ceLkid3f7R70jvdM/o93/uY/vxDYJSKw952LPc/lQF97uU8tlncjMXjn+9Za7t67x/bW9kPR77ejW9/3JsbHxvQXu9r6i7heLfcfY/d8YbNX6/fpa/Ai92Lzz3vHCzumqdwAACAASURBVDna7nnb5u/m98Uiut1pNOl2e++p20MnlbHWfsYYswn8SMHzPn2yLuNoMsALlV3H9SnoSN80TanXhSR5ZmaG9XXhQI37PaanpNNtcWGegv7t6vI9traEkKY6WmNSCZD9IMSqUek0W3QjHd+cwaaSrNy8dYumjjZ3jMNIRcgj5mdnmdHzvP3WW2w2tnn7xtHjTN2r24npiU9/+u/+DADlcpnNdR2H3e0xquOwW60WbSXLqE9M0leS9K21VWpjcszo2ATrOjrFrVeZqOj4oHaXdZ1RNTE9RWtdSFKq1SqlUWFD29jYyMc9l0rFfMJoJ+qDjpD2gyJxIob83r17TE5O8pl/8v8ehnret+zV74mTJz7967/xK4A8wI5uQHs3lL3vmz3Ow+DnrgyO3/vQ2/sNgx04CSlpKhucTHXVkS9pmk8i3hMCY63N38+yjCzL+O9/+mcOQBsHK3t1O14f+/TP/M2fAHQ0km7Wvu++q7HNsmzXMXDd/PsO/j4/j7t7jwY6TNOUWFnYjDH33bv8/NaSKa+tMWb3XmRZfp4sy4jjmF/517+3r+/7fgztErC4598L+t5feKzF5p5loVzCLygFotlVhOu6lHXGURAEjNVlp4uTiGJVmYvGahSUvLsT9Ql0HHOlUqWmzPf9fpx7b5vNFVbWxPCsrG1w846M2U5sxkhdZj/ZOGH9ppCStxodQldHoQcFen74nRjbvF/9LgGLex943/ep6KZxd3ubYl/Ysvr9fq7nKIry3blUKlEbEz10u13aHWEx8osuqc4My7LsXQyGyOCcxWIxH4dtrd2dDGBtHnVkRPkDUCgU+HYjqvcpD7x2DeTjq41x9hhUJ6fOkwd38KDf71ndb4z36vFdDK3d9dFsluXRiZx38Ln3G5jBxIEszciU1itzxNDudwrAAckD6xbu34zMHirCgTjOu5NsW2vvM67vajj36MDzvHyNDn6Xf+4gArM295L3Gte912CtxfM89qva92NoXwTOGmNOIgr7KeCnv9Wx1grHJIAb+BgN1cl2H9ZSqZS/brfbpKlylRrD2qZ4VMV6jKPnWe84OJT0eMvYjBjaStny9kWZJvDN199iXSkBreMR6uC7UhBQ0oGM05OTbCwLT2hje4e3rsg006nRCr7nPezFCvvX74vA2b1vJEmCq7otFAq5gSgUCrlHG/UjxkbFW60WC/ni8zybRxRdz9DUqatuYikrG32/36fXUzq6IMDViQGFwu55Go0dfF/u43ajSS+S17X6RH5MoVDAdd19L9YDlAdeu9znobo4jnwHMbS7D/rAXuw1ru98sPcagz3Zs3esscGQQZMbgzRNsdbkv36n5wqQmT2vs5TUJA977T64brnfE3XMrjHLdeUYCYP1GHeQgrS7ekvTdM9G5+B5u69zI73neGstjjeYzrJrUPPPk8PvixwGf7u7MRzycEZrbQL8HeDfI8njz1pr33iPY4eyT9mvfoe6fXAZrt3Dk6Fu313eV47WWvs54HP7Pbbgeznzv+v76Lgk4iRhsDO4rouju1Kr1SJSMt5ipUoXSRe8dm0dU5SUQuJVyazsRHZzh8jIwEe/3+Dlr30dgOs371CrS353fGIKN2e7b9PviMfc68YYneteGZ9gQ0nJjY0Zr9fyHe5hyn71a6393OKJBUL9XlmaMjoinn05CMlUt45xcrb+0ZERipq66TYbbCrxeqlSo1IRj9/zLaM6x8pJLRtdyWcnUUSkxNQ1Z5SSerpxHOcjsz3Pw8tD7V3vrtfrUdQ10Gw2iaLoPk/iYcmDrt3HH3/svpzfrufk3uflGPXGHMfkZPFra+uMVEWnxVIxP+/9xzvs5m7Jn4F3VrwGka7N7LvmDtMsIx2QXCcJTuY89GjsQXU7NzudF1Rd18m9fBfwGJB3G9JBtAA56XmGHTi6uNZgHZ0N5trcA7aZzW1NZjIy1anNwNktq+0ek2UMRi9Ya3MC8SzbLaq7rqvR2BEczui6Ll6go+PM7liIYrFIpgzrzVaTsCAGLwgCmk0xDK1uzGpHGe5LDotPPApAElZoNMUoeqS8+LqMTEk2btFW42Ecj1JZFnq5MkKiyh2fqODrOl7bWKepxaHMGPziYBKsi/F2H4KjKtZa4khY9uu1MUoaEs1Nj9PSAYuvbbZJe6JPJ+uTZGKYE5sRK9Jgo9WjpAv6+HSd0/NTAPQTywuvyhQGxw2o6hSMgu8Rat4wIc6nBRvXJdZ5QBMTE2xtNfQXRvLDqAkxhqOuW3i3AtjA0LInRwsDw+gHHq+/LPr6xX/xS/zV//avAvDjP/7fYNUxMMbFdQdG2sXVdATGkA6KMViMWgzHmLyqbvfU3qUYJn+aphlJumtokyTNr/soix04Mo6Toy8861BEETMGImd37oyn9iJxIVUjXfKKdJAhr5mTYnTKCHZvodGSWUXkGAdjNee95xgLmGyQurkPAHJf2uFBZNiCO5ShDGUohywPeTijg6OFAeOYPLQM/AJWd+dGu0Gi7n8/7XBHZy2ZFLqpeGDlyScI6zJC27HgdWWHam1dJVoTQvRKZvA98UqbtoM7CO9wSTT+mlucZ7wgVXXf91ndkGJYL46Ynxd418xoSBpHeWL9qIoxhpJC5GyaUQnker1oi/bmIJxyCDWiaLdaFB3RT5KS3wtcjzSR8H+8XOTscZmHtdnoEao+e7gEGgqnrkcvVo/LD/D3YHY9LcgZ4+XX5roB8aC4kMno6O9AofHBxRhcd1AA21sYMzl2W4ou8t1c16XZlFTLa6++SbUiqa5PfuIHGK2V8tMOMN0bG2usrsjaDcIiZ89LfTP0XUw+p4rck96bjpE3dnHoe4s3aboLhTqqsrfglECO8EmwROrxp47JPVrHkCOKol6EUxB9JsUidU9sRLPbpD1Yf05CqPYliB0KfVfPacmc3aKjUS/Zs4Z4Dwoi914zcthXNoDR7dOzfaiG1mLx9UHfm/twXAdP86O10KWt+b+bt2/R1smuo2EhB8mHtTFQSJeXGUqRQJMaOPkkSy8MKY9LXnZp7R47OxK6Bn6Z44/K1NIwLNDQqnqtViNOBgPZUsYUShYEEKX9+8HkR1QGD2GaZIyUdABdr4e1khLpJylRrDnpRoZTEL0FfsigMO64EPXlmHKhQFEXMes9Sp687iUp1tNwOSgQ6aL3PBeryTPPDyhpDjjqJXie3N8wLBDq4iyGoYTMR9wQDOR+dIG8dl2XN96QWs/Ozg4f+tD3AlCpFPNctOd5vPaaIGBu3Fjiez5wXs9j+PrXXwLgF3/xM2ysSwqsWCzx83/v5wH4+Mc/ik12H+Z325SM42DMrg539Slpmb8IlndkxHJfvjlvaHG9HKpmXI9AnYEkTrDqSATuLgJh6eZFqk1JgU3Pz5DV1ZEwBsfK8YkDTqgQxDQmMQo7dCRNA+Bk72h22Ns8oj/zjW6fZuGI34GhDGUoQ/nul4fq0WZZlmM6a7VaHnJtbG7tAQjD3SVBDjR22lQqgum0WZrPYKfg09cdzSYGtyIV9kee+wjLBdkBO7evYNNBGypsK4qgXh9HoxHeeusitYLgaAuBlzdKtNstrl25CsDkWIlquZh3mR1dMVgtm7qeTxLLd6+NFpjU9291Gjzz5OMArK1tsd4QL98NfWYnRIdPPXaOWzeuA1AfqRK4OsJ8Y53psngIRcdluy36LLmWqo57bkURff3cUrVK4Mv72BRrB23VIVEkqYlSoUhm7XdH6mCP7E0duK7L7TvSNfjZ3/wtnv9PXwLgJ/76j+NpqiEIA9ZWZcT9C3/+As98QAq5nutx7Zro+rVXX6eoo8S3txv8m3/zWQDOPXKO2ekJQJ6BdxObZdhch2ZP8GWBoz9u3BjuR3QMWo73pBoDHGaqYgv6ccxGW9auF4Q4iF6maiGby5J+iTqjFNSjjROTGzrXsdisr68NbfV0m65FX+LH4A1gt+/outu9ZvNA6/ahGlpjnBwKNDU1lV94p9tlY0se3JX1jTyECgslPJ11327skPpiCPE9CDWMyFJChSPheFSPnQNgY3mFVku6wYxX2gV9Z31uXr8CQK/bJ6gJP4DrGj7xgx8H4NLbF3n9VTEGYRBizENV07clruNS0Q2HJKPT143ILVAfles/OeNzck64MtZHq7x55SYAvms4PinNC/UQvDlBGkxPTNDrStph9cabVH0JhavlEWZHtUnByWi1xYgYQioj8jCYQinfPK1NKYRy38OwSFFhaGEY4Ps+vnf09Qu7D9re3nprLR//mKwb3wv4nX/7BwD8wj/+v1hYnAMgTRJSRWB85c/+jE/8ZTl+fHyCO7elS9H3Q4Ig1HMaXnv1dQCef/5P+Omf+klgkL0agJneaT73XtM73z/ypvZd0zLWMXltxe8mrL+hzs/sDCXdxCIsiXpg3sg05rTkwju1Cca0NTxprVLQVvvs0hXc27IxurUZvEdOyxXUAnpqsPXT3+Uyd5kUHhSSOEwdDGUoQxnKIctDx9EOevCjKGJ9QzzOJIlptwXfub62iVE8oe+XiPuyc/SiiMTIjm8yizvYcFykDAk0EofKohQajjkB3duX5P31ZeJIvOTt7XV6Gt5Wx6bJ9G/Pnj/Hxz8unsbdWzfxBlXcDOI43W9x8TsmrutSVQIY0gzja0gUbeM44gWdmpsha0vxr+ykPPvoGTm832ekqE0iG8tY9eA9x7CiaZyym9DeEbIZ29lmckw+q5j06a2Jbm/c2eH4B74fgJn5GXqp4GWLhQibSWhYLpdxFEfqex5hIfyu8GgNe3gMcPbgKWFkRHTxqU99ihPHBS3wa7/2qzz//BcAaDY7FEsSjV2+col//H/+EwAq1RFWlkWnnrfLVIdx6Cuu+Q/+4A/42Ee+D4ATxxfz5pxvJfdjPN+d5etoiWUAwHYcMAMMsTUo5JXMGG6+KRj5tVfe4NhHnwAgqVdoq7voeQ6b+t3furZGaVn++Py54wR9wdRHG5eZjiSl0HjjMrYhuNv6c0+wNSoRW88hRyDsLSTaNL2vKC6og/19w4e+wgchfBz36ahxdT03h8X04xjPl9DSdYK8Sp5Zi1UojOmnuD3thIm7WO21p1DGKnfBwvxJuqMSRlz76vNEHYWAtbZJFchcq88Sax53emYmzx/fvnWLlqIUDGUmJsaPfOXW8zympgVlYTNLoJSScT+EWIxraBz80qBxo0RrQx7y1BbxtAMsNUWcgiymu/dus31VFujWDnz5qwLAn52egVNiRGcqAWSqt+tr9D2prp85+wiTk5JbjFObQ8A8xyNUgzUwsK75LkEdKHje4IId9OA7+SacZZbzFwR2+Hf/l/+ZqWlJo/zLf/lLbO8o7DCt8uprkhaoVqv5uipVyjnUq9vt4odiDK7dvMXn/t0fA/A/ffp/xBugPYxcya7Yd/x85/tHVwwm79AyFpwcxrWbB02LIec/8mEA+ktL0vkFmH4Pa2X9nT7/FDPH5B7dWW1y9bbANZd3YgJPEDYjF55hckwctrM0efGlP5OLcPbAEbMMk+3q9r5nfw+BUBzHQ9TBUIYylKEcFXnoDQuxhkfNZouWerSTUxPEGs4naQbasIBxKGuqIe0ViVKtTPYi/EhCq6jdYLQmzQWNQoHIE88sCkdIC1Ic8gpFuq1BVXO37fHevSUqfSn2WCyhUi/OTE3z1qvflL91R5iYmLiPgekoiuu4jGlhz1pLpol9mwWYvujQiTuQtxx2MFp93dno8sWvvgjA+npMbU4igbML47Auha6vvnyZmytyvON2mB0Tj3+yOsnSyqDVOaSrSIaNu0uMTYlH67oOWtPEWgi9AfeCkQLDd812b/b83EODOOjH31OsWlycZ3paiopxHOcokO2trXyd9aMoD/Onp6dzz6nX7eLrOcfGRvmjPxKPdnpikh/9MRlb5XnvHgWIB7iX+fvb/rIPT8zu93EcB8fdveicFtJaLnekQF099ySPnhEmxo3bN2jdlDW6slXmyWcEVROULjI/J9Hb5NQ8Za0hrl3xcSsSARcX6lCSz2olSY5GKmGIvT38BgM2NJvBf+bpHkGuA2Mctral+tfqdMj0oe/0LM2OsvobhyST1724xYTCu3phhWZTjfHOGv0VQQ5sLS1RiCXPEpw4jVHSDoPFaijgjlQIYln0QWiojYvh6SURRYWDjVaLeLrQF+fmmJkWo7W4MM14rZrTDh5VSZKU9TXRg+M4mGDAwJHk+SY3c3E0VxokFmtkwa1vLNHXRbxy6S7f/JrkwtxPPE3WEz1vNhoUAuWmjSLKuiqTqEtboTbVSgFfN8mrly/R0M/CC/LUhDUG42b5dcZJTKcXHYJGDlf2QtgHKASDk3eP7ew0+NM//QoAvW5EoA05SZzQU113250cbN+PovykFphWbo52q83SLamS/6tf/lWeVHjeuXNnSLMBZ8Ke67LvJBA/sK98aGIwObxL6vqD77VLuu25Divrorff/dLX+PCHZA19+IPPcHJe/vbKzRvsvCBpslNzsxybmgWgPlbMN/rqxDNYPf+lN9+gH2n6yndIUA4OJ8PY3Q68wQZoUpNPZNk1wPtT8NG2HkMZylCG8l+APPSGBTNg47GQaKXx1p27bG+LN+Z5HikDfG2TvrJEuUFIqSJeQWv9NteVaWt9dZ3lO28BUFt5nEe+7wcAKC9U8XQOUVifwdG23pEQqmPiJY8WfeKOeNh37tzilVdeBaDZ6XLytODrHBuxevcuiY6/OKqytbXNr/6KgNzDICCoarOAk5IlEvIXQx9fR8p85KlTHBup6d++hedItPCJj53mC88LXvHFL77CE09JgW1q3EcHLzA+WmBirKqf5RFoMXLMqzCAHN++eZ2vvHELgMQaggEPg+PTTwY96C6uuxvlHHXZ2yY66MdPMexiW3dD4M3NbZaXZQyTzaCvo5Teeb5BSqHZb+wShfs+OzqeKbOiJ4B7y2u8+poUJB955BEY0INi93i15h2og6PfDLIbE8i/BlfsOA5aI+f69escn5Fnslp7lJfelEjr9nqDp5+TBpBHz5wi6YpX+vaVOyyFgmqq1wLKYxJRjUxUoC+e8catJaqquD6W3oBw3JiBU31fS/DeVMHuZIcjmDqw1pLoQ7++tkqroz34UZwPQ5wcG2NTu7h6cZ+uGkjjeFTKShixfYd0Q4DemevT2ZZwIf5mh1DD5OATIRU1tPXFx1i+K+D8pNdmbPIDAJx68kle/OIfAvB7f/jvePGrWg0uhdSr8lkmSuh12vlYlqMqrVaHV17e5Vd2vAFd3+7YFYBGQ2ek9ZtMfvQxALa2mrihPPAnT1b5y5nAvi5fWWZEmxROzpTpx0rM4TmUqpoL77cpFmUD7HbB0tdjfFYU9tVPMsKyvG+ND0Y2gX4cE4YhSfzw+Wjfj1ibMcCrG2vuexAH7/e6/RyaiHF2iWTZ0wUFJPoHe0P+uN8n0mfDLxQp6Tgh4wa8+LWXAfjkX/pBRmuCsBFG1qNvUL+VJLoR+X6Qd9RhwHoDhNAEJ86fkGNG5zl7Xqfl+CHdnhjOl778Bo88chKAMxfOgq7FXqvHyoas+9X1LSa17uOPj9BSW2PjJOe+TRPyTjsh5tFUhuPQVx6Qwdic/Wp9mDoYylCGMpRDlodcDIN+b9Da6uF5En72OhHT04Ic8IKARlPSCIUwIEklZI/jHiUtqITExOoZZ05Imog3XO1Zti6+AsCVeo1zH/kEADNnn2Ll1S8D0NpuYovyWccf/Sgrd6XQ8Mf/3x+wsyM718nFKbDidc1VC5QrAZ5/tLGeWZrRbu4WlXRIMGnP5LjksFAk6on3tbbZ4N7ymv6t5cSieLFBscrCgujhxOJpbt+WuXrVUkzmSPh/c2mFVl/0Uwh8CurR9rYajGgkMOKViLVIGSXgDLzhgodF1kDU26FYqO3S5R9xGQS4ruPtzqwCehp1Xbt2navKkbG1tU2zKUVCa+0uTtSQj3l3jEOo6yqO491imCUnR3eDEHfQ7x+E/KcvCpfCMx94mr/xU39Njj/i0dZ7iWMMwZ4GIaOE9H3bp6qTr5/68Ed4fVVyV6tLK3z81AkAyuMlKjpI9fLcFFd1vb726jr1GSmGnViYYFHRSJ2djN/+vKR0/GqBs9Nig0bNDpnamjT1GRAfOG5vz9BMl0BpGDOb5lSN+5GHa2iBWQXVT0zWcRVUnyXknTB37t3F04r2RH2cUKn2VpZXGauIssZGZ1m+Iwpdb7Xw1ZCM+GXaqdyMnaXbbCq/Z6U2xcxjzwJw/eU+r9+Q97c/9yUiDSmCkWlGatLhEwQeHSVNiUcnMH6CNUe7fGuxtHTsj80snvJCdDtd0lTC0FI5pa20kMQJgeqt1Y/43Jck9/epH/wQYwrGL5GRadrhrVvrpIGSdFiHRA3NWNXHDZWYp2I4f17QGpdXIjy722EWKxzPBbqJ6Dzq9SUHd7RVC2gIqXwFFy9eYnl5efAbLl+WfOHrr7+Wv+71evl4IJuleRb3vhYDm+FomOy4bt4ZlmXZrqH1u3S1m89aSy8Wo/5Lv/orBEW5f5/64U8SBgOu3HfmZ819qISjKZZEm2RiDxJX9DA3dpLpGUFZfOGrt7m9JunCHzg+QjkTnupOGGN0JMjpUxPMLcj6W210efOy2Ig//uIqF87I2j0xNcPbr8l5NjY9/E8eB2Bq9CaTZdGta3qkRp4lY02eNbakeQ4+ywxxtv+6zTB1MJShDGUohyzv6dEaYxaBXwGmEd/jM9baf2aMqQO/CZwAbgA/aa3d+tZns/koYUOW78KV0RF2GrJrj1bLrKyJaz81Oc7Zk9LSuDRym4UFSYAvLB7ndZ1f9ZUX/hyrbbqJ7dCJZe8o9xOMDl5suBHjT0r7Xtsts35TWvPWX3oNB/Gu5o8/StoQL8VzM55Shnt8y3rjWt4AcJBysLo1eVEqjmM8ZTdLSXMcbZLFlMsS/t9dWueNi0LRt7zT5aU3RSep/So//clzeh6HZZ3OsJ2O0NXwf7w+jlMUxEKUNLizJiFyFowyc0w8hPVsHZsIHrfXt4TaUprYKMd8O4T0e9mhYT0PVr8yQh3gs5/9LH/+Z18FoFAs0mruepyDYm8v6uUt3VEUkSnm9b7R1+wWw9gzVvy+YZbdLsaRz3U9n9qY6H3p7l3+73/2/wAwNzvLhz/4DABZtne8+ICf4eBd2oPUrbXgW/EOy0mM87pEBYWTLn98RbzMZlrmU1OCFup8/ndYOit24dG/+RNEsfJohCGTE7K+5xfh3COCnf/yKzf5vf8oDUgnj9f44PfKGv3z/3iPG7eFYe3Nqx0+eEru49zoTRJP1nQaF3EduY+Z7WPMYHDBg80N20/qIAH+nrX2ZWNMFXjJGPMfgP8B+IK19heMMf8A+AfA3/+WZ7LQ1WpqYtM857WzucPYmLj8p0+fZk3JZnzX48wJUUrZuBjlRo27MSNKxzdbn2J17Q4AnbhL15Fj6n6QM/knhZBmIgv0+Pf9EKcfV5TC1iaFoqqgucqNr0lI8cyTj3JyTsLht+9eo0vzUAwtB6hb1zF5vs/YlFibAOI93UdhwRJqnvvStVXu3hJD24ky+ql00XVaEUFFQfSNmECnDbc7Xd7WfHZxucXilOS2Zs/NcnNN3t/qdvjhv/IxAE6dn2J8QhZ3c7mRd0OVCx6hNkq0TUroe4fJR3tg+jXGsL4uKacrV67QUMeg241ygwoZRsHtvu/l6IJisUhXafr2GtE03UtWtEtnaAwM+mMym9HVDsra2FjOSTtSHckHl/7b3/k9Hn9UyJTKpUIOiTJmkFc+lJ3s4OwCMKbNNv6b1ylefA2ArS+9SunEkwB87G/8JCcnZLNesx+ickIcoVF/mkDpQbu9Ta68JWvO8WB2VtKUP/HBRY5ryvIX/+1L1EqSIvyJv32B578gtmbp5jR3ivL+xEiKq/wdrtvHosw21sknGx/4cEZr7T1r7cv6uonMap8HfhT4ZT3sl4Efe6BPHspQt4csQ/0engx1+2DyQMUwY8wJ4HuArwLT1tp7+qtlJIT4lmKNIR1U8xyTzwxrpxGJlZCr4JUYr0uP/N3by9xakjSCFwa0dAffaTTw1Z0/eWKBXk+8hZ5jGVHPqT5ZotuV3cprFQi1NbefRlRG5ZjxUo1oUxLmF1//E8qeFC/CMGFFBzWu79zGON185PNhyfvVreM4NHWQpR8GuP4AdmDxffGgRisF7q3IMWkfXEUIWN+juS26nZs7w8iE7P7X1m6R6ayv22v3uH5vS8/jsbyl0yuCUVYagiK4eqfFxWuCZHjuI9/DY49KNHJn5ZtMT0rE8vSTj/Diq0Jf2WpuE8dRztx2mPJ+9YsxOcXnxMQ4a6vi3XZ7PVragpwmCe6eIZ4Dz9V1XVwtKmZpiqOebpqmf0GhysmpAsksRt3bVqORH++MjhLoPLfX33wrR4c8euFcXlSzVopjh92G+351a6xl7Q1JBdZfukhB04vTTsbEReHg2P7l23T+5k8BcOYnfpy0Lmu0t9Hkha9/HoB//7u/yys6g833fY4vyvp77JHznPug0Cr+0HNVfu03vwbA7Mij/PAnZwD4o53r1OckKlhrlCn0ROfjC3dIMnk2smyELNM2XSstuHaf0cK+Da0xpgL8NvDz1trGO4aXWWPevSxvjPk54OdAhvFFfVkErmspqvEbnxjPw68sy/LmhVazyduXJc83Vq8xUZMwNqWPr4tvYXGBDe0qW95YYaQuIe3jpydpalVw+e5lzIi875cCWm05fmN1iZUrAvJfvvIK0xVZ3DeuTTA6Jg9Vo7nO6CSHSnxyELr1/YCnv1fCrO3tbVoNSdFUSmUmdHpCdSQk1U6kXpRx7pFjANTrU/zZlyXn+OwHznP9tujnpddvcVZzYXHWzzfJTi9hSY2uF5YoluX8cdrhi1+WB+N7PvwUH3z2aQC++OVLtHYGnXxrbG/KBpglGd12TPaAbPUPKgeh3/n5eWZnK0YRAQAAE0FJREFUBS70sz/7s9y6LV1vN29e5+JFoYa8dfMWq6vy3bqd7q7Bw+IpwqYfpQLlYhB+7tIbDgyi45gcPSA1bx1W2I9oKWlPsVSiPCLPw8bmDq98Q0LmR86ezs8jXAEPrq8HkYPQ7dhIFSYkFdg4Pk2yLU7XaLdFPZMUjXOty63Pfg6AzugM12NZT3/2x3/Eq28JpLNcGGF6XNIIrUabt9+QBqRXXn0J89uydifG5/CKcsxrX7nFX/5B4fr91A+lLOukkNuXDfVUNrHihI+v986xzp4puKncv33qd1/mw0gG+LeBX7fW/o6+vWKMmdXfzwKr7/a31trPWGuftdY+G+S5rKEM5KB067pD3b6bHJR+6/X6w7ng7yI5KN2W1eH6L1n2gzowwC8BF621/3TPr34f+BngF/Tn773npxlDSYm5XReq6mUa181xtL1ej1pNdpwTJ44xrlXWLM2o6ojx2OtT0ep5Zl087bV3HJiry/lP1lwag+b8ZJPGmkQzQakAPdklO0vX81beIOrR04rx5toWgY7rLld9PO8/71M/CDlQ3WIZr6vHn8TsbMl3jKIezYZsu70oY2ZaZyq1I5JE54Gt3Ob4guj83IVFPvuvpS253XSpT8v71vTzcc/VcpVOW6cnFMtUdTQ7WC69LRHIKy+9wuSEhGWFoExHmymuXbmek5KPTtfodrt4hzRu/CD1a9llwnriiSd48inBd/Z6XTa0eHvr9m2uXL4GwOXLV7h2TV6vrKzQacn9aDdbdLQgnNlsjxfrMuCXdvaQibuui+MNUg0JiaJqtja3sMob4voBX3j+TwH42Ec/yvyceN5SODucQuOB6tYYlgJ5ni8ah+9ZlHVzvt1hc1sip60k49Wb0gxy6f/431nNBI1QrY3w3DOCkX/k9CkKirvvR/18asv2ToetTaXvXNug3ZW0T9hzuHNNU43Tc9SqEoEsfPwMs/Xn5Bj3ONffFnLwfryBo5wg2SDts0/17id18BHgbwGvGWO+oe/9Q0SRnzXGfBq4Cfzke53IdV3OnHsEgDjuUlHCmCw1RD0xZt1el0IoRtfz3JyFX5jXZZFNTU/l40OWlldZ35KF3k/6zE7oiJVog862NB2MJR0Kqa7itgfKQVsZdejdFcW144gp9VoC36Mfy00KaxnW9OUCDl4OTLee57LTkEW5trrK3LxAW65cfitPxZxYmKaoqIM3V6+S6ZyQu/c2GFFjGRPgOLJYZ+dGmFuQjrEs/TIV7QwLgc0dMRw7WQnjSehf8LvML54A4NKlq5SKok8nM4SenDMIyekosTA7U+ONw+u6OzD92szSbnX1X12MMwCxy2YDcGzxOLVR+c6Lx45xQhEzFy9eZPmubOidTic3tJ12m25PDEaaJHlPfZImxOp4OIY8h22zLOc9iHt9lnX67shojZu3BZr4zdcvMa8DOE2W5pNdD0EOTrfWcummcJG8eu0aN3QyyvnRcQraE3Cz0WLTFf2MV8Z47mnhK7lw/gJ1Hc6aZP1ch6VSIbcvMzNO3sWVpgk9ReSsrq9x66bUC5rdFvMnhLSmXp/i5KMnAJibeIxyVdb6Sy/8KYk2X2bWyDkPapSNtfbL/MV2+xP7+5ihvJsMdXu4MtTv4clQtw8mD3dsgDGU1XNKEh8/EE9mZ6OZ0yfOz81z7bqECP24l3s/47VxJicEjZDajNUNcf9fefUVllbEW6iNVqlpG+3Gnes0dsTDKxRHKAXKdGQtiQLDtztdetpqGzgOx+YXABipFsmMIBn8sE8vbsNDqIy/H3GMoaANIFka46mXOb8wzrkz4lnVayXqile+ffsu7Z64C74f0upKRPHKa1c4rQWwzbVVWj2d8dZPmFc0QlgIKBQVA923lMsSfj3z9FkmJqb1GlIG7EmPnJ3CqgdYnyrQ78o5e12D58d5y/VRljRLuXNH8Nqbm5t5e22r1crxsq7r5vjKKIrymXiB71MqDcath9Rqmg7LsrwwFscxgY5hb7Za9Lrd/P1mc4DZ7ea8CmD2FNUy7ugI7c9//vM8+5Swsk1N1B+oH/87JRa4cEGaZAphwEvX5Pn/yr3b1JR3c/TYDE+eE2auR08tMlGTyMFLLX3Vsw123fe9kxHSLM6nqjiuS1knLByvzFFVus+bt+9y6fWvA9BqbpH0Fff82OOcOS/NIP3E56UXngcgTro4D4Ctf+jzWW4tyWKtjpQoKHnE7aW7VHVo4Ph4nfFxUaLrQqzdXUnUZ2tTDKd1DW++/TYAb771BqmOZJmam2V6ToylbazgaKhRGJ/Gc8TAuyZkc1sekvVOC1cT8UEvzslRsqwLyOL2w5h2P1IquqMrvudCIg/h8flppmZFh6c/+hQjurC21u9RH5PXTzx2nCTVxoEoze/LtZs3+MEPS84rjhtEsSy4YwsTkEoKolAMOXdBjLdLTLkg78+cPUmkQzO7vR1CpWp89PwssRGjcPL0JE5f9PzWm7fwg4TgiBP2gITtOzuCxrh58yZvKdJgeXk5f6AH1HmwC+0CMZY9TRHs8pje37wwOTmZp8PCMMyNd7VazQ1wHMe0NH3RaDbY0QGia2trFDR94RvYUpjf1OS4ENgcdVtrLaOj8vw/96EPML0gG/rSjTtMVsUxOHn6GKVxOQbX4Ogm02116Cu6wwR+3hjj+/6eoYq7iI5Bh56861Cris5HLlS5pZMsLn/jFdbvSDqytxXx1Ae+F4DHn/oovUiM+ktf/TLGpvtW7ZDrYChDGcpQDlkeLvE3VmYjAeurHTxfd3ZrKCn4enV1lZKGoqVykXZ/0CNuWNLk/9jURN4S24t6OWXd3MICJd2h/AAKNU2SlyrEXW2O6MQsnJYCT1oIuKV40AAvR0R4bgMvlPMXi4ZW9/65TEdRgsDj6SclmV8uVWl15Hs9+dhxblyThH+5mDExJrf8ez90gTffFH2G3T4nTgoG17gexYJ892efO8dIXTyK5z7wCDub4t1m1vLYeekRd2mTRuLpjc9P0XR09tjSBr7VyQvVKjfuSDhY9ufxdWZYOYhYPDZBGBx9jzazNvdKO50Onba2ksdxPiZcWmoHM6Vsjrm02e4MAcdx7vNoB55rFEW5xzw+Pp57sYVCgfl5KW7Nzs4ypvdjkIoAaDabecFzemqKqclJvZ5MFu4RX7tgSVKxCyaxnFDUxPHZYwSeplycLD8Gx8UbPJDFgDTTJii8+4aoDtI4NjOQj7TfJWpPEstgOobnOpycFy6V8fIoN25KA8iX/sPvcvWaTHD54Ec/ztlzkuLY2lzj+sVX2W+48HBH2aQZti2L1fd3WedLnkegemvuNFhdlYfVDVyKBeWR7HUIdYF2djZwNQc5MjZCRXuX036Pm5rfHSn4mAFu1xi2tE/91rWr/GD9owBcOD5H86yA9qN2yrFFyS+6/hZ91Uzq3sMopOMoS6HgcWxeNwrPh1WFocQ7TI1Lxd+xDqOiKnYaLaKO6KRcLDE5pkMbgwplX4zIdH2Ebl9CqLERQ0kXveM4TE/oJNd4Jze64+NlllIJZ+emRzDaRVOrhIyW5Noamw0qmt89c3qByekKQXC0JwyDDg3UNZokCamGqw4OrvLpWmMYUMPaNMvDVJlKvDsGZ8CH4DpOXiXv9Xq5cc2yjLHBGKYwpKFNCqVSKYcvlcslJtWgXjh/jsKehp80G3yWlSkFRz11ADiOrAHfC3LTlRqXvqJ9Mmvx9Bgn262zZMYhUPpOz7i5PuM4znUFTj7gwnF2mziifh/XG+DPbb5JlipFLjwq+eC17QZLy5Km/K1ff4Nz5yT/febUce1s3d8uNkwdDGUoQxnKIctDHs6Y0la+gmLRB60SlsIKhaLuSsWQ/oa0wiVYNpWaLu12mKhKKiCLU1wjO9fZ0ycZrUg4VQx9elqhbW/2cXWnc4s9Ojq1wSQxHQVBZz2fuSmpADe2+/kOaNwykU5tSGKD7/uHyTB1IOI6lslJuWbHOISBFMOaO6scWxBMrckiMNqrXXU4tqgk7FNTFEfEm/KykJKr5OBRHzeVJTI9XqKvtQjHMWDF6+2211hcVMrEqM3CvLjMo1WPJBE0SKFQYHpKu3+yCKthXFD0CIqHyt51YOK6LjPTEtK2m222///2zuY3kqsI4L/q7pnxjO34Y9feLwwbIe5BQlw4IyEuwI0cOHOJBEfEiT8AuCKBkhsSFzhw48QZBaIIdhPtskIsG8dkkyzrtccz/Vkc3us3PWYVvF53eyzXT7I00+pxV9e8qa5Xr17Vp25BdTqdUEx8sqcQmjaqSNi3XTUyVpRZR4SisTKOznyj8XjM0I/FNE1DEfDpdBrybieTSUjIT+KYYuj020t60AhNXAh3FqHfm3mfocW4KOLLJ6pI8EpFodDZZyNfqL6syrlSkzXa2BjSXAyLk9glKgOlEL6vvA65AJtXr7DhNwL95+lTPnroSjim+x+ztDQ8sX47NrRK6acCmZZEXsZclD2/6UDiiNjv9NKq4uATV1Smr0rq686qVuS5G3wbq5usr7rdS8ujQTCokVbgk77TbD/UrL22eZWJX7ndffSQqd+8MD4sGY7cdDhOKnY/dGlfSzsV0WAEPGtBI2dHFAuDgRtk42dPWK93a22sEff94MvLkDa0vXWNlWU3gJJeDz8rY6m/yuSgbumR0vNpMetrQyY+HWw0GrI08CUZ11bDNC7Nplypu1REJYkvQZkXOXHkjEKZKSsjF3OcFhnjydGcIVpU4iji5nUXIhkNR6ysujDK8toyD3w9jk+fPAnTduKZAaBRc0CrahbVU/dQ9KdQt/or8yI0AUzTlIn/ziaTSfj+0umU3J9TFEUIWUTauK4quvjPMIDZA4fZxiSFYMjcMf2fc5tNLZufBUKtiSbzBphQ2CpJkmDg4ziaM8iVP35lc4tXVn3Z0PGY6XR64nKJFjowDMNomc5XIfI65y2qSBL3dJnkKY8f+5oD/T63X70NQE8ibl677l8D/ikzHR8i3lvtK9SP8/H+AVr43lRxzJEvXxf5hmoAo1dWwxRkMBiSFs7TyrIjHj/2JRlj4d977vhKP2fzep9Fdw2SOGbrmtvQsdLrBU8pi5Rl32tNpwrFrM/Rxobz4MuyRHwZv8EwQnAzhEgLstR5UFJVrK07Ly5JktkTX6PwxB+tLIfqYBtr66hf3Dk8nHBl0/3PstAw6KK4oKzKFy6ifC6IhBzN7e3t4NFubW+zs+NWq+/cucu/HrqqXgf7zyhrT11nWQdNL01EQqihmYNbVRWZzxPNsix4tM3tu9PpNGRBpGkaFoSareVrLoR+Pao6J+9cK3c/5kTLuXzl5vm1t3vc033e+XJMV/XxqlKKohmC8L+lLG+UoHwxnXZuaEvfv/1oWjASv0o+GLJcF5uRiMOnzkAmccSKjz0NejG1XmKU3Mdie1HCJHNhhA8fPeTqposXri6PqNTvHc8mYUqX5quURz7zoT+gVkGcJEymbhCjwlLfGYb9JxOifkFRLv5gVX+Pw9GQIvebNfpxKEFZ5gl93x633++HtDhVJenVMekirH6XWTkrX5mXIXUmiqKwKynp9UD9FyNC6nfURFFEXsfaej3qWVwvjhksOYOlJMTxxYjRNg2AiDAa1fUNPs+635t/88Yt7t13YYS/37/P3q5LERofHKK1g/EcI/I86qyGLMvmY7R16KARu03TlEHfN3OM4nkD8zI33REKIVugubuueR9VVc101zCiqho+KyJzr583rvJ8Zizj3iCEXObDEQTHqiyrmQHW2eaP+ndx0rFroQPDMIyWkS6nFSLyMTAGPunsov+fq5xMni+o6lbbwpyWBdUtnEy/C61bABE5AO6dtxzHsLHbLmc2djs1tAAi8mdV/UqnF/0MFk2el2ER72URZToNi3gfiyjTaVnEezlLmSx0YBiG0TJmaA3DMFrmPAztL8/hmp/FosnzMizivSyiTKdhEe9jEWU6LYt4L2cmU+cxWsMwjMuGhQ4MwzBapjNDKyLfEJF7IvJARH7U1XWPybAjIn8UkfdE5K6I/MAf/4mI7IrIu/7vm+ch32kx3baL6bc9LotuOwkdiEgM3Ae+DnwAvA28rqrvtX7xeTluADdU9R0RWQX+Anwb16nzUFV/2qU8Z4Hptl1Mv+1xmXTblUf7VeCBqv5DVTPgN8C3Orp2QFX3VPUd//oAeB+41bUcZ4zptl1Mv+1xaXTblaG9BTxqvP+Acx4kInIb+DLwJ3/oDRH5q4i8JSIb5ybYi2O6bRfTb3tcGt1eysUwEVkBfgv8UFWfAb8Avgi8BuwBPztH8S40ptt2Mf22R5u67crQ7gI7jfef88c6R0R6OGX+WlV/B6CqH6lqqa5p0K9wU5qLgum2XUy/7XFpdNuVoX0b+JKIvCoifeC7wO87unZAXE2zN4H3VfXnjeM3Gqd9B7jTtWwvgem2XUy/7XFpdNtJPVpVLUTkDeAPQAy8pap3u7j2Mb4GfA/4m4i864/9GHhdRF7DVZv8J/D9c5DtVJhu28X02x6XSbe2M8wwDKNlLuVimGEYRpeYoTUMw2gZM7SGYRgtY4bWMAyjZczQGoZhtIwZWsMwjJYxQ2sYhtEyZmgNwzBa5r8Mz7khEWqe3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a few examples\n",
    "\n",
    "\n",
    "start_num = 0 \n",
    "print(start_num)\n",
    "for i in range(start_num, start_num+16):\n",
    "  for sub_plot in range(0, 16):\n",
    "    plt.subplot(4, 4, 1 + sub_plot)\n",
    "    \n",
    "    plt.imshow(x_train[i+sub_plot], interpolation='none')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hQyZdWDh-66"
   },
   "outputs": [],
   "source": [
    "# Use Image Data Generator for image augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# image data generator object\n",
    "datagen = ImageDataGenerator(horizontal_flip=True, \n",
    "                             width_shift_range=0.10, \n",
    "                             height_shift_range=0.10,\n",
    "                             )\n",
    "# fit parameters from data\n",
    "datagen.fit(x_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, num_filter = num_filter, dropout_rate = dropout_rate):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False, padding='same', kernel_initializer=init, kernel_regularizer=reg)(relu)\n",
    "        if dropout_rate>0:\n",
    "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "                \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, num_filter = num_filter, dropout_rate = dropout_rate):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same', kernel_initializer=init, kernel_regularizer=reg)(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(BatchNorm)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    output = Dense(num_classes, activation='softmax',kernel_initializer=init, kernel_regularizer=reg)(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False, padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Fourth_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "Fourth_Transition = add_transition(Fourth_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Fourth_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32031
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "f22ac353-4c13-4846-e703-bff814cd5b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 12)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 12)   48          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 12)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 6)    648         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 6)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 18)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 18)   72          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 18)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 6)    972         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 6)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 24)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 24)   96          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 24)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 6)    1296        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 6)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 30)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 30)   120         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 30)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 6)    1620        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 6)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 36)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 36)   144         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 36)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 6)    1944        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 6)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 42)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 42)   168         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 42)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 6)    2268        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 6)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 48)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 48)   192         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    2592        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 6)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 54)   0           concatenate_6[0][0]              \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 54)   216         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 54)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    2916        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 60)   0           concatenate_7[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 60)   240         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 60)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 6)    3240        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 6)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 66)   0           concatenate_8[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 66)   264         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 66)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 6)    3564        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 6)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 72)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 72)   288         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 72)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 6)    3888        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 6)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 78)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 78)   312         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 78)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 6)    4212        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 6)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 84)   0           concatenate_11[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 84)   336         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 84)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 6)    4536        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 6)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 90)   0           concatenate_12[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 90)   360         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 90)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 6)    4860        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 6)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 96)   0           concatenate_13[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 96)   384         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 96)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 6)    5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 6)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 32, 32, 102)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 102)  408         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 102)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 6)    5508        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 6)    0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 32, 32, 108)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 108)  432         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 108)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 6)    5832        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 6)    0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 32, 32, 114)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 114)  456         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 114)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 6)    6156        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 6)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 32, 32, 120)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 120)  480         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 120)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 6)    6480        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 6)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 32, 32, 126)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 126)  504         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 126)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 6)    6804        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 6)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 32, 32, 132)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 132)  528         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 132)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 6)    7128        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 6)    0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 32, 32, 138)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 138)  552         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 138)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 6)    7452        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 6)    0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 32, 32, 144)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 144)  576         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 144)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 6)    7776        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 32, 6)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 32, 32, 150)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 150)  600         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 150)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 6)    8100        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 32, 6)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 32, 32, 156)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 156)  624         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 156)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 6)    8424        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 32, 6)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 32, 32, 162)  0           concatenate_24[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 162)  648         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 162)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 6)    8748        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 32, 6)    0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 32, 32, 168)  0           concatenate_25[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 168)  672         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 168)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 6)    9072        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 32, 6)    0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 32, 32, 174)  0           concatenate_26[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 174)  696         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 174)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 6)    9396        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 32, 6)    0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 32, 32, 180)  0           concatenate_27[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 180)  720         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 180)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 6)    9720        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 32, 6)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 32, 32, 186)  0           concatenate_28[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 186)  744         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 186)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 6)    10044       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 32, 32, 6)    0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 32, 32, 192)  0           concatenate_29[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 192)  768         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 6)    10368       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 32, 32, 6)    0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 32, 32, 198)  0           concatenate_30[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 198)  792         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 198)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 6)    10692       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 32, 32, 6)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 204)  0           concatenate_31[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 204)  816         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 204)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 6)    1224        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 32, 32, 6)    0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 6)    0           dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 6)    24          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 6)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 6)    324         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 6)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 16, 16, 12)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 12)   48          concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 12)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 6)    648         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 6)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 16, 16, 18)   0           concatenate_33[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 18)   72          concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 18)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 6)    972         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 6)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 16, 16, 24)   0           concatenate_34[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 24)   96          concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 24)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 6)    1296        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 6)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 16, 16, 30)   0           concatenate_35[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 30)   120         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 30)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 6)    1620        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 6)    0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 16, 16, 36)   0           concatenate_36[0][0]             \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 36)   144         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 36)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 6)    1944        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 6)    0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 16, 16, 42)   0           concatenate_37[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 42)   168         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 42)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 6)    2268        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 6)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 16, 16, 48)   0           concatenate_38[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 6)    2592        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 6)    0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 16, 16, 54)   0           concatenate_39[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 54)   216         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 54)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 6)    2916        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 6)    0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 16, 16, 60)   0           concatenate_40[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 60)   240         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 60)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 6)    3240        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 6)    0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 16, 16, 66)   0           concatenate_41[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 66)   264         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 66)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 6)    3564        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 6)    0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 16, 16, 72)   0           concatenate_42[0][0]             \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 72)   288         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 72)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 6)    3888        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 6)    0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 16, 16, 78)   0           concatenate_43[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 78)   312         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 78)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 6)    4212        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 6)    0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 16, 16, 84)   0           concatenate_44[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 84)   336         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 84)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 6)    4536        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 6)    0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 16, 16, 90)   0           concatenate_45[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 90)   360         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 90)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 6)    4860        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 6)    0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 16, 16, 96)   0           concatenate_46[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 96)   384         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 96)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 6)    5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 6)    0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 16, 16, 102)  0           concatenate_47[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 102)  408         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 102)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 6)    5508        activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 6)    0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 16, 16, 108)  0           concatenate_48[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 108)  432         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 108)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 6)    5832        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 6)    0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 16, 16, 114)  0           concatenate_49[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 114)  456         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 114)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 6)    6156        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 6)    0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 16, 16, 120)  0           concatenate_50[0][0]             \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 120)  480         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 120)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 6)    6480        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 16, 16, 6)    0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 16, 16, 126)  0           concatenate_51[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 126)  504         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 126)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 6)    6804        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 16, 16, 6)    0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 16, 16, 132)  0           concatenate_52[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 132)  528         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 132)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 6)    7128        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 16, 16, 6)    0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 16, 16, 138)  0           concatenate_53[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 138)  552         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 138)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 6)    7452        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 16, 16, 6)    0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 16, 16, 144)  0           concatenate_54[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 144)  576         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 144)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 6)    7776        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 16, 16, 6)    0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 16, 16, 150)  0           concatenate_55[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 150)  600         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 150)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 6)    8100        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 16, 16, 6)    0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 16, 16, 156)  0           concatenate_56[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 156)  624         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 156)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 6)    8424        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 16, 16, 6)    0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 16, 16, 162)  0           concatenate_57[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 162)  648         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 162)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 6)    8748        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 16, 16, 6)    0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 16, 16, 168)  0           concatenate_58[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 168)  672         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 168)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 6)    9072        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 16, 16, 6)    0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 16, 16, 174)  0           concatenate_59[0][0]             \n",
      "                                                                 dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 174)  696         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 174)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 6)    9396        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 16, 16, 6)    0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 16, 16, 180)  0           concatenate_60[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 180)  720         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 180)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 6)    9720        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 16, 16, 6)    0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 16, 16, 186)  0           concatenate_61[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 186)  744         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 186)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 6)    10044       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 16, 16, 6)    0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 16, 16, 192)  0           concatenate_62[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 192)  768         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 6)    10368       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 16, 16, 6)    0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 16, 16, 198)  0           concatenate_63[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 198)  792         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 198)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 6)    1188        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 16, 16, 6)    0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 6)      0           dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 6)      24          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 6)      0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 6)      324         activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 6)      0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 8, 8, 12)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 12)     48          concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 12)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 6)      648         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 6)      0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 8, 8, 18)     0           concatenate_65[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 18)     72          concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 18)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 6)      972         activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 6)      0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 8, 8, 24)     0           concatenate_66[0][0]             \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 24)     96          concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 24)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 6)      1296        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 6)      0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 8, 8, 30)     0           concatenate_67[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 30)     120         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 30)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 6)      1620        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 6)      0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 8, 8, 36)     0           concatenate_68[0][0]             \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 36)     144         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 36)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 6)      1944        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 6)      0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 8, 8, 42)     0           concatenate_69[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 42)     168         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 42)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 6)      2268        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 6)      0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 8, 8, 48)     0           concatenate_70[0][0]             \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 6)      2592        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 6)      0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 8, 8, 54)     0           concatenate_71[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 54)     216         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 54)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 6)      2916        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 6)      0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 8, 8, 60)     0           concatenate_72[0][0]             \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 60)     240         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 60)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 6)      3240        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 6)      0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 8, 8, 66)     0           concatenate_73[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 66)     264         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 66)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 6)      3564        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 6)      0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 8, 8, 72)     0           concatenate_74[0][0]             \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 72)     288         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 72)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 6)      3888        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 6)      0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 8, 8, 78)     0           concatenate_75[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 78)     312         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 78)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 6)      4212        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 6)      0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 8, 8, 84)     0           concatenate_76[0][0]             \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 84)     336         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 84)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 6)      4536        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 6)      0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 8, 8, 90)     0           concatenate_77[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 90)     360         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 90)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 6)      4860        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 6)      0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 8, 8, 96)     0           concatenate_78[0][0]             \n",
      "                                                                 dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 96)     384         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 96)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 6)      5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 6)      0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 8, 8, 102)    0           concatenate_79[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 102)    408         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 102)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 6)      5508        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 6)      0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 108)    0           concatenate_80[0][0]             \n",
      "                                                                 dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 108)    432         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 108)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 6)      5832        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 6)      0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 114)    0           concatenate_81[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 114)    456         concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 114)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 6)      6156        activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 6)      0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 120)    0           concatenate_82[0][0]             \n",
      "                                                                 dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 120)    480         concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 120)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 6)      6480        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 6)      0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 126)    0           concatenate_83[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 126)    504         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 126)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 6)      6804        activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 6)      0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 132)    0           concatenate_84[0][0]             \n",
      "                                                                 dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 132)    528         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 132)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 6)      7128        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 6)      0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 138)    0           concatenate_85[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 138)    552         concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 138)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 6)      7452        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 6)      0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 144)    0           concatenate_86[0][0]             \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 144)    576         concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 144)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 6)      7776        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 6)      0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 8, 8, 150)    0           concatenate_87[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 150)    600         concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 150)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 6)      8100        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 6)      0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 8, 8, 156)    0           concatenate_88[0][0]             \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 156)    624         concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 156)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 6)      8424        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 6)      0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 8, 8, 162)    0           concatenate_89[0][0]             \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 162)    648         concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 162)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 6)      8748        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 6)      0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 8, 8, 168)    0           concatenate_90[0][0]             \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 168)    672         concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 168)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 6)      9072        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 6)      0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 8, 8, 174)    0           concatenate_91[0][0]             \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 174)    696         concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 174)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 6)      9396        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 6)      0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 8, 8, 180)    0           concatenate_92[0][0]             \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 180)    720         concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 180)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 6)      9720        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 6)      0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 8, 8, 186)    0           concatenate_93[0][0]             \n",
      "                                                                 dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 186)    744         concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 186)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 6)      10044       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 8, 8, 6)      0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 8, 8, 192)    0           concatenate_94[0][0]             \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 192)    768         concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 192)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 6)      10368       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 8, 8, 6)      0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 8, 8, 198)    0           concatenate_95[0][0]             \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 8, 8, 198)    792         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 8, 8, 198)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 6)      1188        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 8, 8, 6)      0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 6)      0           dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 6)      24          average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 6)      0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 6)      324         activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 6)      0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 4, 4, 12)     0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 12)     48          concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 12)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 6)      648         activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 6)      0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 4, 4, 18)     0           concatenate_97[0][0]             \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 18)     72          concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 18)     0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 6)      972         activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 6)      0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 4, 4, 24)     0           concatenate_98[0][0]             \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 24)     96          concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 24)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 6)      1296        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 6)      0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 4, 4, 30)     0           concatenate_99[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 30)     120         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 30)     0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 6)      1620        activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 6)      0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 4, 4, 36)     0           concatenate_100[0][0]            \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 36)     144         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 36)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 6)      1944        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 4, 4, 6)      0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 4, 4, 42)     0           concatenate_101[0][0]            \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 42)     168         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 42)     0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 6)      2268        activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 6)      0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 4, 4, 48)     0           concatenate_102[0][0]            \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 48)     192         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 48)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 6)      2592        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 6)      0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 4, 4, 54)     0           concatenate_103[0][0]            \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 54)     216         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 54)     0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 6)      2916        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 6)      0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 4, 4, 60)     0           concatenate_104[0][0]            \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 60)     240         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 60)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 6)      3240        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 6)      0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 4, 4, 66)     0           concatenate_105[0][0]            \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 66)     264         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 66)     0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 6)      3564        activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 6)      0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 4, 4, 72)     0           concatenate_106[0][0]            \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 72)     288         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 72)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 6)      3888        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 6)      0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 4, 4, 78)     0           concatenate_107[0][0]            \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 78)     312         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 78)     0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 6)      4212        activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 6)      0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 4, 4, 84)     0           concatenate_108[0][0]            \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 84)     336         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 84)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 6)      4536        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 6)      0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 4, 4, 90)     0           concatenate_109[0][0]            \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 90)     360         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 90)     0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 6)      4860        activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 6)      0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 4, 4, 96)     0           concatenate_110[0][0]            \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 96)     384         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 96)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 6)      5184        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 6)      0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 4, 4, 102)    0           concatenate_111[0][0]            \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 102)    408         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 102)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 4, 4, 6)      5508        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 4, 4, 6)      0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 4, 4, 108)    0           concatenate_112[0][0]            \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 4, 4, 108)    432         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 4, 4, 108)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 4, 4, 6)      5832        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 4, 4, 6)      0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 4, 4, 114)    0           concatenate_113[0][0]            \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 4, 4, 114)    456         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 4, 4, 114)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 4, 4, 6)      6156        activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 4, 4, 6)      0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 4, 4, 120)    0           concatenate_114[0][0]            \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 4, 4, 120)    480         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 4, 4, 120)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 4, 4, 6)      6480        activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 4, 4, 6)      0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 4, 4, 126)    0           concatenate_115[0][0]            \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 4, 4, 126)    504         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 4, 4, 126)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 4, 4, 6)      6804        activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 4, 4, 6)      0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 4, 4, 132)    0           concatenate_116[0][0]            \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 4, 4, 132)    528         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 4, 4, 132)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 4, 4, 6)      7128        activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 4, 4, 6)      0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 4, 4, 138)    0           concatenate_117[0][0]            \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 4, 4, 138)    552         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 4, 4, 138)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 4, 4, 6)      7452        activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 4, 4, 6)      0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 4, 4, 144)    0           concatenate_118[0][0]            \n",
      "                                                                 dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 4, 4, 144)    576         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 4, 4, 144)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 4, 4, 6)      7776        activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 4, 4, 6)      0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 4, 4, 150)    0           concatenate_119[0][0]            \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 4, 4, 150)    600         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 4, 4, 150)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 4, 4, 6)      8100        activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 4, 4, 6)      0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 4, 4, 156)    0           concatenate_120[0][0]            \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 4, 4, 156)    624         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 4, 4, 156)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 4, 4, 6)      8424        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 4, 4, 6)      0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 4, 4, 162)    0           concatenate_121[0][0]            \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 4, 4, 162)    648         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 4, 4, 162)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 4, 4, 6)      8748        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 4, 4, 6)      0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 4, 4, 168)    0           concatenate_122[0][0]            \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 4, 4, 168)    672         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 4, 4, 168)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 4, 4, 6)      9072        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 4, 4, 6)      0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 4, 4, 174)    0           concatenate_123[0][0]            \n",
      "                                                                 dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 4, 4, 174)    696         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 4, 4, 174)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 4, 4, 6)      9396        activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 4, 4, 6)      0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 4, 4, 180)    0           concatenate_124[0][0]            \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 4, 4, 180)    720         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 4, 4, 180)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 4, 4, 6)      9720        activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 4, 4, 6)      0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 4, 4, 186)    0           concatenate_125[0][0]            \n",
      "                                                                 dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 4, 4, 186)    744         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 4, 4, 186)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 4, 4, 6)      10044       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 4, 4, 6)      0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 4, 4, 192)    0           concatenate_126[0][0]            \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 4, 4, 192)    768         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 4, 4, 192)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 4, 4, 6)      10368       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 4, 4, 6)      0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 4, 4, 198)    0           concatenate_127[0][0]            \n",
      "                                                                 dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 4, 4, 198)    792         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 4, 4, 198)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 4, 4, 6)      1188        activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 4, 4, 6)      0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 6)      0           dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 2, 2, 6)      24          average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 2, 2, 6)      0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 2, 2, 6)      324         activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 2, 2, 6)      0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 2, 2, 12)     0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 2, 2, 12)     48          concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 2, 2, 12)     0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 2, 2, 6)      648         activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 2, 2, 6)      0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 2, 2, 18)     0           concatenate_129[0][0]            \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 2, 2, 18)     72          concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 2, 2, 18)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 2, 2, 6)      972         activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 2, 2, 6)      0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 2, 2, 24)     0           concatenate_130[0][0]            \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 2, 2, 24)     96          concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 2, 2, 24)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 2, 2, 6)      1296        activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 2, 2, 6)      0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 2, 2, 30)     0           concatenate_131[0][0]            \n",
      "                                                                 dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 2, 2, 30)     120         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 2, 2, 30)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 2, 2, 6)      1620        activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 2, 2, 6)      0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 2, 2, 36)     0           concatenate_132[0][0]            \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 2, 2, 36)     144         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 2, 2, 36)     0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 2, 2, 6)      1944        activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 2, 2, 6)      0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 2, 2, 42)     0           concatenate_133[0][0]            \n",
      "                                                                 dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 2, 2, 42)     168         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 2, 2, 42)     0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 2, 2, 6)      2268        activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 2, 2, 6)      0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 2, 2, 48)     0           concatenate_134[0][0]            \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 2, 2, 48)     192         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 2, 2, 48)     0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 2, 2, 6)      2592        activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 2, 2, 6)      0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 2, 2, 54)     0           concatenate_135[0][0]            \n",
      "                                                                 dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 2, 2, 54)     216         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 2, 2, 54)     0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 2, 2, 6)      2916        activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 2, 2, 6)      0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 2, 2, 60)     0           concatenate_136[0][0]            \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 2, 2, 60)     240         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 2, 2, 60)     0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 2, 2, 6)      3240        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 2, 2, 6)      0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 2, 2, 66)     0           concatenate_137[0][0]            \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 2, 2, 66)     264         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 2, 2, 66)     0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 2, 2, 6)      3564        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 2, 2, 6)      0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 2, 2, 72)     0           concatenate_138[0][0]            \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 2, 2, 72)     288         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 2, 2, 72)     0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 2, 2, 6)      3888        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 2, 2, 6)      0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 2, 2, 78)     0           concatenate_139[0][0]            \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 2, 2, 78)     312         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 2, 2, 78)     0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 2, 2, 6)      4212        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 2, 2, 6)      0           conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 2, 2, 84)     0           concatenate_140[0][0]            \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 2, 2, 84)     336         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 2, 2, 84)     0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 2, 2, 6)      4536        activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 2, 2, 6)      0           conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 2, 2, 90)     0           concatenate_141[0][0]            \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 2, 2, 90)     360         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 2, 2, 90)     0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 2, 2, 6)      4860        activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 2, 2, 6)      0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 2, 2, 96)     0           concatenate_142[0][0]            \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 2, 2, 96)     384         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 2, 2, 96)     0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 2, 2, 6)      5184        activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 2, 2, 6)      0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 2, 2, 102)    0           concatenate_143[0][0]            \n",
      "                                                                 dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 2, 2, 102)    408         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 2, 2, 102)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 2, 2, 6)      5508        activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 2, 2, 6)      0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 2, 2, 108)    0           concatenate_144[0][0]            \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 2, 2, 108)    432         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 2, 2, 108)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 2, 2, 6)      5832        activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 2, 2, 6)      0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 2, 2, 114)    0           concatenate_145[0][0]            \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 2, 2, 114)    456         concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 2, 2, 114)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 2, 2, 6)      6156        activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 2, 2, 6)      0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 2, 2, 120)    0           concatenate_146[0][0]            \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 2, 2, 120)    480         concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 2, 2, 120)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 2, 2, 6)      6480        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 2, 2, 6)      0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 2, 2, 126)    0           concatenate_147[0][0]            \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 2, 2, 126)    504         concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 2, 2, 126)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 2, 2, 6)      6804        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 2, 2, 6)      0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 2, 2, 132)    0           concatenate_148[0][0]            \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 2, 2, 132)    528         concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 2, 2, 132)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 2, 2, 6)      7128        activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 2, 2, 6)      0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 2, 2, 138)    0           concatenate_149[0][0]            \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 2, 2, 138)    552         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 2, 2, 138)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 2, 2, 6)      7452        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 2, 2, 6)      0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 2, 2, 144)    0           concatenate_150[0][0]            \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 2, 2, 144)    576         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 2, 2, 144)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 2, 2, 6)      7776        activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 2, 2, 6)      0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 2, 2, 150)    0           concatenate_151[0][0]            \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 2, 2, 150)    600         concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 2, 2, 150)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 2, 2, 6)      8100        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 2, 2, 6)      0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 2, 2, 156)    0           concatenate_152[0][0]            \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 2, 2, 156)    624         concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 2, 2, 156)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 2, 2, 6)      8424        activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 2, 2, 6)      0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 2, 2, 162)    0           concatenate_153[0][0]            \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 2, 2, 162)    648         concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 2, 2, 162)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 2, 2, 6)      8748        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 2, 2, 6)      0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 2, 2, 168)    0           concatenate_154[0][0]            \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 2, 2, 168)    672         concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 2, 2, 168)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 2, 2, 6)      9072        activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 2, 2, 6)      0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 2, 2, 174)    0           concatenate_155[0][0]            \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 2, 2, 174)    696         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 2, 2, 174)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 2, 2, 6)      9396        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 2, 2, 6)      0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 2, 2, 180)    0           concatenate_156[0][0]            \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 2, 2, 180)    720         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 2, 2, 180)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 2, 2, 6)      9720        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 2, 2, 6)      0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 2, 2, 186)    0           concatenate_157[0][0]            \n",
      "                                                                 dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 2, 2, 186)    744         concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 2, 2, 186)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 2, 2, 6)      10044       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 2, 2, 6)      0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 2, 2, 192)    0           concatenate_158[0][0]            \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 2, 2, 192)    768         concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 2, 2, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 2, 2, 6)      10368       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 2, 2, 6)      0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 2, 2, 198)    0           concatenate_159[0][0]            \n",
      "                                                                 dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 2, 2, 198)    792         concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 198)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 198)          0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           1990        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 940,942\n",
      "Trainable params: 906,886\n",
      "Non-trainable params: 34,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEU5dsCISXLt"
   },
   "outputs": [],
   "source": [
    "# create a very simple learning schedule\n",
    "# Create a function for step decay in learning rate based on epochs\n",
    "def simple_decay(epoch):\n",
    "  initial_lrate = 0.1\n",
    "  \n",
    "  if epoch <= 100:\n",
    "    sim_lr = initial_lrate\n",
    "  elif  (100 < epoch <= 150):\n",
    "    sim_lr = initial_lrate/10.0\n",
    "  else:\n",
    "    sim_lr = initial_lrate/100.0\n",
    "      \n",
    "  return sim_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FHMPknjSXLv"
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(simple_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vtd9RbxSnhab"
   },
   "outputs": [],
   "source": [
    "# set up SGD optimizer with momentum\n",
    "# set decay and learning rate as zero, implement the rate changes through a callback\n",
    "optim = optimizers.SGD(lr=0.0, momentum=momentum_sgd, decay=1e-4, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71SbUCCpYPAV"
   },
   "outputs": [],
   "source": [
    "# checkpoint for saving weights whenever val acc increases\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"lastl2-aug-dropout-weights-improvement-{epoch:03d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint_dir = os.path.dirname(filepath)\n",
    "# set up checkpoint to save weights whenever validation accuracy improves\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsrbIWgwlYOC"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, lrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# compile the model using cross entropy loss and the SGD optimizer set up above\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1005
    },
    "colab_type": "code",
    "id": "0B1NbWVHbJwm",
    "outputId": "ba2f3341-82f2-492b-c93a-4427ecdc7ded"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "781/781 [==============================] - 238s 304ms/step - loss: 2.2169 - acc: 0.2501 - val_loss: 2.1323 - val_acc: 0.2739\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27390, saving model to lastl2-aug-dropout-weights-improvement-001-0.2739.hdf5\n",
      "Epoch 2/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 1.8921 - acc: 0.3632 - val_loss: 1.8248 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27390 to 0.40670, saving model to lastl2-aug-dropout-weights-improvement-002-0.4067.hdf5\n",
      "Epoch 3/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 1.6888 - acc: 0.4373 - val_loss: 1.6657 - val_acc: 0.4589\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.40670 to 0.45890, saving model to lastl2-aug-dropout-weights-improvement-003-0.4589.hdf5\n",
      "Epoch 4/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 1.5234 - acc: 0.4978 - val_loss: 1.6599 - val_acc: 0.4889\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.45890 to 0.48890, saving model to lastl2-aug-dropout-weights-improvement-004-0.4889.hdf5\n",
      "Epoch 5/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 1.3931 - acc: 0.5524 - val_loss: 1.9659 - val_acc: 0.4534\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.48890\n",
      "Epoch 6/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 1.2927 - acc: 0.5901 - val_loss: 1.6605 - val_acc: 0.5257\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.48890 to 0.52570, saving model to lastl2-aug-dropout-weights-improvement-006-0.5257.hdf5\n",
      "Epoch 7/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 1.2190 - acc: 0.6148 - val_loss: 1.4466 - val_acc: 0.5847\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.52570 to 0.58470, saving model to lastl2-aug-dropout-weights-improvement-007-0.5847.hdf5\n",
      "Epoch 8/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 1.1626 - acc: 0.6388 - val_loss: 2.4446 - val_acc: 0.4277\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.58470\n",
      "Epoch 9/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 1.1137 - acc: 0.6601 - val_loss: 1.8079 - val_acc: 0.5668\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.58470\n",
      "Epoch 10/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 1.0787 - acc: 0.6742 - val_loss: 1.7984 - val_acc: 0.5338\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.58470\n",
      "Epoch 11/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 1.0338 - acc: 0.6911 - val_loss: 1.8001 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.58470\n",
      "Epoch 12/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 1.0062 - acc: 0.7022 - val_loss: 1.0362 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.58470 to 0.70610, saving model to lastl2-aug-dropout-weights-improvement-012-0.7061.hdf5\n",
      "Epoch 13/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.9722 - acc: 0.7155 - val_loss: 1.6839 - val_acc: 0.5835\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.70610\n",
      "Epoch 14/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 0.9539 - acc: 0.7235 - val_loss: 1.6921 - val_acc: 0.5909\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.70610\n",
      "Epoch 15/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.9214 - acc: 0.7361 - val_loss: 1.6772 - val_acc: 0.6117\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.70610\n",
      "Epoch 16/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.9022 - acc: 0.7430 - val_loss: 1.2127 - val_acc: 0.6798\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.70610\n",
      "Epoch 17/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.8853 - acc: 0.7500 - val_loss: 1.4374 - val_acc: 0.6434\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70610\n",
      "Epoch 18/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.8668 - acc: 0.7577 - val_loss: 2.2531 - val_acc: 0.5529\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.70610\n",
      "Epoch 19/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 0.8562 - acc: 0.7615 - val_loss: 1.1950 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.70610\n",
      "Epoch 20/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.8409 - acc: 0.7669 - val_loss: 1.0028 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.70610 to 0.73690, saving model to lastl2-aug-dropout-weights-improvement-020-0.7369.hdf5\n",
      "Epoch 21/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.8279 - acc: 0.7702 - val_loss: 0.9586 - val_acc: 0.7543\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.73690 to 0.75430, saving model to lastl2-aug-dropout-weights-improvement-021-0.7543.hdf5\n",
      "Epoch 22/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.8120 - acc: 0.7785 - val_loss: 1.2720 - val_acc: 0.6874\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75430\n",
      "Epoch 23/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.8018 - acc: 0.7827 - val_loss: 0.9979 - val_acc: 0.7432\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75430\n",
      "Epoch 24/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.7871 - acc: 0.7858 - val_loss: 1.5309 - val_acc: 0.6705\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75430\n",
      "Epoch 25/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.7834 - acc: 0.7875 - val_loss: 1.1141 - val_acc: 0.7311\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75430\n",
      "Epoch 26/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.7672 - acc: 0.7930 - val_loss: 1.5302 - val_acc: 0.6600\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75430\n",
      "Epoch 27/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.7497 - acc: 0.8014 - val_loss: 0.8114 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.75430 to 0.80430, saving model to lastl2-aug-dropout-weights-improvement-027-0.8043.hdf5\n",
      "Epoch 28/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.7536 - acc: 0.7988 - val_loss: 0.9592 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80430\n",
      "Epoch 29/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.7436 - acc: 0.8036 - val_loss: 0.8606 - val_acc: 0.7865\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80430\n",
      "Epoch 30/200\n",
      "781/781 [==============================] - 182s 233ms/step - loss: 0.7299 - acc: 0.8077 - val_loss: 1.0963 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80430\n",
      "Epoch 31/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.7279 - acc: 0.8083 - val_loss: 0.8318 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80430\n",
      "Epoch 32/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.7185 - acc: 0.8125 - val_loss: 1.0373 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80430\n",
      "Epoch 33/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.7149 - acc: 0.8133 - val_loss: 1.0836 - val_acc: 0.7434\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80430\n",
      "Epoch 34/200\n",
      "781/781 [==============================] - 182s 234ms/step - loss: 0.7015 - acc: 0.8171 - val_loss: 1.3636 - val_acc: 0.7004\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.80430\n",
      "Epoch 35/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.6950 - acc: 0.8203 - val_loss: 1.4011 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.80430\n",
      "Epoch 36/200\n",
      "781/781 [==============================] - 182s 233ms/step - loss: 0.6880 - acc: 0.8222 - val_loss: 0.7395 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.80430 to 0.82390, saving model to lastl2-aug-dropout-weights-improvement-036-0.8239.hdf5\n",
      "Epoch 37/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.6905 - acc: 0.8206 - val_loss: 1.0521 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82390\n",
      "Epoch 38/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.6823 - acc: 0.8217 - val_loss: 0.8616 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82390\n",
      "Epoch 39/200\n",
      "781/781 [==============================] - 181s 232ms/step - loss: 0.6763 - acc: 0.8260 - val_loss: 0.9076 - val_acc: 0.7781\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.82390\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 184s 236ms/step - loss: 0.6664 - acc: 0.8292 - val_loss: 1.1540 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82390\n",
      "Epoch 41/200\n",
      "781/781 [==============================] - 190s 243ms/step - loss: 0.6632 - acc: 0.8293 - val_loss: 1.1164 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.82390\n",
      "Epoch 42/200\n",
      "781/781 [==============================] - 187s 240ms/step - loss: 0.6548 - acc: 0.8332 - val_loss: 1.0117 - val_acc: 0.7668\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.82390\n",
      "Epoch 43/200\n",
      "781/781 [==============================] - 188s 241ms/step - loss: 0.6580 - acc: 0.8314 - val_loss: 0.7276 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.82390 to 0.82840, saving model to lastl2-aug-dropout-weights-improvement-043-0.8284.hdf5\n",
      "Epoch 44/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.6374 - acc: 0.8393 - val_loss: 0.7886 - val_acc: 0.8209\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82840\n",
      "Epoch 45/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.6454 - acc: 0.8354 - val_loss: 0.7392 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.82840\n",
      "Epoch 46/200\n",
      "781/781 [==============================] - 181s 232ms/step - loss: 0.6343 - acc: 0.8399 - val_loss: 0.7605 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.82840\n",
      "Epoch 47/200\n",
      "781/781 [==============================] - 181s 232ms/step - loss: 0.6307 - acc: 0.8411 - val_loss: 0.9936 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.82840\n",
      "Epoch 48/200\n",
      "781/781 [==============================] - 189s 242ms/step - loss: 0.6273 - acc: 0.8427 - val_loss: 0.8362 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.82840\n",
      "Epoch 49/200\n",
      "781/781 [==============================] - 188s 241ms/step - loss: 0.6237 - acc: 0.8422 - val_loss: 0.7127 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.82840\n",
      "Epoch 50/200\n",
      "781/781 [==============================] - 187s 240ms/step - loss: 0.6192 - acc: 0.8442 - val_loss: 1.1771 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.82840\n",
      "Epoch 51/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.6156 - acc: 0.8452 - val_loss: 0.7868 - val_acc: 0.8174\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.82840\n",
      "Epoch 52/200\n",
      "781/781 [==============================] - 188s 240ms/step - loss: 0.6066 - acc: 0.8484 - val_loss: 0.8809 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.82840\n",
      "Epoch 53/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.6092 - acc: 0.8472 - val_loss: 0.8632 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.82840\n",
      "Epoch 54/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.6045 - acc: 0.8478 - val_loss: 0.8091 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.82840\n",
      "Epoch 55/200\n",
      "781/781 [==============================] - 188s 241ms/step - loss: 0.6030 - acc: 0.8469 - val_loss: 0.9293 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.82840\n",
      "Epoch 56/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.5957 - acc: 0.8530 - val_loss: 0.8128 - val_acc: 0.8149\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.82840\n",
      "Epoch 57/200\n",
      "781/781 [==============================] - 187s 240ms/step - loss: 0.5900 - acc: 0.8541 - val_loss: 0.7661 - val_acc: 0.8286\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.82840 to 0.82860, saving model to lastl2-aug-dropout-weights-improvement-057-0.8286.hdf5\n",
      "Epoch 58/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5934 - acc: 0.8510 - val_loss: 0.8958 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.82860\n",
      "Epoch 59/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5851 - acc: 0.8569 - val_loss: 0.9100 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.82860\n",
      "Epoch 60/200\n",
      "781/781 [==============================] - 186s 239ms/step - loss: 0.5829 - acc: 0.8562 - val_loss: 0.8194 - val_acc: 0.8126\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.82860\n",
      "Epoch 61/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.5794 - acc: 0.8563 - val_loss: 0.6853 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.82860 to 0.84200, saving model to lastl2-aug-dropout-weights-improvement-061-0.8420.hdf5\n",
      "Epoch 62/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.5787 - acc: 0.8575 - val_loss: 1.0222 - val_acc: 0.7663\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.84200\n",
      "Epoch 63/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5710 - acc: 0.8586 - val_loss: 0.7039 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.84200 to 0.84430, saving model to lastl2-aug-dropout-weights-improvement-063-0.8443.hdf5\n",
      "Epoch 64/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5683 - acc: 0.8598 - val_loss: 0.8534 - val_acc: 0.8052\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.84430\n",
      "Epoch 65/200\n",
      "781/781 [==============================] - 188s 240ms/step - loss: 0.5685 - acc: 0.8598 - val_loss: 0.8728 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.84430\n",
      "Epoch 66/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5619 - acc: 0.8619 - val_loss: 0.7398 - val_acc: 0.8269\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.84430\n",
      "Epoch 67/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.5653 - acc: 0.8594 - val_loss: 0.6716 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.84430 to 0.85010, saving model to lastl2-aug-dropout-weights-improvement-067-0.8501.hdf5\n",
      "Epoch 68/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5536 - acc: 0.8660 - val_loss: 0.7537 - val_acc: 0.8317\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85010\n",
      "Epoch 69/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5624 - acc: 0.8619 - val_loss: 0.7139 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85010\n",
      "Epoch 70/200\n",
      "781/781 [==============================] - 187s 240ms/step - loss: 0.5540 - acc: 0.8640 - val_loss: 0.6833 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.85010\n",
      "Epoch 71/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5454 - acc: 0.8673 - val_loss: 0.8501 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.85010\n",
      "Epoch 72/200\n",
      "781/781 [==============================] - 187s 240ms/step - loss: 0.5471 - acc: 0.8661 - val_loss: 0.8054 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85010\n",
      "Epoch 73/200\n",
      "781/781 [==============================] - 186s 239ms/step - loss: 0.5468 - acc: 0.8668 - val_loss: 0.8649 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85010\n",
      "Epoch 74/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5443 - acc: 0.8674 - val_loss: 0.9825 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85010\n",
      "Epoch 75/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5428 - acc: 0.8674 - val_loss: 0.7382 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85010\n",
      "Epoch 76/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5374 - acc: 0.8690 - val_loss: 0.8847 - val_acc: 0.7971\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.85010\n",
      "Epoch 77/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5288 - acc: 0.8719 - val_loss: 0.7883 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85010\n",
      "Epoch 78/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5340 - acc: 0.8702 - val_loss: 0.6014 - val_acc: 0.8636\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.85010 to 0.86360, saving model to lastl2-aug-dropout-weights-improvement-078-0.8636.hdf5\n",
      "Epoch 79/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5276 - acc: 0.8716 - val_loss: 0.7311 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.86360\n",
      "Epoch 80/200\n",
      "781/781 [==============================] - 186s 239ms/step - loss: 0.5295 - acc: 0.8716 - val_loss: 0.6132 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.86360\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5248 - acc: 0.8718 - val_loss: 0.6508 - val_acc: 0.8573\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.86360\n",
      "Epoch 82/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5277 - acc: 0.8724 - val_loss: 0.8283 - val_acc: 0.8214\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.86360\n",
      "Epoch 83/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5201 - acc: 0.8733 - val_loss: 0.9265 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.86360\n",
      "Epoch 84/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.5166 - acc: 0.8743 - val_loss: 0.8023 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.86360\n",
      "Epoch 85/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5204 - acc: 0.8744 - val_loss: 0.6954 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.86360\n",
      "Epoch 86/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.5167 - acc: 0.8746 - val_loss: 0.7668 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.86360\n",
      "Epoch 87/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5127 - acc: 0.8765 - val_loss: 0.7661 - val_acc: 0.8255\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.86360\n",
      "Epoch 88/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5132 - acc: 0.8755 - val_loss: 0.6733 - val_acc: 0.8451\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.86360\n",
      "Epoch 89/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.5109 - acc: 0.8768 - val_loss: 0.7275 - val_acc: 0.8349\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.86360\n",
      "Epoch 90/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5092 - acc: 0.8770 - val_loss: 0.8273 - val_acc: 0.8190\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.86360\n",
      "Epoch 91/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5082 - acc: 0.8771 - val_loss: 0.6330 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.86360\n",
      "Epoch 92/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.5047 - acc: 0.8784 - val_loss: 0.6017 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.86360 to 0.86610, saving model to lastl2-aug-dropout-weights-improvement-092-0.8661.hdf5\n",
      "Epoch 93/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.5019 - acc: 0.8790 - val_loss: 0.8548 - val_acc: 0.8116\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.86610\n",
      "Epoch 94/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.5004 - acc: 0.8793 - val_loss: 0.8413 - val_acc: 0.8123\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.86610\n",
      "Epoch 95/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.5015 - acc: 0.8786 - val_loss: 0.8548 - val_acc: 0.7967\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.86610\n",
      "Epoch 96/200\n",
      "781/781 [==============================] - 185s 238ms/step - loss: 0.4933 - acc: 0.8815 - val_loss: 0.8119 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.86610\n",
      "Epoch 97/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4955 - acc: 0.8812 - val_loss: 0.6362 - val_acc: 0.8617\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.86610\n",
      "Epoch 98/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4871 - acc: 0.8840 - val_loss: 0.6610 - val_acc: 0.8566\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.86610\n",
      "Epoch 99/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4917 - acc: 0.8815 - val_loss: 0.6662 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.86610\n",
      "Epoch 100/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4946 - acc: 0.8799 - val_loss: 0.7807 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.86610\n",
      "Epoch 101/200\n",
      "781/781 [==============================] - 186s 239ms/step - loss: 0.4873 - acc: 0.8837 - val_loss: 0.8243 - val_acc: 0.8128\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.86610\n",
      "Epoch 102/200\n",
      "781/781 [==============================] - 191s 244ms/step - loss: 0.4435 - acc: 0.8965 - val_loss: 0.5206 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.86610 to 0.89200, saving model to lastl2-aug-dropout-weights-improvement-102-0.8920.hdf5\n",
      "Epoch 103/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4123 - acc: 0.9084 - val_loss: 0.5603 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.89200\n",
      "Epoch 104/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.4104 - acc: 0.9094 - val_loss: 0.5270 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.89200 to 0.89230, saving model to lastl2-aug-dropout-weights-improvement-104-0.8923.hdf5\n",
      "Epoch 105/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3977 - acc: 0.9137 - val_loss: 0.5417 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.89230\n",
      "Epoch 106/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3937 - acc: 0.9130 - val_loss: 0.5218 - val_acc: 0.8953\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.89230 to 0.89530, saving model to lastl2-aug-dropout-weights-improvement-106-0.8953.hdf5\n",
      "Epoch 107/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3899 - acc: 0.9156 - val_loss: 0.5201 - val_acc: 0.8947\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.89530\n",
      "Epoch 108/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3871 - acc: 0.9169 - val_loss: 0.5525 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.89530\n",
      "Epoch 109/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3889 - acc: 0.9155 - val_loss: 0.5293 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.89530\n",
      "Epoch 110/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3814 - acc: 0.9172 - val_loss: 0.5412 - val_acc: 0.8923\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.89530\n",
      "Epoch 111/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3856 - acc: 0.9168 - val_loss: 0.5391 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.89530\n",
      "Epoch 112/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3816 - acc: 0.9177 - val_loss: 0.5371 - val_acc: 0.8900\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.89530\n",
      "Epoch 113/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3780 - acc: 0.9182 - val_loss: 0.5194 - val_acc: 0.8957\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.89530 to 0.89570, saving model to lastl2-aug-dropout-weights-improvement-113-0.8957.hdf5\n",
      "Epoch 114/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3769 - acc: 0.9186 - val_loss: 0.5304 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.89570\n",
      "Epoch 115/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3697 - acc: 0.9204 - val_loss: 0.5543 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.89570\n",
      "Epoch 116/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3751 - acc: 0.9193 - val_loss: 0.5213 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.89570\n",
      "Epoch 117/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3707 - acc: 0.9199 - val_loss: 0.5686 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.89570\n",
      "Epoch 118/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3660 - acc: 0.9218 - val_loss: 0.5373 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.89570\n",
      "Epoch 119/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3664 - acc: 0.9218 - val_loss: 0.5482 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.89570\n",
      "Epoch 120/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3661 - acc: 0.9214 - val_loss: 0.5090 - val_acc: 0.8974\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.89570 to 0.89740, saving model to lastl2-aug-dropout-weights-improvement-120-0.8974.hdf5\n",
      "Epoch 121/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3644 - acc: 0.9221 - val_loss: 0.5624 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.89740\n",
      "Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3648 - acc: 0.9215 - val_loss: 0.5290 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.89740\n",
      "Epoch 123/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3615 - acc: 0.9211 - val_loss: 0.5528 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.89740\n",
      "Epoch 124/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3610 - acc: 0.9224 - val_loss: 0.5241 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.89740\n",
      "Epoch 125/200\n",
      "174/781 [=====>........................] - ETA: 2:17 - loss: 0.3652 - acc: 0.9221"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=(x_train.shape[0] // batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/200\n",
      "781/781 [==============================] - 188s 241ms/step - loss: 0.4495 - acc: 0.8928 - val_loss: 0.6526 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00121: val_acc improved from -inf to 0.85920, saving model to lastl2-aug-dropout-weights-improvement-121-0.8592.hdf5\n",
      "Epoch 122/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4531 - acc: 0.8920 - val_loss: 0.7175 - val_acc: 0.8427\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.85920\n",
      "Epoch 123/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4489 - acc: 0.8943 - val_loss: 0.6096 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.85920 to 0.86440, saving model to lastl2-aug-dropout-weights-improvement-123-0.8644.hdf5\n",
      "Epoch 124/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.4395 - acc: 0.8963 - val_loss: 0.5713 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.86440 to 0.87310, saving model to lastl2-aug-dropout-weights-improvement-124-0.8731.hdf5\n",
      "Epoch 125/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4377 - acc: 0.8976 - val_loss: 0.8442 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.87310\n",
      "Epoch 126/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4318 - acc: 0.8977 - val_loss: 0.6335 - val_acc: 0.8639\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.87310\n",
      "Epoch 127/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4285 - acc: 0.8997 - val_loss: 0.5853 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.87310\n",
      "Epoch 128/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4161 - acc: 0.9038 - val_loss: 0.6378 - val_acc: 0.8604\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.87310\n",
      "Epoch 129/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4159 - acc: 0.9043 - val_loss: 0.7415 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.87310\n",
      "Epoch 130/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.4134 - acc: 0.9055 - val_loss: 0.5240 - val_acc: 0.8901\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.87310 to 0.89010, saving model to lastl2-aug-dropout-weights-improvement-130-0.8901.hdf5\n",
      "Epoch 131/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4084 - acc: 0.9054 - val_loss: 0.5820 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.89010\n",
      "Epoch 132/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.4047 - acc: 0.9064 - val_loss: 0.5526 - val_acc: 0.8845\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.89010\n",
      "Epoch 133/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3968 - acc: 0.9086 - val_loss: 0.5202 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.89010\n",
      "Epoch 134/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.4001 - acc: 0.9074 - val_loss: 0.5613 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.89010\n",
      "Epoch 135/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3908 - acc: 0.9113 - val_loss: 0.5492 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.89010\n",
      "Epoch 136/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.3908 - acc: 0.9099 - val_loss: 0.5666 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.89010\n",
      "Epoch 137/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3841 - acc: 0.9127 - val_loss: 0.5324 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.89010\n",
      "Epoch 138/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3841 - acc: 0.9116 - val_loss: 0.5089 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.89010\n",
      "Epoch 139/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3822 - acc: 0.9121 - val_loss: 0.5523 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.89010\n",
      "Epoch 140/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3770 - acc: 0.9138 - val_loss: 0.6006 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.89010\n",
      "Epoch 141/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3732 - acc: 0.9141 - val_loss: 0.5267 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.89010 to 0.89020, saving model to lastl2-aug-dropout-weights-improvement-141-0.8902.hdf5\n",
      "Epoch 142/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3689 - acc: 0.9151 - val_loss: 0.5478 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.89020\n",
      "Epoch 143/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3667 - acc: 0.9167 - val_loss: 0.6738 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.89020\n",
      "Epoch 144/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3665 - acc: 0.9175 - val_loss: 0.4847 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.89020 to 0.90090, saving model to lastl2-aug-dropout-weights-improvement-144-0.9009.hdf5\n",
      "Epoch 145/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3654 - acc: 0.9159 - val_loss: 0.5581 - val_acc: 0.8839\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.90090\n",
      "Epoch 146/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 0.3619 - acc: 0.9176 - val_loss: 0.5254 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.90090\n",
      "Epoch 147/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3597 - acc: 0.9200 - val_loss: 0.5492 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.90090\n",
      "Epoch 148/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3529 - acc: 0.9209 - val_loss: 0.5936 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.90090\n",
      "Epoch 149/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3516 - acc: 0.9210 - val_loss: 0.5628 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.90090\n",
      "Epoch 150/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3541 - acc: 0.9196 - val_loss: 0.6010 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.90090\n",
      "Epoch 151/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3496 - acc: 0.9216 - val_loss: 0.5459 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.90090\n",
      "Epoch 152/200\n",
      "669/781 [========================>.....] - ETA: 25s - loss: 0.3311 - acc: 0.9287"
     ]
    }
   ],
   "source": [
    "# reloading weights and continuinuing training as SSH connection issues disconnected notebook\n",
    "# including initial epoch as 120 and epochs = 200 to restart training from the checkpointed epoch with appropriate weights\n",
    "model.load_weights('lastl2-aug-dropout-weights-improvement-120-0.8974.hdf5')\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=(x_train.shape[0] // batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list,\n",
    "                        initial_epoch=120,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "781/781 [==============================] - 237s 304ms/step - loss: 0.4494 - acc: 0.8887 - val_loss: 0.5602 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00145: val_acc improved from -inf to 0.87440, saving model to lastl2-aug-dropout-weights-improvement-145-0.8744.hdf5\n",
      "Epoch 146/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4470 - acc: 0.8907 - val_loss: 0.6219 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.87440\n",
      "Epoch 147/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.4385 - acc: 0.8935 - val_loss: 0.5457 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.87440 to 0.88060, saving model to lastl2-aug-dropout-weights-improvement-147-0.8806.hdf5\n",
      "Epoch 148/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.4338 - acc: 0.8953 - val_loss: 0.5415 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.88060\n",
      "Epoch 149/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.4278 - acc: 0.8968 - val_loss: 0.5421 - val_acc: 0.8783\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.88060\n",
      "Epoch 150/200\n",
      "781/781 [==============================] - 186s 239ms/step - loss: 0.4205 - acc: 0.9001 - val_loss: 0.6891 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.88060\n",
      "Epoch 151/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.4186 - acc: 0.8994 - val_loss: 0.5154 - val_acc: 0.8894\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.88060 to 0.88940, saving model to lastl2-aug-dropout-weights-improvement-151-0.8894.hdf5\n",
      "Epoch 152/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3750 - acc: 0.9147 - val_loss: 0.4894 - val_acc: 0.8950\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.88940 to 0.89500, saving model to lastl2-aug-dropout-weights-improvement-152-0.8950.hdf5\n",
      "Epoch 153/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3546 - acc: 0.9227 - val_loss: 0.4915 - val_acc: 0.8964\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.89500 to 0.89640, saving model to lastl2-aug-dropout-weights-improvement-153-0.8964.hdf5\n",
      "Epoch 154/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3493 - acc: 0.9226 - val_loss: 0.4943 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.89640 to 0.89860, saving model to lastl2-aug-dropout-weights-improvement-154-0.8986.hdf5\n",
      "Epoch 155/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3422 - acc: 0.9256 - val_loss: 0.4799 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.89860 to 0.90120, saving model to lastl2-aug-dropout-weights-improvement-155-0.9012.hdf5\n",
      "Epoch 156/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3453 - acc: 0.9248 - val_loss: 0.4729 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.90120 to 0.90500, saving model to lastl2-aug-dropout-weights-improvement-156-0.9050.hdf5\n",
      "Epoch 157/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3397 - acc: 0.9264 - val_loss: 0.4893 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.90500\n",
      "Epoch 158/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3381 - acc: 0.9260 - val_loss: 0.5016 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.90500\n",
      "Epoch 159/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 0.3342 - acc: 0.9280 - val_loss: 0.4946 - val_acc: 0.8991\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.90500\n",
      "Epoch 160/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.3294 - acc: 0.9289 - val_loss: 0.4861 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.90500\n",
      "Epoch 161/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3303 - acc: 0.9292 - val_loss: 0.4786 - val_acc: 0.9035\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.90500\n",
      "Epoch 162/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3256 - acc: 0.9307 - val_loss: 0.4906 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.90500\n",
      "Epoch 163/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3225 - acc: 0.9311 - val_loss: 0.4837 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.90500\n",
      "Epoch 164/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3268 - acc: 0.9316 - val_loss: 0.4826 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.90500\n",
      "Epoch 165/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3250 - acc: 0.9316 - val_loss: 0.5052 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.90500\n",
      "Epoch 166/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3178 - acc: 0.9330 - val_loss: 0.4885 - val_acc: 0.9019\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.90500\n",
      "Epoch 167/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3267 - acc: 0.9299 - val_loss: 0.4964 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.90500\n",
      "Epoch 168/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3187 - acc: 0.9343 - val_loss: 0.4818 - val_acc: 0.9055\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.90500 to 0.90550, saving model to lastl2-aug-dropout-weights-improvement-168-0.9055.hdf5\n",
      "Epoch 169/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3209 - acc: 0.9322 - val_loss: 0.5025 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.90550\n",
      "Epoch 170/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3215 - acc: 0.9327 - val_loss: 0.4945 - val_acc: 0.9013\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.90550\n",
      "Epoch 171/200\n",
      "781/781 [==============================] - 183s 235ms/step - loss: 0.3193 - acc: 0.9326 - val_loss: 0.5002 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.90550\n",
      "Epoch 172/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3190 - acc: 0.9326 - val_loss: 0.5032 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.90550\n",
      "Epoch 173/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3159 - acc: 0.9341 - val_loss: 0.5030 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.90550\n",
      "Epoch 174/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.3197 - acc: 0.9325 - val_loss: 0.5039 - val_acc: 0.9014\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.90550\n",
      "Epoch 175/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3178 - acc: 0.9340 - val_loss: 0.4997 - val_acc: 0.9028\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.90550\n",
      "Epoch 176/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3185 - acc: 0.9331 - val_loss: 0.4866 - val_acc: 0.9061\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.90550 to 0.90610, saving model to lastl2-aug-dropout-weights-improvement-176-0.9061.hdf5\n",
      "Epoch 177/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3178 - acc: 0.9334 - val_loss: 0.4958 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.90610\n",
      "Epoch 178/200\n",
      "781/781 [==============================] - 187s 239ms/step - loss: 0.3154 - acc: 0.9341 - val_loss: 0.5035 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.90610\n",
      "Epoch 179/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3152 - acc: 0.9344 - val_loss: 0.4939 - val_acc: 0.9047\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.90610\n",
      "Epoch 180/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3144 - acc: 0.9345 - val_loss: 0.4970 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.90610\n",
      "Epoch 181/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3133 - acc: 0.9341 - val_loss: 0.4945 - val_acc: 0.9037\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.90610\n",
      "Epoch 182/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3100 - acc: 0.9356 - val_loss: 0.4907 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.90610\n",
      "Epoch 183/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3140 - acc: 0.9344 - val_loss: 0.4945 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.90610\n",
      "Epoch 184/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 183s 234ms/step - loss: 0.3129 - acc: 0.9347 - val_loss: 0.5068 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.90610\n",
      "Epoch 185/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3121 - acc: 0.9334 - val_loss: 0.4887 - val_acc: 0.9042\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.90610\n",
      "Epoch 186/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3123 - acc: 0.9350 - val_loss: 0.4944 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.90610\n",
      "Epoch 187/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3102 - acc: 0.9342 - val_loss: 0.4984 - val_acc: 0.9030\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.90610\n",
      "Epoch 188/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3134 - acc: 0.9337 - val_loss: 0.4936 - val_acc: 0.9040\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.90610\n",
      "Epoch 189/200\n",
      "781/781 [==============================] - 185s 236ms/step - loss: 0.3120 - acc: 0.9348 - val_loss: 0.4862 - val_acc: 0.9063\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.90610 to 0.90630, saving model to lastl2-aug-dropout-weights-improvement-189-0.9063.hdf5\n",
      "Epoch 190/200\n",
      "781/781 [==============================] - 184s 236ms/step - loss: 0.3090 - acc: 0.9354 - val_loss: 0.4932 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.90630\n",
      "Epoch 191/200\n",
      "781/781 [==============================] - 183s 234ms/step - loss: 0.3112 - acc: 0.9351 - val_loss: 0.4828 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.90630 to 0.90690, saving model to lastl2-aug-dropout-weights-improvement-191-0.9069.hdf5\n",
      "Epoch 192/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3084 - acc: 0.9352 - val_loss: 0.4809 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.90690\n",
      "Epoch 193/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3096 - acc: 0.9355 - val_loss: 0.4887 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.90690\n",
      "Epoch 194/200\n",
      "781/781 [==============================] - 184s 235ms/step - loss: 0.3079 - acc: 0.9358 - val_loss: 0.4820 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.90690\n",
      "Epoch 195/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3051 - acc: 0.9372 - val_loss: 0.4858 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.90690\n",
      "Epoch 196/200\n",
      "781/781 [==============================] - 182s 234ms/step - loss: 0.3067 - acc: 0.9355 - val_loss: 0.4840 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.90690\n",
      "Epoch 197/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3059 - acc: 0.9368 - val_loss: 0.4854 - val_acc: 0.9062\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.90690\n",
      "Epoch 198/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3098 - acc: 0.9351 - val_loss: 0.4822 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.90690\n",
      "Epoch 199/200\n",
      "781/781 [==============================] - 185s 237ms/step - loss: 0.3059 - acc: 0.9359 - val_loss: 0.4870 - val_acc: 0.9058\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.90690\n",
      "Epoch 200/200\n",
      "781/781 [==============================] - 186s 238ms/step - loss: 0.3053 - acc: 0.9359 - val_loss: 0.4839 - val_acc: 0.9059\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.90690\n"
     ]
    }
   ],
   "source": [
    "# reloading weights and continuinuing training as SSH connection issues disconnected notebook again\n",
    "# including initial epoch as 144 and epochs = 200 to restart training from the checkpointed epoch with appropriate weights\n",
    "model.load_weights('lastl2-aug-dropout-weights-improvement-144-0.9009.hdf5')\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=(x_train.shape[0] // batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list,\n",
    "                        initial_epoch=144,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last leg of training using the learnt weights on unaugmented image data\n",
    "# this includes a call back to reduce learning rate if needed and to stop training if no improvement is seen in 15 epochs\n",
    "\n",
    "# create callbacks for learning rate reduction and for early stopping\n",
    "reduce = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, mode='auto')\n",
    "early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=15, mode='auto')\n",
    "\n",
    "# update the callbacks list used earlier to now include these while dropping the call to the LR scheduler\n",
    "callbacks_list = [checkpoint, reduce, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 201/250\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.2808 - acc: 0.9455 - val_loss: 0.4615 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00201: val_acc improved from 0.90690 to 0.90980, saving model to lastl2-aug-dropout-weights-improvement-201-0.9098.hdf5\n",
      "Epoch 202/250\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.2758 - acc: 0.9466 - val_loss: 0.4640 - val_acc: 0.9097\n",
      "\n",
      "Epoch 00202: val_acc did not improve from 0.90980\n",
      "Epoch 203/250\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.2749 - acc: 0.9474 - val_loss: 0.4660 - val_acc: 0.9100\n",
      "\n",
      "Epoch 00203: val_acc improved from 0.90980 to 0.91000, saving model to lastl2-aug-dropout-weights-improvement-203-0.9100.hdf5\n",
      "Epoch 204/250\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.2715 - acc: 0.9483 - val_loss: 0.4679 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00204: val_acc did not improve from 0.91000\n",
      "Epoch 205/250\n",
      "50000/50000 [==============================] - 183s 4ms/step - loss: 0.2736 - acc: 0.9483 - val_loss: 0.4660 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00205: val_acc did not improve from 0.91000\n",
      "Epoch 206/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2680 - acc: 0.9492 - val_loss: 0.4760 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00206: val_acc did not improve from 0.91000\n",
      "Epoch 207/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2686 - acc: 0.9488 - val_loss: 0.4744 - val_acc: 0.9069\n",
      "\n",
      "Epoch 00207: val_acc did not improve from 0.91000\n",
      "Epoch 208/250\n",
      "50000/50000 [==============================] - 183s 4ms/step - loss: 0.2707 - acc: 0.9484 - val_loss: 0.4693 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00208: val_acc did not improve from 0.91000\n",
      "Epoch 209/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2719 - acc: 0.9480 - val_loss: 0.4696 - val_acc: 0.9086\n",
      "\n",
      "Epoch 00209: val_acc did not improve from 0.91000\n",
      "Epoch 210/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2706 - acc: 0.9484 - val_loss: 0.4720 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00210: val_acc did not improve from 0.91000\n",
      "Epoch 211/250\n",
      "50000/50000 [==============================] - 186s 4ms/step - loss: 0.2684 - acc: 0.9492 - val_loss: 0.4728 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00211: val_acc did not improve from 0.91000\n",
      "Epoch 212/250\n",
      "50000/50000 [==============================] - 185s 4ms/step - loss: 0.2688 - acc: 0.9496 - val_loss: 0.4693 - val_acc: 0.9084\n",
      "\n",
      "Epoch 00212: val_acc did not improve from 0.91000\n",
      "Epoch 213/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2696 - acc: 0.9482 - val_loss: 0.4711 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00213: val_acc did not improve from 0.91000\n",
      "Epoch 214/250\n",
      "50000/50000 [==============================] - 184s 4ms/step - loss: 0.2692 - acc: 0.9491 - val_loss: 0.4694 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00214: val_acc did not improve from 0.91000\n",
      "Epoch 215/250\n",
      "50000/50000 [==============================] - 183s 4ms/step - loss: 0.2682 - acc: 0.9497 - val_loss: 0.4689 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00215: val_acc did not improve from 0.91000\n",
      "Epoch 216/250\n",
      "50000/50000 [==============================] - 183s 4ms/step - loss: 0.2672 - acc: 0.9495 - val_loss: 0.4740 - val_acc: 0.9076\n",
      "\n",
      "Epoch 00216: val_acc did not improve from 0.91000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f300cb91fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on unaugmented data start with initial epoch = 200 to ensure that we meet the assignment limit of 250 epochs\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=250,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=callbacks_list,\n",
    "          initial_epoch=200,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9h5T10ERFoDe"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a subplot grid that is 1 x 2\n",
    "\n",
    "# set up x_axis based on epochs run above, y axis is set on expected values of loss and accuracy\n",
    "max_x = 220\n",
    "\n",
    "# set the size with aspect ratio 4:1\n",
    "fig = plt.figure(figsize=(16,4))\n",
    "# and set the first such subplot as active.\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(np.arange(10, (max_x+1), step=10), rotation=90)\n",
    "plt.yticks(np.arange(0.75, 1.09, step=0.01))\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,max_x])\n",
    "axes.set_ylim([0.75, 1.00])\n",
    "plt.legend(['training acc', 'validation acc'], loc='upper right')\n",
    "\n",
    "# now set the second subplot as active, doing this will allow space between the two plots.\n",
    "plt.subplot(1, 2, 2)\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xticks(np.arange(10, (max_x+1), step=10), rotation=90)\n",
    "plt.yticks(np.arange(0.1, 2.01, step=0.05))\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,max_x])\n",
    "axes.set_ylim([0.10, 2.00])\n",
    "plt.legend(['training loss', 'validation loss'], loc='upper right')\n",
    "\n",
    "# actually display the two plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the generalization error from the training run above\n",
    "gen_error = []\n",
    "for item in range(len(history.history['val_loss'])):\n",
    "    gen_error.append(history.history['val_loss'][item]- history.history['loss'][item])\n",
    "    \n",
    "plt.plot(gen_error_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [],
   "source": [
    "# Test the best model by loading the best checkpoint\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "model.save_weights(\"DNST_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mult_blks_drpout_constraint_28_Oct.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
